{"cells":[{"source":"## Reshaping Data w/Pandas\n\n### Intro to DataReshaping\nLet's start by understanding the concept of wide and long formats and the advantages of using each of them. Youâ€™ll then learn how to pivot data from long to a wide format, and get summary statistics from a large DataFrame.","metadata":{},"cell_type":"markdown","id":"c4cc3a3b-4e6c-4108-b0aa-c687e81f36eb"},{"source":"# Import any packages you want to use here\nimport pandas as pd","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# Import any packages you want to use here\nimport pandas as pd"},"id":"7f26dd6a-20aa-4d19-8d3f-b8f64fba1821","cell_type":"code","execution_count":1,"outputs":[]},{"source":"#### Flipping players\nCongratulations! You got the data scientist job! In your first project, you will work with the fifa_players dataset. It contains data of the players included in the last version of the video game. Before you start to do any analysis, you need to clean and format your dataset.\n\nAs a first step, you need to explore your dataset and reshape it using basic steps, such as setting different indices, filtering columns and flipping the DataFrame. You would like to see if that is enough for further analysis.","metadata":{},"cell_type":"markdown","id":"b13a5875-0954-4b83-866b-e9a681f10e25"},{"source":"fifa_players = pd.DataFrame({\n    'name': ['Lionel Messi', 'Cristiano Ronaldo', 'Neymar da Silva', 'Jan Oblak', 'Eden Hazard'],\n    'age':[32, 34, 27, 26, 28],\n    'height':[170, 187, 175, 188, 175],\n    'weight':[72, 83, 68, 87, 74],\n    'nationality':['Argentina', 'Portugal', 'Brazil', 'Slovenia', 'Belgium'],\n    'club':['FC Barcelona', 'Juventus', 'Paris Saint-Germain', 'Atletico Madrid', 'Real Madrid']\n})\nfifa_players","metadata":{"executionTime":199,"lastSuccessfullyExecutedCode":"fifa_players = pd.DataFrame({\n    'name': ['Lionel Messi', 'Cristiano Ronaldo', 'Neymar da Silva', 'Jan Oblak', 'Eden Hazard'],\n    'age':[32, 34, 27, 26, 28],\n    'height':[170, 187, 175, 188, 175],\n    'weight':[72, 83, 68, 87, 74],\n    'nationality':['Argentina', 'Portugal', 'Brazil', 'Slovenia', 'Belgium'],\n    'club':['FC Barcelona', 'Juventus', 'Paris Saint-Germain', 'Atletico Madrid', 'Real Madrid']\n})\nfifa_players"},"cell_type":"code","id":"07d41b6e-c48a-49eb-93b3-aaaee2369d77","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"application/com.datacamp.data-table.v1+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"name","type":"string"},{"name":"age","type":"integer"},{"name":"height","type":"integer"},{"name":"weight","type":"integer"},{"name":"nationality","type":"string"},{"name":"club","type":"string"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":[{"index":0,"name":"Lionel Messi","age":32,"height":170,"weight":72,"nationality":"Argentina","club":"FC Barcelona"},{"index":1,"name":"Cristiano Ronaldo","age":34,"height":187,"weight":83,"nationality":"Portugal","club":"Juventus"},{"index":2,"name":"Neymar da Silva","age":27,"height":175,"weight":68,"nationality":"Brazil","club":"Paris Saint-Germain"},{"index":3,"name":"Jan Oblak","age":26,"height":188,"weight":87,"nationality":"Slovenia","club":"Atletico Madrid"},{"index":4,"name":"Eden Hazard","age":28,"height":175,"weight":74,"nationality":"Belgium","club":"Real Madrid"}]},"total_rows":5,"truncation_type":null},"text/plain":"                name  age  height  weight nationality                 club\n0       Lionel Messi   32     170      72   Argentina         FC Barcelona\n1  Cristiano Ronaldo   34     187      83    Portugal             Juventus\n2    Neymar da Silva   27     175      68      Brazil  Paris Saint-Germain\n3          Jan Oblak   26     188      87    Slovenia      Atletico Madrid\n4        Eden Hazard   28     175      74     Belgium          Real Madrid","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>age</th>\n      <th>height</th>\n      <th>weight</th>\n      <th>nationality</th>\n      <th>club</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Lionel Messi</td>\n      <td>32</td>\n      <td>170</td>\n      <td>72</td>\n      <td>Argentina</td>\n      <td>FC Barcelona</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Cristiano Ronaldo</td>\n      <td>34</td>\n      <td>187</td>\n      <td>83</td>\n      <td>Portugal</td>\n      <td>Juventus</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Neymar da Silva</td>\n      <td>27</td>\n      <td>175</td>\n      <td>68</td>\n      <td>Brazil</td>\n      <td>Paris Saint-Germain</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Jan Oblak</td>\n      <td>26</td>\n      <td>188</td>\n      <td>87</td>\n      <td>Slovenia</td>\n      <td>Atletico Madrid</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Eden Hazard</td>\n      <td>28</td>\n      <td>175</td>\n      <td>74</td>\n      <td>Belgium</td>\n      <td>Real Madrid</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"source":"# Set name as index\nfifa_transpose = fifa_players.set_index('name')\n\n# Print fifa_transpose\nprint(fifa_transpose, '\\n')\n\n# Modify the DataFrame to keep only height and weight columns\nfifa_transpose = fifa_players.set_index('name')[['height', 'weight']]\n\n# Print fifa_transpose\nprint(fifa_transpose, '\\n')\n\n# Change the DataFrame so rows become columns and vice versa\nfifa_transpose = fifa_players.set_index('name')[['height', 'weight']].transpose()\n\n# Print fifa_transpose\nprint(fifa_transpose)","metadata":{"executionTime":130,"lastSuccessfullyExecutedCode":"# Set name as index\nfifa_transpose = fifa_players.set_index('name')\n\n# Print fifa_transpose\nprint(fifa_transpose, '\\n')\n\n# Modify the DataFrame to keep only height and weight columns\nfifa_transpose = fifa_players.set_index('name')[['height', 'weight']]\n\n# Print fifa_transpose\nprint(fifa_transpose, '\\n')\n\n# Change the DataFrame so rows become columns and vice versa\nfifa_transpose = fifa_players.set_index('name')[['height', 'weight']].transpose()\n\n# Print fifa_transpose\nprint(fifa_transpose)"},"cell_type":"code","id":"b5c649ca-7b7f-491c-a1a1-ef3ee6acd4cf","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":"                   age  height  weight nationality                 club\nname                                                                   \nLionel Messi        32     170      72   Argentina         FC Barcelona\nCristiano Ronaldo   34     187      83    Portugal             Juventus\nNeymar da Silva     27     175      68      Brazil  Paris Saint-Germain\nJan Oblak           26     188      87    Slovenia      Atletico Madrid\nEden Hazard         28     175      74     Belgium          Real Madrid \n\n                   height  weight\nname                             \nLionel Messi          170      72\nCristiano Ronaldo     187      83\nNeymar da Silva       175      68\nJan Oblak             188      87\nEden Hazard           175      74 \n\nname    Lionel Messi  Cristiano Ronaldo  ...  Jan Oblak  Eden Hazard\nheight           170                187  ...        188          175\nweight            72                 83  ...         87           74\n\n[2 rows x 5 columns]\n"}]},{"source":"### Dribbling the pivot method\nIt's time to keep working with the fifa_players dataset. After you explored the dataset, you realized the dataset contains player scores on different movements: shooting, dribbling, and passing. There are attacking scores as well as overall scores.\n\nThe goal of the project is to analyze the scores to create an optimized team, so you decide to explore which score is better. But the current data is in a long format. You'll need to to pivot your DataFrame in different ways to discover a pattern.\n\n\n```python\n# fifa_players df\n                name   movement  overall  attacking\n0           L. Messi   shooting       92         70\n1  Cristiano Ronaldo   shooting       93         89\n2           L. Messi    passing       92         92\n3  Cristiano Ronaldo    passing       82         83\n4           L. Messi  dribbling       96         88\n5  Cristiano Ronaldo  dribbling       89         84\n\n# Pivot fifa_players to get overall scores indexed by name and identified by movement\nfifa_overall = fifa_players.pivot(index='name', columns='movement', values='overall')\n\n# Print fifa_overall\nprint(fifa_overall)\n\n# pivoted item wit name as index, column values set to unique items for movement, with overall values for movement set to values for column return\nmovement           dribbling  passing  shooting\nname                                           \nCristiano Ronaldo         89       82        93\nL. Messi                  96       92        92\n```\n\n```python\n# Pivot fifa_players to get attacking scores indexed by name and identified by movement\nfifa_attacking = fifa_players.pivot(index='name', columns='movement', values='attacking')\n\n# Print fifa_attacking\nprint(fifa_attacking)\n\n# pivoted \nmovement           dribbling  passing  shooting\nname                                           \nCristiano Ronaldo         84       83        89\nL. Messi                  88       92        70\n```\n\n```python\n# Use the pivot method to get overall scores indexed by movement and identified by name\nfifa_names = fifa_players.pivot(index='movement', columns='name', values='overall')\n\n# Print fifa_names\nprint(fifa_names)\n\n# pivoted by index as movement, column values set to the names with values for each being brought over from overall tallies for each\nname       Cristiano Ronaldo  L. Messi\nmovement                              \ndribbling                 89        96\npassing                   82        92\nshooting                  93        92\n```\n\n### Offensive or defensive player?\nYou're not convinced with your previous exploration - you've discovered patterns in the attacking and overall scores in fifa_players. You would like to compare both scores, so you would like to see both in the same DataFrame.\n\nTo do this, you'll need a way to pivot more than one column. You remember you can achieve this goal in two different ways: you could pivot the DataFrame using the list with the two columns, or you could extend the .pivot() method to all the columns present in the dataset.\n\n```python\n# Pivot fifa_players to get overall and attacking scores indexed by name and identified by movement\nfifa_over_attack = fifa_players.pivot(index='name', \n                                     columns='movement', \n                                     values=['overall', 'attacking'])\n\n# Print fifa_over_attack\nprint(fifa_over_attack)\n\n<script.py> output:\n                        overall                  attacking                 \n    movement          dribbling passing shooting dribbling passing shooting\n    name                                                                   \n    Cristiano Ronaldo        89      82       93        84      83       89\n    L. Messi                 96      92       92        88      92       70\n    \n# Use pivot method to get all the scores index by name and identified by movement\nfifa_all = fifa_players.pivot(index='name', columns='movement')\n\n# Print fifa_over_attack\nprint(fifa_all)\n    \n# Same output if not declaring values as it will just default the unused columns\n```","metadata":{},"cell_type":"markdown","id":"2c8c9cb6-c77c-494e-ae85-dd5b4c0e7aa9"},{"source":"## Intro Section Closing\n### Reviewing the moves\nWow! You have now learned about pivot tables. In the last analysis that you did, you encountered a DataFrame that had non-unique index/column pairs. In order to pivot your DataFrame, you wrote code to drop the last row, and then reshaped it.\n\nIn this exercise, you will modify the code using pivot tables and compare it with your strategy of using the pivot method.\n\n```python\n# DFrame in exercises\nfifa_players\n                name   movement  overall  attacking\n0           L. Messi   shooting       92         70\n1  Cristiano Ronaldo   shooting       93         89\n2           L. Messi    passing       92         92\n3  Cristiano Ronaldo    passing       82         83\n4           L. Messi  dribbling       96         88\n5  Cristiano Ronaldo  dribbling       89         84\n6           L. Messi  dribbling       88         97\n\n# Discard the fifth row to delete all repeated rows\nfifa_drop = fifa_players.drop(4, axis=0)\n\n# Use pivot method to get all scores by name and movement\nfifa_pivot = fifa_drop.pivot(index='name', columns='movement') \n\n# Print fifa_pivot\nprint(fifa_pivot, '\\n')  \n\n# Use pivot table to get all scores by name and movement\nfifa_pivot_table = fifa_players.pivot_table(index='name', \n                                     columns='movement', \n                                     aggfunc='mean')\n# Print fifa_pivot_table\nprint(fifa_pivot_table)\n\n\n                    overall                  attacking                 \nmovement          dribbling passing shooting dribbling passing shooting\nname                                                                   \nCristiano Ronaldo        89      82       93        84      83       89\nL. Messi                 88      92       92        97      92       70 \n\n                  attacking                    overall                 \nmovement          dribbling passing shooting dribbling passing shooting\nname                                                                   \nCristiano Ronaldo      84.0    83.0     89.0        89      82       93\nL. Messi               92.5    92.0     70.0        92      92       92\n```","metadata":{},"cell_type":"markdown","id":"effc7e8d-0acf-4ad7-809b-cdfbc89e2633"},{"source":"# Use pivot table to display mean age of players by club and nationality \nmean_age_fifa = fifa_players.pivot_table(index='nationality', \n                                  columns='club', \n                                  values='age', \n                                  aggfunc='mean')\n\n# Print mean_age_fifa\nprint(mean_age_fifa)","metadata":{"executionTime":117,"lastSuccessfullyExecutedCode":"# Use pivot table to display mean age of players by club and nationality \nmean_age_fifa = fifa_players.pivot_table(index='nationality', \n                                  columns='club', \n                                  values='age', \n                                  aggfunc='mean')\n\n# Print mean_age_fifa\nprint(mean_age_fifa)"},"cell_type":"code","id":"10ee5f00-f9a3-40b4-a8ea-12fd6bda8028","execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":"club         Atletico Madrid  FC Barcelona  ...  Paris Saint-Germain  Real Madrid\nnationality                                 ...                                  \nArgentina                NaN          32.0  ...                  NaN          NaN\nBelgium                  NaN           NaN  ...                  NaN         28.0\nBrazil                   NaN           NaN  ...                 27.0          NaN\nPortugal                 NaN           NaN  ...                  NaN          NaN\nSlovenia                26.0           NaN  ...                  NaN          NaN\n\n[5 rows x 5 columns]\n"}]},{"source":"### Using Provided DataFrame in Exercises\n```python\nIn [1]:\nfifa_players\nOut[1]:\n\n        id                                 name  age  height  weight nationality          club\n0   192448                Marc-AndrÃ© ter Stegen   27     187      85     Germany  FC Barcelona\n1   177003                          Luka ModriÄ‡   33     172      66     Croatia   Real Madrid\n2   176580             Luis Alberto SuÃ¡rez DÃ­az   32     182      86     Uruguay  FC Barcelona\n3   194765                    Antoine Griezmann   28     176      73      France  FC Barcelona\n4   182521                           Toni Kroos   29     183      76     Germany   Real Madrid\n5   200145    Carlos Henrique Venancio Casimiro   27     185      84      Brazil   Real Madrid\n6   165153                        Karim Benzema   31     185      81      France   Real Madrid\n7   205600                        Samuel Umtiti   25     182      75      France  FC Barcelona\n8   168651                         Ivan RakitiÄ‡   31     184      78     Croatia  FC Barcelona\n9   201535                       RaphaÃ«l Varane   26     191      81      France   Real Madrid\n10  220440                      ClÃ©ment Lenglet   24     186      81      France  FC Barcelona\n11  194404                 Norberto Murara Neto   29     190      84      Brazil  FC Barcelona\n12  176676       Marcelo Vieira da Silva JÃºnior   31     174      75      Brazil   Real Madrid\n13  231443                      Ousmane DembÃ©lÃ©   22     178      67      France  FC Barcelona\n14  230658  Arthur Henrique Ramos Oliveira Melo   22     171      73      Brazil  FC Barcelona\n15  240130                 Ã‰der Gabriel MilitÃ£o   21     186      78      Brazil   Real Madrid\n16  201400       Rafael AlcÃ¢ntara do Nascimento   26     174      71      Brazil  FC Barcelona\n17  228618                        Ferland Mendy   24     180      73      France   Real Madrid\n18  238794     VinÃ­cius JosÃ© de Oliveira JÃºnior   18     176      73      Brazil   Real Madrid\n19  239053                    Federico Valverde   20     182      78     Uruguay   Real Madrid\n20  243812                Rodrygo Silva de Goes   18     174      64      Brazil   Real Madrid\n21  209749                   Lucas Silva Borges   26     182      80      Brazil   Real Madrid\n22  245388                    Jean-Clair Todibo   19     190      81      France  FC Barcelona\n\n# Use pivot table to display max height of any player by club and nationality\ntall_players_fifa = fifa_players.pivot_table(index='nationality', \n                                     columns='club', \n                                      values='height', \n                                      aggfunc='max')\n\n# Print tall_players_fifa\nprint(tall_players_fifa)\nclub         FC Barcelona  Real Madrid\nnationality                           \nBrazil                190          186\nCroatia               184          172\nFrance                190          191\nGermany               187          183\nUruguay               182          182\n\n\n# Use pivot table to show the count of players by club and nationality and the total count\nplayers_country = fifa_players.pivot_table(index='nationality', \n                                    columns='club', \n                                    values='name', \n                                    aggfunc='count', \n                                    margins=True)\n\n# Print players_country\nprint(players_country)\n\nclub         FC Barcelona  Real Madrid  All\nnationality                                \nBrazil                  3            6    9\nCroatia                 1            1    2\nFrance                  5            3    8\nGermany                 1            1    2\nUruguay                 1            1    2\nAll                    11           12   23\n```\n\n### The tallest and the heaviest\nYou will continue your exploration of characteristics of players in fifa_players belonging to two teams: FC Barcelona and Real Madrid. As your last task, you are interested in exploring the maximum height and weight separated by teams and nationality. You will also compare two years, 2000 and 2010.\n\nYou have two columns that you want to set as an index, so you will need to use pivot_table().\n\nThe fifa_players dataset is available for you. It contains data about the club, nationality, height, weight, and year of the players playing for each team.\n\n```python\nprint(fifa_players.head())\n           club nationality  year  height  weight\n0  FC Barcelona     Germany  2000     187      85\n1  FC Barcelona     Germany  2010     189      87\n2   Real Madrid     Croatia  2000     172      66\n3   Real Madrid     Croatia  2010     173      68\n4   Real Madrid     Germany  2000     183      76\n\n\n# Set the argument to get the maximum for each row and column\nfifa_mean = fifa_players.pivot_table(index=['nationality', 'club'], \n                                     columns='year', \n                                     aggfunc='max', \n                                     margins=True)\n\n# Print fifa_mean\nprint(fifa_mean)\n                             height           weight         \n    year                       2000 2010  All   2000 2010 All\n    nationality club                                         \n    Croatia     FC Barcelona    184  185  185     78   76  78\n                Real Madrid     172  173  173     66   68  68\n    Germany     FC Barcelona    187  189  189     85   87  87\n                Real Madrid     183  185  185     76   77  77\n    All                         187  189  189     85   87  87\n```","metadata":{},"cell_type":"markdown","id":"f33091ff-f334-43f5-9c71-93f97ca13067"},{"source":"## Converting Between Wide & Long Format \nMaster the technique of reshaping DataFrames from wide to long format. In this chapter, you'll learn how to use the melting method and wide to long function before discovering how to handle string columns by concatenating or splitting them.\n\n### Reshaping w/Melt (Wide to Long)\n```python\nIn [2]:\nbooks_gothic\nOut[2]:\n\n                        title       authors  num_pages  rating_count  rating          publisher\n0           Wuthering Heights  Emily Bronte        322          2155    3.85      Penguin Books\n1                Frankenstein  Mary Shelley        189          2452    4.31  Kaplan Publishing\n2  The Picture of Dorian Gray   Oscar Wilde        187          3342    4.15            Pearson\n\n# Melt books_gothic using the title column as identifier \ngothic_melted = books_gothic.melt(id_vars='title')\n\n# Print gothic_melted\nprint(gothic_melted)\n<script.py> output:\n                             title      variable              value\n    0            Wuthering Heights       authors       Emily Bronte\n    1                 Frankenstein       authors       Mary Shelley\n    2   The Picture of Dorian Gray       authors        Oscar Wilde\n    3            Wuthering Heights     num_pages                322\n    4                 Frankenstein     num_pages                189\n    5   The Picture of Dorian Gray     num_pages                187\n    6            Wuthering Heights  rating_count               2155\n    7                 Frankenstein  rating_count               2452\n    8   The Picture of Dorian Gray  rating_count               3342\n    9            Wuthering Heights        rating               3.85\n    10                Frankenstein        rating               4.31\n    11  The Picture of Dorian Gray        rating               4.15\n    12           Wuthering Heights     publisher      Penguin Books\n    13                Frankenstein     publisher  Kaplan Publishing\n    14  The Picture of Dorian Gray     publisher            Pearson\n```\n\n```python\n# Melt books_gothic using the title, authors, and publisher columns as identifier\ngothic_melted_new = books_gothic.melt(id_vars=['title','authors', 'publisher'])\n\n# Print gothic_melted_new\nprint(gothic_melted_new)\n\n<script.py> output:\n                            title       authors          publisher      variable    value\n    0           Wuthering Heights  Emily Bronte      Penguin Books     num_pages   322.00\n    1                Frankenstein  Mary Shelley  Kaplan Publishing     num_pages   189.00\n    2  The Picture of Dorian Gray   Oscar Wilde            Pearson     num_pages   187.00\n    3           Wuthering Heights  Emily Bronte      Penguin Books  rating_count  2155.00\n    4                Frankenstein  Mary Shelley  Kaplan Publishing  rating_count  2452.00\n    5  The Picture of Dorian Gray   Oscar Wilde            Pearson  rating_count  3342.00\n    6           Wuthering Heights  Emily Bronte      Penguin Books        rating     3.85\n    7                Frankenstein  Mary Shelley  Kaplan Publishing        rating     4.31\n    8  The Picture of Dorian Gray   Oscar Wilde            Pearson        rating     4.15\n```\n* Notice here as the unused columns are then placed per row with the variable and then value to transform to long version\n\n```python\n# Melt publisher column using title and authors as identifiers\npublisher_melted = books_gothic.melt(id_vars=['title', 'authors'], \n                                     value_vars='publisher')\n\n# Print publisher_melted\nprint(publisher_melted)\n<script.py> output:\n                            title       authors   variable              value\n    0           Wuthering Heights  Emily Bronte  publisher      Penguin Books\n    1                Frankenstein  Mary Shelley  publisher  Kaplan Publishing\n    2  The Picture of Dorian Gray   Oscar Wilde  publisher            Pearson\n    \n    \n# Melt rating and rating_count columns using the title as identifier\nrating_melted = books_gothic.melt(id_vars='title', \n                                  value_vars=['rating', 'rating_count'])\n\n# Print rating_melted\nprint(rating_melted)\n\n<script.py> output:\n                            title      variable    value\n    0           Wuthering Heights        rating     3.85\n    1                Frankenstein        rating     4.31\n    2  The Picture of Dorian Gray        rating     4.15\n    3           Wuthering Heights  rating_count  2155.00\n    4                Frankenstein  rating_count  2452.00\n    5  The Picture of Dorian Gray  rating_count  3342.00\n    \n# Melt rating and rating_count columns using title and authors as identifier\nbooks_melted = books_gothic.melt(id_vars=['title', 'authors'], \n                                 value_vars=['rating', 'rating_count'])\n\n# Print books_melted\nprint(books_melted)\n\n                        title       authors      variable    value\n0           Wuthering Heights  Emily Bronte        rating     3.85\n1                Frankenstein  Mary Shelley        rating     4.31\n2  The Picture of Dorian Gray   Oscar Wilde        rating     4.15\n3           Wuthering Heights  Emily Bronte  rating_count  2155.00\n4                Frankenstein  Mary Shelley  rating_count  2452.00\n5  The Picture of Dorian Gray   Oscar Wilde  rating_count  3342.00\n```\n\n#### How is Frankenstein, Dorian Gray?\nYou are satisfied with the way you reshaped the books_gothic DataFrame, however, you would like to finish your work by naming the newly-created columns. This will help you clarify what the variables and values are.\n\nYou remember that .melt() allows you to do that. In order to achieve your goal, you will reshape your DataFrame in three steps.\n```python\n# Melt the rating and rating_count using title, authors and publisher as identifiers\nbooks_ratings = books_gothic.melt(id_vars=['title', 'authors', 'publisher'], \n                                  value_vars=['rating', 'rating_count'])\n\n# Print books_ratings\nprint(books_ratings)\n\n                        title       authors          publisher      variable    value\n0           Wuthering Heights  Emily Bronte      Penguin Books        rating     3.85\n1                Frankenstein  Mary Shelley  Kaplan Publishing        rating     4.31\n2  The Picture of Dorian Gray   Oscar Wilde            Pearson        rating     4.15\n3           Wuthering Heights  Emily Bronte      Penguin Books  rating_count  2155.00\n4                Frankenstein  Mary Shelley  Kaplan Publishing  rating_count  2452.00\n5  The Picture of Dorian Gray   Oscar Wilde            Pearson  rating_count  3342.00\n\n\n# Assign the name feature to the new variable column\nbooks_ratings = books_gothic.melt(id_vars=['title', 'authors', 'publisher'], \n                                  value_vars=['rating', 'rating_count'], \n                                  var_name='feature')\n\n# Print books_ratings\nprint(books_ratings)\n\n\n                        title       authors          publisher       feature    value\n0           Wuthering Heights  Emily Bronte      Penguin Books        rating     3.85\n1                Frankenstein  Mary Shelley  Kaplan Publishing        rating     4.31\n2  The Picture of Dorian Gray   Oscar Wilde            Pearson        rating     4.15\n3           Wuthering Heights  Emily Bronte      Penguin Books  rating_count  2155.00\n4                Frankenstein  Mary Shelley  Kaplan Publishing  rating_count  2452.00\n5  The Picture of Dorian Gray   Oscar Wilde            Pearson  rating_count  3342.00\n\n# Assign the name number to the new column containing the values\nbooks_ratings = books_gothic.melt(id_vars=['title', 'authors', 'publisher'], \n                                  value_vars=['rating', 'rating_count'], \n                                  var_name='feature', \n                                  value_name='number')\n\n# Print books_ratings\nprint(books_ratings)\n\n                        title       authors          publisher       feature   number\n0           Wuthering Heights  Emily Bronte      Penguin Books        rating     3.85\n1                Frankenstein  Mary Shelley  Kaplan Publishing        rating     4.31\n2  The Picture of Dorian Gray   Oscar Wilde            Pearson        rating     4.15\n3           Wuthering Heights  Emily Bronte      Penguin Books  rating_count  2155.00\n4                Frankenstein  Mary Shelley  Kaplan Publishing  rating_count  2452.00\n5  The Picture of Dorian Gray   Oscar Wilde            Pearson  rating_count  3342.00\n```","metadata":{},"cell_type":"markdown","id":"14dc6ea9-2115-492b-80ca-03e005b2dc98"},{"source":"### Wide to Long Function\n![Screen Shot 2023-03-13 at 7.25.15 PM](Screen%20Shot%202023-03-13%20at%207.25.15%20PM.png)\n\n#### The golden age\nIn this exercise, you'll continue working on the book project. Now, you'll analyze books from the Golden Age.\n\nUpon inspection, you discovered that the dataset golden_age needs reshaping. You noticed that some column names start with the same prefix (stub names) and identified other columns to use as unique IDs.\n\nFor that reason, you'll reshape your DataFrame in several ways.","metadata":{},"cell_type":"markdown","id":"92c71e39-0b7f-4153-8717-695ac9253182"},{"source":"golden_age = pd.DataFrame({\n    'title':['The Great Gatsby', 'The Short Stories', 'To the Lighthouse'],\n    'authors':['F. Scott Fitzgerald', 'Ernest Hemingway', 'Virginia Woolf'],\n    'isbn13':[9780060098919, 9780684837864, 9780156030472],\n    'isbn10':[1572702567, 684837862, 156030470],\n    'prefix13':[978, 978, 978],\n    'prefix10':[1,0,0]\n})\ngolden_age","metadata":{"executionTime":169,"lastSuccessfullyExecutedCode":"golden_age = pd.DataFrame({\n    'title':['The Great Gatsby', 'The Short Stories', 'To the Lighthouse'],\n    'authors':['F. Scott Fitzgerald', 'Ernest Hemingway', 'Virginia Woolf'],\n    'isbn13':[9780060098919, 9780684837864, 9780156030472],\n    'isbn10':[1572702567, 684837862, 156030470],\n    'prefix13':[978, 978, 978],\n    'prefix10':[1,0,0]\n})\ngolden_age"},"cell_type":"code","id":"fd28275a-26a5-4326-a072-6b33ab092eef","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"application/com.datacamp.data-table.v1+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"title","type":"string"},{"name":"authors","type":"string"},{"name":"isbn13","type":"integer"},{"name":"isbn10","type":"integer"},{"name":"prefix13","type":"integer"},{"name":"prefix10","type":"integer"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":[{"index":0,"title":"The Great Gatsby","authors":"F. Scott Fitzgerald","isbn13":9780060098919,"isbn10":1572702567,"prefix13":978,"prefix10":1},{"index":1,"title":"The Short Stories","authors":"Ernest Hemingway","isbn13":9780684837864,"isbn10":684837862,"prefix13":978,"prefix10":0},{"index":2,"title":"To the Lighthouse","authors":"Virginia Woolf","isbn13":9780156030472,"isbn10":156030470,"prefix13":978,"prefix10":0}]},"total_rows":3,"truncation_type":null},"text/plain":"               title              authors  ...  prefix13  prefix10\n0   The Great Gatsby  F. Scott Fitzgerald  ...       978         1\n1  The Short Stories     Ernest Hemingway  ...       978         0\n2  To the Lighthouse       Virginia Woolf  ...       978         0\n\n[3 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>authors</th>\n      <th>isbn13</th>\n      <th>isbn10</th>\n      <th>prefix13</th>\n      <th>prefix10</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The Great Gatsby</td>\n      <td>F. Scott Fitzgerald</td>\n      <td>9780060098919</td>\n      <td>1572702567</td>\n      <td>978</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The Short Stories</td>\n      <td>Ernest Hemingway</td>\n      <td>9780684837864</td>\n      <td>684837862</td>\n      <td>978</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>To the Lighthouse</td>\n      <td>Virginia Woolf</td>\n      <td>9780156030472</td>\n      <td>156030470</td>\n      <td>978</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"source":"# Reshape wide to long using title as index and version as new name, and extracting isbn prefix \nisbn_long = pd.wide_to_long(golden_age,\n                           stubnames='isbn',\n                           i='title',\n                           j='version')\ndisplay(isbn_long)","metadata":{"executionTime":181,"lastSuccessfullyExecutedCode":"# Reshape wide to long using title as index and version as new name, and extracting isbn prefix \nisbn_long = pd.wide_to_long(golden_age,\n                           stubnames='isbn',\n                           i='title',\n                           j='version')\ndisplay(isbn_long)"},"cell_type":"code","id":"30a00bce-93eb-4305-8cb1-eca56975ab3c","execution_count":6,"outputs":[{"output_type":"display_data","data":{"application/com.datacamp.data-table.v1+json":{"table":{"schema":{"fields":[{"name":"title","type":"string"},{"name":"version","type":"integer"},{"name":"authors","type":"string"},{"name":"prefix13","type":"integer"},{"name":"prefix10","type":"integer"},{"name":"isbn","type":"integer"}],"primaryKey":["title","version"],"pandas_version":"1.4.0"},"data":[{"title":"The Great Gatsby","version":13,"authors":"F. Scott Fitzgerald","prefix13":978,"prefix10":1,"isbn":9780060098919},{"title":"The Short Stories","version":13,"authors":"Ernest Hemingway","prefix13":978,"prefix10":0,"isbn":9780684837864},{"title":"To the Lighthouse","version":13,"authors":"Virginia Woolf","prefix13":978,"prefix10":0,"isbn":9780156030472},{"title":"The Great Gatsby","version":10,"authors":"F. Scott Fitzgerald","prefix13":978,"prefix10":1,"isbn":1572702567},{"title":"The Short Stories","version":10,"authors":"Ernest Hemingway","prefix13":978,"prefix10":0,"isbn":684837862},{"title":"To the Lighthouse","version":10,"authors":"Virginia Woolf","prefix13":978,"prefix10":0,"isbn":156030470}]},"total_rows":6,"truncation_type":null},"text/plain":"                                       authors  ...           isbn\ntitle             version                       ...               \nThe Great Gatsby  13       F. Scott Fitzgerald  ...  9780060098919\nThe Short Stories 13          Ernest Hemingway  ...  9780684837864\nTo the Lighthouse 13            Virginia Woolf  ...  9780156030472\nThe Great Gatsby  10       F. Scott Fitzgerald  ...     1572702567\nThe Short Stories 10          Ernest Hemingway  ...      684837862\nTo the Lighthouse 10            Virginia Woolf  ...      156030470\n\n[6 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>authors</th>\n      <th>prefix13</th>\n      <th>prefix10</th>\n      <th>isbn</th>\n    </tr>\n    <tr>\n      <th>title</th>\n      <th>version</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>The Great Gatsby</th>\n      <th>13</th>\n      <td>F. Scott Fitzgerald</td>\n      <td>978</td>\n      <td>1</td>\n      <td>9780060098919</td>\n    </tr>\n    <tr>\n      <th>The Short Stories</th>\n      <th>13</th>\n      <td>Ernest Hemingway</td>\n      <td>978</td>\n      <td>0</td>\n      <td>9780684837864</td>\n    </tr>\n    <tr>\n      <th>To the Lighthouse</th>\n      <th>13</th>\n      <td>Virginia Woolf</td>\n      <td>978</td>\n      <td>0</td>\n      <td>9780156030472</td>\n    </tr>\n    <tr>\n      <th>The Great Gatsby</th>\n      <th>10</th>\n      <td>F. Scott Fitzgerald</td>\n      <td>978</td>\n      <td>1</td>\n      <td>1572702567</td>\n    </tr>\n    <tr>\n      <th>The Short Stories</th>\n      <th>10</th>\n      <td>Ernest Hemingway</td>\n      <td>978</td>\n      <td>0</td>\n      <td>684837862</td>\n    </tr>\n    <tr>\n      <th>To the Lighthouse</th>\n      <th>10</th>\n      <td>Virginia Woolf</td>\n      <td>978</td>\n      <td>0</td>\n      <td>156030470</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"source":"# Reshape wide to long using title and authors as index and version as new name, and prefix as stubnames \nprefix_long = pd.wide_to_long(golden_age, \n                              stubnames='prefix', \n                              i=['title', 'authors'], \n                              j='version')\n\n# Print prefix_long\ndisplay(prefix_long)\nprint(prefix_long.index) # notice how the suffix at the end of prefix is now held in the j column value for version","metadata":{"executionTime":184,"lastSuccessfullyExecutedCode":"# Reshape wide to long using title and authors as index and version as new name, and prefix as stubnames \nprefix_long = pd.wide_to_long(golden_age, \n                              stubnames='prefix', \n                              i=['title', 'authors'], \n                              j='version')\n\n# Print prefix_long\ndisplay(prefix_long)\nprint(prefix_long.index) # notice how the suffix at the end of prefix is now held in the j column value for version"},"cell_type":"code","id":"661fb238-df06-48a2-aba7-f3ec0875dbc9","execution_count":7,"outputs":[{"output_type":"display_data","data":{"application/com.datacamp.data-table.v1+json":{"table":{"schema":{"fields":[{"name":"title","type":"string"},{"name":"authors","type":"string"},{"name":"version","type":"integer"},{"name":"isbn10","type":"integer"},{"name":"isbn13","type":"integer"},{"name":"prefix","type":"integer"}],"primaryKey":["title","authors","version"],"pandas_version":"1.4.0"},"data":[{"title":"The Great Gatsby","authors":"F. Scott Fitzgerald","version":13,"isbn10":1572702567,"isbn13":9780060098919,"prefix":978},{"title":"The Great Gatsby","authors":"F. Scott Fitzgerald","version":10,"isbn10":1572702567,"isbn13":9780060098919,"prefix":1},{"title":"The Short Stories","authors":"Ernest Hemingway","version":13,"isbn10":684837862,"isbn13":9780684837864,"prefix":978},{"title":"The Short Stories","authors":"Ernest Hemingway","version":10,"isbn10":684837862,"isbn13":9780684837864,"prefix":0},{"title":"To the Lighthouse","authors":"Virginia Woolf","version":13,"isbn10":156030470,"isbn13":9780156030472,"prefix":978},{"title":"To the Lighthouse","authors":"Virginia Woolf","version":10,"isbn10":156030470,"isbn13":9780156030472,"prefix":0}]},"total_rows":6,"truncation_type":null},"text/plain":"                                                   isbn10  ...  prefix\ntitle             authors             version              ...        \nThe Great Gatsby  F. Scott Fitzgerald 13       1572702567  ...     978\n                                      10       1572702567  ...       1\nThe Short Stories Ernest Hemingway    13        684837862  ...     978\n                                      10        684837862  ...       0\nTo the Lighthouse Virginia Woolf      13        156030470  ...     978\n                                      10        156030470  ...       0\n\n[6 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>isbn10</th>\n      <th>isbn13</th>\n      <th>prefix</th>\n    </tr>\n    <tr>\n      <th>title</th>\n      <th>authors</th>\n      <th>version</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">The Great Gatsby</th>\n      <th rowspan=\"2\" valign=\"top\">F. Scott Fitzgerald</th>\n      <th>13</th>\n      <td>1572702567</td>\n      <td>9780060098919</td>\n      <td>978</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1572702567</td>\n      <td>9780060098919</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">The Short Stories</th>\n      <th rowspan=\"2\" valign=\"top\">Ernest Hemingway</th>\n      <th>13</th>\n      <td>684837862</td>\n      <td>9780684837864</td>\n      <td>978</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>684837862</td>\n      <td>9780684837864</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">To the Lighthouse</th>\n      <th rowspan=\"2\" valign=\"top\">Virginia Woolf</th>\n      <th>13</th>\n      <td>156030470</td>\n      <td>9780156030472</td>\n      <td>978</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>156030470</td>\n      <td>9780156030472</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"stream","name":"stdout","text":"MultiIndex([( 'The Great Gatsby', 'F. Scott Fitzgerald', 13),\n            ( 'The Great Gatsby', 'F. Scott Fitzgerald', 10),\n            ('The Short Stories',    'Ernest Hemingway', 13),\n            ('The Short Stories',    'Ernest Hemingway', 10),\n            ('To the Lighthouse',      'Virginia Woolf', 13),\n            ('To the Lighthouse',      'Virginia Woolf', 10)],\n           names=['title', 'authors', 'version'])\n"}]},{"source":"# Reshape wide to long using title and authors as index and version as new name, and prefix and isbn as wide column prefixes\nall_long = pd.wide_to_long(golden_age, \n                   stubnames=['isbn', 'prefix'], \n                   i=['title', 'authors'], \n                   j='version')\n\n# Print all_long\ndisplay(all_long)","metadata":{"executionTime":596,"lastSuccessfullyExecutedCode":"# Reshape wide to long using title and authors as index and version as new name, and prefix and isbn as wide column prefixes\nall_long = pd.wide_to_long(golden_age, \n                   stubnames=['isbn', 'prefix'], \n                   i=['title', 'authors'], \n                   j='version')\n\n# Print all_long\ndisplay(all_long)"},"cell_type":"code","id":"45dbb7e6-aab8-48e9-969a-d4bd0d129771","execution_count":8,"outputs":[{"output_type":"display_data","data":{"application/com.datacamp.data-table.v1+json":{"table":{"schema":{"fields":[{"name":"title","type":"string"},{"name":"authors","type":"string"},{"name":"version","type":"integer"},{"name":"isbn","type":"integer"},{"name":"prefix","type":"integer"}],"primaryKey":["title","authors","version"],"pandas_version":"1.4.0"},"data":[{"title":"The Great Gatsby","authors":"F. Scott Fitzgerald","version":13,"isbn":9780060098919,"prefix":978},{"title":"The Great Gatsby","authors":"F. Scott Fitzgerald","version":10,"isbn":1572702567,"prefix":1},{"title":"The Short Stories","authors":"Ernest Hemingway","version":13,"isbn":9780684837864,"prefix":978},{"title":"The Short Stories","authors":"Ernest Hemingway","version":10,"isbn":684837862,"prefix":0},{"title":"To the Lighthouse","authors":"Virginia Woolf","version":13,"isbn":9780156030472,"prefix":978},{"title":"To the Lighthouse","authors":"Virginia Woolf","version":10,"isbn":156030470,"prefix":0}]},"total_rows":6,"truncation_type":null},"text/plain":"                                                        isbn  prefix\ntitle             authors             version                       \nThe Great Gatsby  F. Scott Fitzgerald 13       9780060098919     978\n                                      10          1572702567       1\nThe Short Stories Ernest Hemingway    13       9780684837864     978\n                                      10           684837862       0\nTo the Lighthouse Virginia Woolf      13       9780156030472     978\n                                      10           156030470       0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>isbn</th>\n      <th>prefix</th>\n    </tr>\n    <tr>\n      <th>title</th>\n      <th>authors</th>\n      <th>version</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">The Great Gatsby</th>\n      <th rowspan=\"2\" valign=\"top\">F. Scott Fitzgerald</th>\n      <th>13</th>\n      <td>9780060098919</td>\n      <td>978</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1572702567</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">The Short Stories</th>\n      <th rowspan=\"2\" valign=\"top\">Ernest Hemingway</th>\n      <th>13</th>\n      <td>9780684837864</td>\n      <td>978</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>684837862</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">To the Lighthouse</th>\n      <th rowspan=\"2\" valign=\"top\">Virginia Woolf</th>\n      <th>13</th>\n      <td>9780156030472</td>\n      <td>978</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>156030470</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"source":"#### Decrypting the code\nYou are doing a great job on the book project! Your boss encouraged you to do an analysis using books written by Dan Brown.\n\nYou explored the dataset books_brown and it needs reshaping. Again, you identified several columns to use as unique IDs and realized something different about the columns to group. Their name starts with a prefix, but this time, you identified a suffix and a separation element.\n\n```python\n\nbooks_brown\nOut[2]:\n\n                  title     author  language_code language_name  publisher_code publisher_name\n0     The Da Vinci Code  Dan Brown              0       english              12   Random House\n1       Angels & Demons  Dan Brown              0       english              34   Pocket Books\n2  La fortaleza digital  Dan Brown             84       spanish              43        Umbriel\n\n# Specify that wide columns have a suffix containing words\nthe_code_long = pd.wide_to_long(books_brown, \n                                stubnames=['language', 'publisher'], \n                                i=['author', 'title'], \n                                j='code', \n                                sep='_', \n                                suffix='\\w+')\n\n# Print the_code_long\nprint(the_code_long)\n\n                                   language     publisher\nauthor    title                code                       \nDan Brown The Da Vinci Code    code        0            12\n                               name  english  Random House\n          Angels & Demons      code        0            34\n                               name  english  Pocket Books\n          La fortaleza digital code       84            43\n                               name  spanish       Umbriel\n```\n* Notice how you needed to specify the separating elements. When you didn't do that, pandas didn't recognize the column names and returned an empty DataFrame. Also, wide_to_long() always assumes that suffixes are numeric, so don't forget to specify if they are not!","metadata":{},"cell_type":"markdown","id":"183f685b-f111-415b-bc42-9cbb4ef8de74"},{"source":"#### Time to read, Katniss!\nIt's almost time to finish working for the day. But first, you would like to do an analysis for fun. You will analyze another book dataset, this time with the Hunger Games series.\n\nYou explored the dataset books_hunger before reshaping it, but something was not right. The index of the DataFrame contains the title of the books. You know that you cannot reshape it in this format. If you do, you will lose valuable data, the title, so you'll need to make some changes before transforming the DataFrame.\n\n```python\nIn [1]:\nbooks_hunger\nOut[1]:\n\n                       language publication date  publication number  page number\ntitle                                                                            \nLos Juegos del Hambre   Spanish        5/25/2010                   2          374\nCatching Fire           English        5/25/2012                   6          391\nIl canto della rivolta  Italian         6/8/2015                   4          390\n\n# Modify books_hunger by resetting the index without dropping it (send title value index to column)\nbooks_hunger.reset_index(drop=False, inplace=True)\n\nprint(books_hunger, '\\n')\n\n# Reshape using title and language as index, feature as new name, publication and page as prefix separated by space and ending in a word\npublication_features = pd.wide_to_long(books_hunger, \n                                       stubnames=['publication', 'page'], \n                                       i=['title', 'language'], \n                                       j='feature', \n                                       sep=' ', \n                                       suffix='\\w+')\n\n# # Print publication_features\nprint(publication_features)\n\n# First print out\n                    title language publication date  publication number  page number\n0   Los Juegos del Hambre  Spanish        5/25/2010                   2          374\n1           Catching Fire  English        5/25/2012                   6          391\n2  Il canto della rivolta  Italian         6/8/2015                   4          390 \n\n# second print out     \n\ntitle                  language feature   publication page             \nLos Juegos del Hambre  Spanish  date      5/25/2010    NaN\n                                number            2  374.0\nCatching Fire          English  date      5/25/2012    NaN\n                                number            6  391.0\nIl canto della rivolta Italian  date       6/8/2015    NaN\n                                number            4  390.0\n```\n* You will always need to reset the index of a DataFrame if you want to keep it after applying wide_to_long(). Also, notice that missing values appear if you don't have a column for a particular prefix and suffix combination.","metadata":{},"cell_type":"markdown","id":"1f843d99-f2a0-43e5-9a13-e56fd6c96990"},{"source":"### String Columns Concat/Molding\n#### Did you say dystopia?\nAnother day at work, another day working with your book project! You are very excited because you have been making a lot of progress. You plan to work on a dataset about dystopian fiction books.\n\nBut first, you need to do some string manipulations. You realize that the DataFrame index contains data about the title and the release year. You can't find a column with the author of the book, so you decide to pre-define a list of the writers. Then, you want to delete the year and replace it with the author.\n\nYou decide that splitting the index and then concatenating it with the list is the best way to do it.","metadata":{},"cell_type":"markdown","id":"1b06463c-b681-46e1-924a-bba1eabcabc2"},{"source":"books_dys = pd.DataFrame({\n    'title':['Fahrenheit 451-1953', '1984-1949', 'Brave New World-1932'],\n    'year':[1953,1949,1932],\n    'num_pages':[186,268,123],\n    'average_rating':[4.10,4.31,4.30],\n    'ratings_count':[23244, 14353, 23535]\n})\nbooks_dys = books_dys.set_index('title')\ndisplay(books_dys)","metadata":{"executionTime":124,"lastSuccessfullyExecutedCode":"books_dys = pd.DataFrame({\n    'title':['Fahrenheit 451-1953', '1984-1949', 'Brave New World-1932'],\n    'year':[1953,1949,1932],\n    'num_pages':[186,268,123],\n    'average_rating':[4.10,4.31,4.30],\n    'ratings_count':[23244, 14353, 23535]\n})\nbooks_dys = books_dys.set_index('title')\ndisplay(books_dys)"},"cell_type":"code","id":"c75369cb-cbe2-450c-afe6-a0bddd52e3f8","execution_count":9,"outputs":[{"output_type":"display_data","data":{"application/com.datacamp.data-table.v1+json":{"table":{"schema":{"fields":[{"name":"title","type":"string"},{"name":"year","type":"integer"},{"name":"num_pages","type":"integer"},{"name":"average_rating","type":"number"},{"name":"ratings_count","type":"integer"}],"primaryKey":["title"],"pandas_version":"1.4.0"},"data":[{"title":"Fahrenheit 451-1953","year":1953,"num_pages":186,"average_rating":4.1,"ratings_count":23244},{"title":"1984-1949","year":1949,"num_pages":268,"average_rating":4.31,"ratings_count":14353},{"title":"Brave New World-1932","year":1932,"num_pages":123,"average_rating":4.3,"ratings_count":23535}]},"total_rows":3,"truncation_type":null},"text/plain":"                      year  num_pages  average_rating  ratings_count\ntitle                                                               \nFahrenheit 451-1953   1953        186            4.10          23244\n1984-1949             1949        268            4.31          14353\nBrave New World-1932  1932        123            4.30          23535","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>year</th>\n      <th>num_pages</th>\n      <th>average_rating</th>\n      <th>ratings_count</th>\n    </tr>\n    <tr>\n      <th>title</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Fahrenheit 451-1953</th>\n      <td>1953</td>\n      <td>186</td>\n      <td>4.10</td>\n      <td>23244</td>\n    </tr>\n    <tr>\n      <th>1984-1949</th>\n      <td>1949</td>\n      <td>268</td>\n      <td>4.31</td>\n      <td>14353</td>\n    </tr>\n    <tr>\n      <th>Brave New World-1932</th>\n      <td>1932</td>\n      <td>123</td>\n      <td>4.30</td>\n      <td>23535</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"source":"# Split the index of books_dys by the hyphen \nbooks_dys.index = books_dys.index.str.split('-')\nprint(books_dys)","metadata":{"executionTime":84,"lastSuccessfullyExecutedCode":"# Split the index of books_dys by the hyphen \nbooks_dys.index = books_dys.index.str.split('-')\nprint(books_dys)"},"cell_type":"code","id":"6c6e06b7-aa68-4210-85dd-f21670ccda38","execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":"                         year  num_pages  average_rating  ratings_count\ntitle                                                                  \n[Fahrenheit 451, 1953]   1953        186            4.10          23244\n[1984, 1949]             1949        268            4.31          14353\n[Brave New World, 1932]  1932        123            4.30          23535\n"}]},{"source":"# Get the first element after splitting the index of books_dys\nbooks_dys.index = books_dys.index.str.get(0)\n\n# Print books_dys\nprint(books_dys)","metadata":{"executionTime":98,"lastSuccessfullyExecutedCode":"# Get the first element after splitting the index of books_dys\nbooks_dys.index = books_dys.index.str.get(0)\n\n# Print books_dys\nprint(books_dys)"},"cell_type":"code","id":"3ed871d6-58d1-443b-9bdc-392b37b2a8a5","execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":"                 year  num_pages  average_rating  ratings_count\ntitle                                                          \nFahrenheit 451   1953        186            4.10          23244\n1984             1949        268            4.31          14353\nBrave New World  1932        123            4.30          23535\n"}]},{"source":"# Values to concatenate index with\nauthor_list = ['Ray Bradbury', 'George Orwell', 'Aldous Huxley']\n\n# Concatenate the index with the list author_list separated by a hyphen\nbooks_dys.index = books_dys.index.str.cat(author_list, sep='-')\n\n# Print books_dys\ndisplay(books_dys)","metadata":{"executionTime":98,"lastSuccessfullyExecutedCode":"# Values to concatenate index with\nauthor_list = ['Ray Bradbury', 'George Orwell', 'Aldous Huxley']\n\n# Concatenate the index with the list author_list separated by a hyphen\nbooks_dys.index = books_dys.index.str.cat(author_list, sep='-')\n\n# Print books_dys\ndisplay(books_dys)"},"cell_type":"code","id":"a013b498-20d2-43e3-a6e8-e33984fdd4f1","execution_count":12,"outputs":[{"output_type":"display_data","data":{"application/com.datacamp.data-table.v1+json":{"table":{"schema":{"fields":[{"name":"title","type":"string"},{"name":"year","type":"integer"},{"name":"num_pages","type":"integer"},{"name":"average_rating","type":"number"},{"name":"ratings_count","type":"integer"}],"primaryKey":["title"],"pandas_version":"1.4.0"},"data":[{"title":"Fahrenheit 451-Ray Bradbury","year":1953,"num_pages":186,"average_rating":4.1,"ratings_count":23244},{"title":"1984-George Orwell","year":1949,"num_pages":268,"average_rating":4.31,"ratings_count":14353},{"title":"Brave New World-Aldous Huxley","year":1932,"num_pages":123,"average_rating":4.3,"ratings_count":23535}]},"total_rows":3,"truncation_type":null},"text/plain":"                               year  num_pages  average_rating  ratings_count\ntitle                                                                        \nFahrenheit 451-Ray Bradbury    1953        186            4.10          23244\n1984-George Orwell             1949        268            4.31          14353\nBrave New World-Aldous Huxley  1932        123            4.30          23535","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>year</th>\n      <th>num_pages</th>\n      <th>average_rating</th>\n      <th>ratings_count</th>\n    </tr>\n    <tr>\n      <th>title</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Fahrenheit 451-Ray Bradbury</th>\n      <td>1953</td>\n      <td>186</td>\n      <td>4.10</td>\n      <td>23244</td>\n    </tr>\n    <tr>\n      <th>1984-George Orwell</th>\n      <td>1949</td>\n      <td>268</td>\n      <td>4.31</td>\n      <td>14353</td>\n    </tr>\n    <tr>\n      <th>Brave New World-Aldous Huxley</th>\n      <td>1932</td>\n      <td>123</td>\n      <td>4.30</td>\n      <td>23535</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"source":"* The str attribute of pandas makes it easy to work with strings, even when they are in the index, which is something that would be very difficult to handle otherwise!","metadata":{},"cell_type":"markdown","id":"d928c666-3a2b-4632-8f9b-48538f4a21ce"},{"source":"### What's your rating, Harry?\nYou fix yourself a coffee and keep working on your book project. For your next task, you need to get an appropriate dataset containing ratings for all the Harry Potter books. You gathered data from Goodreads as well as from Amazon.\n\nYou realized that you need a long format, but the dataset hp_books is in a wide format. You want to melt the data, but first, you need to manipulate some of the string columns.\n\n```python\nIn [1]:\nhp_books\nOut[1]:\n\n          title                   subtitle                     authors  goodreads  amazon\n0  Harry Potter     the Half-Blood Prince   J.K. Rowling/Mary GrandPrÃ©       4.57    4.52\n1  Harry Potter  the Order of the Phoenix   J.K. Rowling/Mary GrandPrÃ©       4.49    4.44\n2  Harry Potter    the Chamber of Secrets                 J.K. Rowling       4.42    4.37\n3  Harry Potter   the Prisoner of Azkaban   J.K. Rowling/Mary GrandPrÃ©       4.56    4.51\n4  Harry Potter        The Deathly Hallows  J.K. Rowling/Mary GrandPrÃ©       4.42    4.37\n5  Harry Potter      the Sorcerer's Stone   J.K. Rowling/Mary GrandPrÃ©       4.47    4.42\n6  Harry Potter        the Goblet of Fire                 J.K. Rowling       4.56    4.51\n```\n\n* Concatenate two columns\n```python\n# Concatenate the title and subtitle separated by \"and\" surrounded by spaces\nhp_books['full_title'] = hp_books['title'].str.cat(hp_books['subtitle'], sep =' and ') \n\n# Print hp_books\nprint(hp_books)\n\n\n          title                   subtitle                     authors  goodreads  amazon                                 full_title\n0  Harry Potter     the Half-Blood Prince   J.K. Rowling/Mary GrandPrÃ©       4.57    4.52     Harry Potter and the Half-Blood Prince \n1  Harry Potter  the Order of the Phoenix   J.K. Rowling/Mary GrandPrÃ©       4.49    4.44  Harry Potter and the Order of the Phoenix \n2  Harry Potter    the Chamber of Secrets                 J.K. Rowling       4.42    4.37    Harry Potter and the Chamber of Secrets \n3  Harry Potter   the Prisoner of Azkaban   J.K. Rowling/Mary GrandPrÃ©       4.56    4.51   Harry Potter and the Prisoner of Azkaban \n4  Harry Potter        The Deathly Hallows  J.K. Rowling/Mary GrandPrÃ©       4.42    4.37        Harry Potter and The Deathly Hallows\n5  Harry Potter      the Sorcerer's Stone   J.K. Rowling/Mary GrandPrÃ©       4.47    4.42      Harry Potter and the Sorcerer's Stone \n6  Harry Potter        the Goblet of Fire                 J.K. Rowling       4.56    4.51        Harry Potter and the Goblet of Fire \n```\n\n* Split the authors into writer and illustrator columns\n\n```python\n# Split the authors into writer and illustrator columns\nhp_books[['writer', 'illustrator']] = hp_books['authors'].str.split('/', expand=True) \n\n# Print hp_books\nprint(hp_books)\n          title                   subtitle                     authors  goodreads  amazon                             full_title        writer    illustrator\n0  Harry Potter     the Half-Blood Prince   J.K. Rowling/Mary GrandPrÃ©       4.57    4.52     Harry Potter and the Half-Blood Prince   J.K. Rowling  Mary GrandPrÃ©\n1  Harry Potter  the Order of the Phoenix   J.K. Rowling/Mary GrandPrÃ©       4.49    4.44  Harry Potter and the Order of the Phoenix   J.K. Rowling  Mary GrandPrÃ©\n2  Harry Potter    the Chamber of Secrets                 J.K. Rowling       4.42    4.37    Harry Potter and the Chamber of Secrets   J.K. Rowling           None\n3  Harry Potter   the Prisoner of Azkaban   J.K. Rowling/Mary GrandPrÃ©       4.56    4.51   Harry Potter and the Prisoner of Azkaban   J.K. Rowling  Mary GrandPrÃ©\n4  Harry Potter        The Deathly Hallows  J.K. Rowling/Mary GrandPrÃ©       4.42    4.37        Harry Potter and The Deathly Hallows  J.K. Rowling  Mary GrandPrÃ©\n5  Harry Potter      the Sorcerer's Stone   J.K. Rowling/Mary GrandPrÃ©       4.47    4.42      Harry Potter and the Sorcerer's Stone   J.K. Rowling  Mary GrandPrÃ©\n6  Harry Potter        the Goblet of Fire                 J.K. Rowling       4.56    4.51        Harry Potter and the Goblet of Fire   J.K. Rowling           None\n```\n\n* Melt goodreads/Amazon into single column\n    * Define a DataFrame hp_melt by melting the goodreads and amazon columns into a single column named source. Assign the name rating to the resulting value column. Use only the full title and the writer as identifier variables. \n\n```python\n# Melt goodreads and amazon columns into a single column\nhp_melt = hp_books.melt(id_vars=['full_title', 'writer'], \n                        var_name='source', \n                        value_vars=['goodreads', 'amazon'], \n                        value_name='rating')\n\n# Print hp_melt\nprint(hp_melt)\n\n                                    full_title        writer     source  rating\n0      Harry Potter and the Half-Blood Prince   J.K. Rowling  goodreads    4.57\n1   Harry Potter and the Order of the Phoenix   J.K. Rowling  goodreads    4.49\n2     Harry Potter and the Chamber of Secrets   J.K. Rowling  goodreads    4.42\n3    Harry Potter and the Prisoner of Azkaban   J.K. Rowling  goodreads    4.56\n4         Harry Potter and The Deathly Hallows  J.K. Rowling  goodreads    4.42\n5       Harry Potter and the Sorcerer's Stone   J.K. Rowling  goodreads    4.47\n6         Harry Potter and the Goblet of Fire   J.K. Rowling  goodreads    4.56\n7      Harry Potter and the Half-Blood Prince   J.K. Rowling     amazon    4.52\n8   Harry Potter and the Order of the Phoenix   J.K. Rowling     amazon    4.44\n9     Harry Potter and the Chamber of Secrets   J.K. Rowling     amazon    4.37\n10   Harry Potter and the Prisoner of Azkaban   J.K. Rowling     amazon    4.51\n11        Harry Potter and The Deathly Hallows  J.K. Rowling     amazon    4.37\n12      Harry Potter and the Sorcerer's Stone   J.K. Rowling     amazon    4.42\n13        Harry Potter and the Goblet of Fire   J.K. Rowling     amazon    4.51\n```\n* `melt` quickly condenses (think var_name as `title` of collapsed columns to long format) and value_name as what value the collapsed column is ","metadata":{},"cell_type":"markdown","id":"a46fc241-0eb2-4f41-84d3-159bd32a6473"},{"source":"### Elementary, dear Watson!\nIt's Friday, and you are about to finish working on your book project. For your last task, you will analyze data about Arthur Conan Doyle's books.\n\nYou realize your dataset, books_sh, needs reshaping. You notice there are columns that can be grouped using a prefix. You identify the columns to use as unique IDs. However, some of these columns contain strings. They need some manipulation before applying a wide to long transformation. You decide some of the strings need splitting to make the DataFrame cleaner.\n\n* Original DataFrame\n```python\nIn [1]:\nbooks_sh\nOut[1]:\n\n                               main_title version  number_pages  number_ratings\n0    Sherlock Holmes: The Complete Novels   Vol I          1059           24087\n1    Sherlock Holmes: The Complete Novels  Vol II           709           26794\n2  Adventures of Sherlock Holmes: Memoirs   Vol I           334            2184\n3  Adventures of Sherlock Holmes: Memoirs  Vol II           238            1884\n```\n* Resulting work\n```python\n# Split main_title by a colon and assign it to two columns named title and subtitle \nbooks_sh[['title', 'subtitle']] = books_sh['main_title'].str.split(':', expand=True)\n\n# Split version by a space and assign the second element to the column named volume \nbooks_sh['volume'] = books_sh['version'].str.split(' ').str.get(1)\n\n# Drop the main_title and version columns modifying books_sh\nbooks_sh.drop(['main_title', 'version'], axis=1, inplace=True)\n\n# Reshape using title, subtitle and volume as index, name feature the new variable from columns starting with number, separated by undescore and ending in words \nsh_long = pd.wide_to_long(books_sh, stubnames='number', i=['title', 'subtitle', 'volume'], \n                  j='feature', sep='_', suffix='\\w+')\n\n# Print sh_long \nprint(sh_long)\n\n                                                                   number\ntitle                         subtitle             volume feature        \nSherlock Holmes                The Complete Novels I      pages      1059\n                                                          ratings   24087\n                                                   II     pages       709\n                                                          ratings   26794\nAdventures of Sherlock Holmes  Memoirs             I      pages       334\n                                                          ratings    2184\n                                                   II     pages       238\n                                                          ratings    1884\n```","metadata":{},"cell_type":"markdown","id":"ab622c34-95d3-4226-bd31-3031ea0796c3"},{"source":"<br>\n\n## Stacking and unstacking DataFrames\n\nIn this chapter, youâ€™ll level-up your data manipulation skills using multi-level indexing. You'll learn how to reshape DataFrames by rearranging levels of the row indexes to the column axis, or vice versa. You'll also gain the skills you need to handle missing data generated in the stacking and unstacking process","metadata":{},"cell_type":"markdown","id":"a5657f2b-8cd1-425d-a242-9f9d46bf8e12"},{"source":"churn = pd.DataFrame({\n    'Area code' : [408,408,415,510],\n    'total_day_calls':[116,109,84,67],\n    'total_day_minutes':[204,287,84,50]\n})\nchurn","metadata":{"executionTime":102,"lastSuccessfullyExecutedCode":"churn = pd.DataFrame({\n    'Area code' : [408,408,415,510],\n    'total_day_calls':[116,109,84,67],\n    'total_day_minutes':[204,287,84,50]\n})\nchurn"},"cell_type":"code","id":"8bfb9fe9-6310-4e39-85bb-93f51b97b9bf","execution_count":13,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"application/com.datacamp.data-table.v1+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"Area code","type":"integer"},{"name":"total_day_calls","type":"integer"},{"name":"total_day_minutes","type":"integer"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":[{"index":0,"Area code":408,"total_day_calls":116,"total_day_minutes":204},{"index":1,"Area code":408,"total_day_calls":109,"total_day_minutes":287},{"index":2,"Area code":415,"total_day_calls":84,"total_day_minutes":84},{"index":3,"Area code":510,"total_day_calls":67,"total_day_minutes":50}]},"total_rows":4,"truncation_type":null},"text/plain":"   Area code  total_day_calls  total_day_minutes\n0        408              116                204\n1        408              109                287\n2        415               84                 84\n3        510               67                 50","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Area code</th>\n      <th>total_day_calls</th>\n      <th>total_day_minutes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>408</td>\n      <td>116</td>\n      <td>204</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>408</td>\n      <td>109</td>\n      <td>287</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>415</td>\n      <td>84</td>\n      <td>84</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>510</td>\n      <td>67</td>\n      <td>50</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"source":"# Predefined list to use as index\nnew_index = [['California', 'California', 'New York', 'Ohio'], \n             ['Los Angeles', 'San Francisco', 'New York', 'Cleveland']]\n\n# Create a multi-level index using predefined new_index\nchurn_new = pd.MultiIndex.from_arrays(new_index, names=['state', 'city'])\n\n# Print churn_new\nprint(churn_new)","metadata":{"executionTime":90,"lastSuccessfullyExecutedCode":"# Predefined list to use as index\nnew_index = [['California', 'California', 'New York', 'Ohio'], \n             ['Los Angeles', 'San Francisco', 'New York', 'Cleveland']]\n\n# Create a multi-level index using predefined new_index\nchurn_new = pd.MultiIndex.from_arrays(new_index, names=['state', 'city'])\n\n# Print churn_new\nprint(churn_new)"},"cell_type":"code","id":"32a3fdbf-4e3a-4a3f-b66e-14b3a2c84177","execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":"MultiIndex([('California',   'Los Angeles'),\n            ('California', 'San Francisco'),\n            (  'New York',      'New York'),\n            (      'Ohio',     'Cleveland')],\n           names=['state', 'city'])\n"}]},{"source":"# Assign the new index to the churn index\nchurn.index = churn_new\n\n# Print churn\nprint(churn)","metadata":{"executionTime":104,"lastSuccessfullyExecutedCode":"# Assign the new index to the churn index\nchurn.index = churn_new\n\n# Print churn\nprint(churn)"},"cell_type":"code","id":"abaaa23e-c9d9-4bd9-8811-5d74cef27e87","execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":"                          Area code  total_day_calls  total_day_minutes\nstate      city                                                        \nCalifornia Los Angeles          408              116                204\n           San Francisco        408              109                287\nNew York   New York             415               84                 84\nOhio       Cleveland            510               67                 50\n"}]},{"source":"# Reshape by stacking churn DataFrame\nchurn_stack = churn.stack()\n\n# Print churn_stack\ndisplay(churn_stack)","metadata":{"executionTime":76,"lastSuccessfullyExecutedCode":"# Reshape by stacking churn DataFrame\nchurn_stack = churn.stack()\n\n# Print churn_stack\ndisplay(churn_stack)"},"cell_type":"code","id":"80ecdd5e-5157-4275-a96f-c5dbde685bd6","execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"state       city                            \nCalifornia  Los Angeles    Area code            408\n                           total_day_calls      116\n                           total_day_minutes    204\n            San Francisco  Area code            408\n                           total_day_calls      109\n                           total_day_minutes    287\nNew York    New York       Area code            415\n                           total_day_calls       84\n                           total_day_minutes     84\nOhio        Cleveland      Area code            510\n                           total_day_calls       67\n                           total_day_minutes     50\ndtype: int64"},"metadata":{}}]},{"source":"churn_stack.index","metadata":{"executionTime":87,"lastSuccessfullyExecutedCode":"churn_stack.index"},"cell_type":"code","id":"6cd0c7bf-aec9-4c00-8c4a-87410d97c665","execution_count":17,"outputs":[{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"MultiIndex([('California',   'Los Angeles',         'Area code'),\n            ('California',   'Los Angeles',   'total_day_calls'),\n            ('California',   'Los Angeles', 'total_day_minutes'),\n            ('California', 'San Francisco',         'Area code'),\n            ('California', 'San Francisco',   'total_day_calls'),\n            ('California', 'San Francisco', 'total_day_minutes'),\n            (  'New York',      'New York',         'Area code'),\n            (  'New York',      'New York',   'total_day_calls'),\n            (  'New York',      'New York', 'total_day_minutes'),\n            (      'Ohio',     'Cleveland',         'Area code'),\n            (      'Ohio',     'Cleveland',   'total_day_calls'),\n            (      'Ohio',     'Cleveland', 'total_day_minutes')],\n           names=['state', 'city', None])"},"metadata":{}}]},{"source":"* If no level given to **stack** it will condense all available columns and create a new index/row for each column value under its' parent Multi-Index (for example above)\n\n#### Phone directory index\nAfter reshaping the dataset, you sent it to your colleagues and asked them to fill in some data. Now, they sent the new churn dataset back and you realized that its shape has changed.\n\nBefore you go on, you need to do some reshaping again. The dataset contains a multi-level index in the columns. You'd like to have some columns set as the row index. Also, this time you will only stack some levels. You believe it will help you discover some patterns in the data.\n\nThe DataFrame churn is available for you. It contains data about state, city, total_day_calls and total_day_minutes during day and night time\n\n* state of churn \n```python\nIn [1]:\nchurn\nOut[1]:\n\n        state           city       night                       day              \n                             total calls total minutes total calls total minutes\n0  California    Los Angeles         116           204          85           107\n1  California  San Francisco         109           287          90           167\n2    New York       New York          84            84          75            90\n3        Ohio      Cleveland          67            50          67           110\nIn [2]:\nchurn.columns\nOut[2]:\n\nMultiIndex([('state',              ''),\n            ( 'city',              ''),\n            ('night',   'total calls'),\n            ('night', 'total minutes'),\n            (  'day',   'total calls'),\n            (  'day', 'total minutes')],\n           )\n\n```\n\n```python\n# Set state and city as index modifying the DataFrame\nchurn.set_index(['state', 'city'], inplace=True)\n\n# Print churn\nprint(churn)\n                               night                       day              \n                         total calls total minutes total calls total minutes\nstate      city                                                             \nCalifornia Los Angeles           116           204          85           107\n           San Francisco         109           287          90           167\nNew York   New York               84            84          75            90\nOhio       Cleveland              67            50          67           110\n```\n\n* Stack second column level\n```python\n# Reshape by stacking the second level\nchurn_stack = churn.stack(level=1)\n\n# Print churn_stack\nprint(churn_stack)\n\n                                        day  night\nstate      city                                   \nCalifornia Los Angeles   total calls     85    116\n                         total minutes  107    204\n           San Francisco total calls     90    109\n                         total minutes  167    287\nNew York   New York      total calls     75     84\n                         total minutes   90     84\nOhio       Cleveland     total calls     67     67\n                         total minutes  110     50\n```","metadata":{},"cell_type":"markdown","id":"e5d41e4a-8ad7-4846-9541-461c7e7981e3"},{"source":"#### Text me!\nYou are making progress in your customer's project. Now, you need to analyze a new dataset to find differences in the messages and gigabytes (GB) of data the customers use during the daytime and nighttime.\n\nTo that aim, you will reshape your dataset churn using different levels. The advantage of your new dataset is that the column indices have names.\n\nThe DataFrame churn is available for you. It contains data about state, city, text messages and total GB during day and night time.\n\n* churn dataframe for exercise\n```python\nIn [1]:\nchurn\nOut[1]:\n\ntime                               day                  night         \nfeature                  text messages total GB text messages total GB\nstate      city                                                       \nCalifornia Los Angeles              20        5            30       10\n           San Francisco            40        5           100        5\nNew York   New York                 50        2            20        9\nOhio       Cleveland               100        3            40        6\n\nIn [2]:\nchurn.columns \nOut[2]:\n\nMultiIndex([(  'day', 'text messages'),\n            (  'day',      'total GB'),\n            ('night', 'text messages'),\n            ('night',      'total GB')],\n           names=['time', 'feature'])\n```\n\n```python\n# Stack churn by the time column level (remember the level starts at zero for the column we're stacking into index)\nchurn_time = churn.stack(level=0)\n\n# Print churn_time\nprint(churn_time)\n\nfeature                         text messages  total GB\nstate      city          time                          \nCalifornia Los Angeles   day               20         5\n                         night             30        10\n           San Francisco day               40         5\n                         night            100         5\nNew York   New York      day               50         2\n                         night             20         9\nOhio       Cleveland     day              100         3\n                         night             40         6\n```\n\n* feature stacking for column multi-index\n```python\n# Stack churn by the feature column level\nchurn_feature = churn.stack(level=1)\n\n# Print churn_feature\nprint(churn_feature)\n\n\ntime                                    day  night\nstate      city          feature                  \nCalifornia Los Angeles   text messages   20     30\n                         total GB         5     10\n           San Francisco text messages   40    100\n                         total GB         5      5\nNew York   New York      text messages   50     20\n                         total GB         2      9\nOhio       Cleveland     text messages  100     40\n                         total GB         3      6\n```","metadata":{},"cell_type":"markdown","id":"261f7e4d-abdc-4775-b1ce-c4fd9d0282bb"},{"source":"### International Caller\n* Unstack dataframe\n    * unstacks MultiIndex into column starting with default of inner most index first ","metadata":{},"cell_type":"markdown","id":"1af3c275-17b5-42b5-b350-1936eee3383f"},{"source":"arrays = [['day', 'day', 'night', 'night', 'eve', 'eve'], ['International', 'National', 'International', 'National', 'International', 'National'], ['churn', 'churn', 'churn', 'no churn', 'no churn', 'no churn']]\nmulti_index = pd.MultiIndex.from_arrays(arrays, names=['time', 'type', 'exited'])\nchurn = pd.DataFrame({\n    'minutes':[184.5, 129.1, 332.9, 110.4, 119.3, 137.1],\n    'calls':[97, 137, 67, 103, 117, 88],\n    'charge':[31.37, 21.95, 56.59, 18.77, 20.28, 23.31]\n}, index=multi_index)\ndisplay(churn)","metadata":{"executionTime":107,"lastSuccessfullyExecutedCode":"arrays = [['day', 'day', 'night', 'night', 'eve', 'eve'], ['International', 'National', 'International', 'National', 'International', 'National'], ['churn', 'churn', 'churn', 'no churn', 'no churn', 'no churn']]\nmulti_index = pd.MultiIndex.from_arrays(arrays, names=['time', 'type', 'exited'])\nchurn = pd.DataFrame({\n    'minutes':[184.5, 129.1, 332.9, 110.4, 119.3, 137.1],\n    'calls':[97, 137, 67, 103, 117, 88],\n    'charge':[31.37, 21.95, 56.59, 18.77, 20.28, 23.31]\n}, index=multi_index)\ndisplay(churn)"},"cell_type":"code","id":"0767d308-0b25-4a2a-a5c1-bebcce764fb1","execution_count":18,"outputs":[{"output_type":"display_data","data":{"application/com.datacamp.data-table.v1+json":{"table":{"schema":{"fields":[{"name":"time","type":"string"},{"name":"type","type":"string"},{"name":"exited","type":"string"},{"name":"minutes","type":"number"},{"name":"calls","type":"integer"},{"name":"charge","type":"number"}],"primaryKey":["time","type","exited"],"pandas_version":"1.4.0"},"data":[{"time":"day","type":"International","exited":"churn","minutes":184.5,"calls":97,"charge":31.37},{"time":"day","type":"National","exited":"churn","minutes":129.1,"calls":137,"charge":21.95},{"time":"night","type":"International","exited":"churn","minutes":332.9,"calls":67,"charge":56.59},{"time":"night","type":"National","exited":"no churn","minutes":110.4,"calls":103,"charge":18.77},{"time":"eve","type":"International","exited":"no churn","minutes":119.3,"calls":117,"charge":20.28},{"time":"eve","type":"National","exited":"no churn","minutes":137.1,"calls":88,"charge":23.31}]},"total_rows":6,"truncation_type":null},"text/plain":"                              minutes  calls  charge\ntime  type          exited                          \nday   International churn       184.5     97   31.37\n      National      churn       129.1    137   21.95\nnight International churn       332.9     67   56.59\n      National      no churn    110.4    103   18.77\neve   International no churn    119.3    117   20.28\n      National      no churn    137.1     88   23.31","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>minutes</th>\n      <th>calls</th>\n      <th>charge</th>\n    </tr>\n    <tr>\n      <th>time</th>\n      <th>type</th>\n      <th>exited</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">day</th>\n      <th>International</th>\n      <th>churn</th>\n      <td>184.5</td>\n      <td>97</td>\n      <td>31.37</td>\n    </tr>\n    <tr>\n      <th>National</th>\n      <th>churn</th>\n      <td>129.1</td>\n      <td>137</td>\n      <td>21.95</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">night</th>\n      <th>International</th>\n      <th>churn</th>\n      <td>332.9</td>\n      <td>67</td>\n      <td>56.59</td>\n    </tr>\n    <tr>\n      <th>National</th>\n      <th>no churn</th>\n      <td>110.4</td>\n      <td>103</td>\n      <td>18.77</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">eve</th>\n      <th>International</th>\n      <th>no churn</th>\n      <td>119.3</td>\n      <td>117</td>\n      <td>20.28</td>\n    </tr>\n    <tr>\n      <th>National</th>\n      <th>no churn</th>\n      <td>137.1</td>\n      <td>88</td>\n      <td>23.31</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"source":"# Reshape the churn DataFrame by unstacking\nchurn_unstack = churn.unstack()\n\n# print churn unstack\ndisplay(churn_unstack)","metadata":{"executionTime":74,"lastSuccessfullyExecutedCode":"# Reshape the churn DataFrame by unstacking\nchurn_unstack = churn.unstack()\n\n# print churn unstack\ndisplay(churn_unstack)"},"cell_type":"code","id":"753ee2ca-14b8-4dae-bd84-8e2f43957e98","execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"                    minutes           calls          charge         \nexited                churn no churn  churn no churn  churn no churn\ntime  type                                                          \nday   International   184.5      NaN   97.0      NaN  31.37      NaN\n      National        129.1      NaN  137.0      NaN  21.95      NaN\neve   International     NaN    119.3    NaN    117.0    NaN    20.28\n      National          NaN    137.1    NaN     88.0    NaN    23.31\nnight International   332.9      NaN   67.0      NaN  56.59      NaN\n      National          NaN    110.4    NaN    103.0    NaN    18.77","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th></th>\n      <th colspan=\"2\" halign=\"left\">minutes</th>\n      <th colspan=\"2\" halign=\"left\">calls</th>\n      <th colspan=\"2\" halign=\"left\">charge</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>exited</th>\n      <th>churn</th>\n      <th>no churn</th>\n      <th>churn</th>\n      <th>no churn</th>\n      <th>churn</th>\n      <th>no churn</th>\n    </tr>\n    <tr>\n      <th>time</th>\n      <th>type</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">day</th>\n      <th>International</th>\n      <td>184.5</td>\n      <td>NaN</td>\n      <td>97.0</td>\n      <td>NaN</td>\n      <td>31.37</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>National</th>\n      <td>129.1</td>\n      <td>NaN</td>\n      <td>137.0</td>\n      <td>NaN</td>\n      <td>21.95</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">eve</th>\n      <th>International</th>\n      <td>NaN</td>\n      <td>119.3</td>\n      <td>NaN</td>\n      <td>117.0</td>\n      <td>NaN</td>\n      <td>20.28</td>\n    </tr>\n    <tr>\n      <th>National</th>\n      <td>NaN</td>\n      <td>137.1</td>\n      <td>NaN</td>\n      <td>88.0</td>\n      <td>NaN</td>\n      <td>23.31</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">night</th>\n      <th>International</th>\n      <td>332.9</td>\n      <td>NaN</td>\n      <td>67.0</td>\n      <td>NaN</td>\n      <td>56.59</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>National</th>\n      <td>NaN</td>\n      <td>110.4</td>\n      <td>NaN</td>\n      <td>103.0</td>\n      <td>NaN</td>\n      <td>18.77</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"source":"churn_unstack.columns","metadata":{"executionTime":58,"lastSuccessfullyExecutedCode":"churn_unstack.columns"},"cell_type":"code","id":"2456a791-b715-4e29-8acd-e797ebcb6b71","execution_count":20,"outputs":[{"output_type":"execute_result","execution_count":20,"data":{"text/plain":"MultiIndex([('minutes',    'churn'),\n            ('minutes', 'no churn'),\n            (  'calls',    'churn'),\n            (  'calls', 'no churn'),\n            ( 'charge',    'churn'),\n            ( 'charge', 'no churn')],\n           names=[None, 'exited'])"},"metadata":{}}]},{"source":"* `Unstack()` takes the inner most MultiIndex **exited** and nests the values underneath the columns and for unavailable values, fills with NaN","metadata":{},"cell_type":"markdown","id":"0610a467-358e-4b97-8394-694b275136c0"},{"source":"# Reshape churn by unstacking the first row level\nchurn_first = churn.unstack(level=0)\n\n# Print churn_zero\ndisplay(churn_first)","metadata":{"executionTime":67,"lastSuccessfullyExecutedCode":"# Reshape churn by unstacking the first row level\nchurn_first = churn.unstack(level=0)\n\n# Print churn_zero\ndisplay(churn_first)"},"cell_type":"code","id":"c308ab81-2177-41e1-a695-78a3674568d4","execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"                       minutes                calls  ...        charge              \ntime                       day    eve  night    day  ...  night    day    eve  night\ntype          exited                                 ...                            \nInternational churn      184.5    NaN  332.9   97.0  ...   67.0  31.37    NaN  56.59\n              no churn     NaN  119.3    NaN    NaN  ...    NaN    NaN  20.28    NaN\nNational      churn      129.1    NaN    NaN  137.0  ...    NaN  21.95    NaN    NaN\n              no churn     NaN  137.1  110.4    NaN  ...  103.0    NaN  23.31  18.77\n\n[4 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th></th>\n      <th colspan=\"3\" halign=\"left\">minutes</th>\n      <th colspan=\"3\" halign=\"left\">calls</th>\n      <th colspan=\"3\" halign=\"left\">charge</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>time</th>\n      <th>day</th>\n      <th>eve</th>\n      <th>night</th>\n      <th>day</th>\n      <th>eve</th>\n      <th>night</th>\n      <th>day</th>\n      <th>eve</th>\n      <th>night</th>\n    </tr>\n    <tr>\n      <th>type</th>\n      <th>exited</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">International</th>\n      <th>churn</th>\n      <td>184.5</td>\n      <td>NaN</td>\n      <td>332.9</td>\n      <td>97.0</td>\n      <td>NaN</td>\n      <td>67.0</td>\n      <td>31.37</td>\n      <td>NaN</td>\n      <td>56.59</td>\n    </tr>\n    <tr>\n      <th>no churn</th>\n      <td>NaN</td>\n      <td>119.3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>117.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>20.28</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">National</th>\n      <th>churn</th>\n      <td>129.1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>137.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>21.95</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>no churn</th>\n      <td>NaN</td>\n      <td>137.1</td>\n      <td>110.4</td>\n      <td>NaN</td>\n      <td>88.0</td>\n      <td>103.0</td>\n      <td>NaN</td>\n      <td>23.31</td>\n      <td>18.77</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"source":"* level argument for unstack is zero based like list indexing and takes the time index or `left-most` index with the level set at zero","metadata":{},"cell_type":"markdown","id":"1edc9294-942d-40b6-b8ed-c3837a0ef23e"},{"source":"# Reshape churn by unstacking the second row level\nchurn_second = churn.unstack(level=1)\n\n# Print churn_second\ndisplay(churn_second)","metadata":{"executionTime":81,"lastSuccessfullyExecutedCode":"# Reshape churn by unstacking the second row level\nchurn_second = churn.unstack(level=1)\n\n# Print churn_second\ndisplay(churn_second)"},"cell_type":"code","id":"d3a28c2c-a55e-43d4-bf50-986fb9c46a25","execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"                     minutes           ...        charge         \ntype           International National  ... International National\ntime  exited                           ...                       \nday   churn            184.5    129.1  ...         31.37    21.95\neve   no churn         119.3    137.1  ...         20.28    23.31\nnight churn            332.9      NaN  ...         56.59      NaN\n      no churn           NaN    110.4  ...           NaN    18.77\n\n[4 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th></th>\n      <th colspan=\"2\" halign=\"left\">minutes</th>\n      <th colspan=\"2\" halign=\"left\">calls</th>\n      <th colspan=\"2\" halign=\"left\">charge</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>type</th>\n      <th>International</th>\n      <th>National</th>\n      <th>International</th>\n      <th>National</th>\n      <th>International</th>\n      <th>National</th>\n    </tr>\n    <tr>\n      <th>time</th>\n      <th>exited</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>day</th>\n      <th>churn</th>\n      <td>184.5</td>\n      <td>129.1</td>\n      <td>97.0</td>\n      <td>137.0</td>\n      <td>31.37</td>\n      <td>21.95</td>\n    </tr>\n    <tr>\n      <th>eve</th>\n      <th>no churn</th>\n      <td>119.3</td>\n      <td>137.1</td>\n      <td>117.0</td>\n      <td>88.0</td>\n      <td>20.28</td>\n      <td>23.31</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">night</th>\n      <th>churn</th>\n      <td>332.9</td>\n      <td>NaN</td>\n      <td>67.0</td>\n      <td>NaN</td>\n      <td>56.59</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>no churn</th>\n      <td>NaN</td>\n      <td>110.4</td>\n      <td>NaN</td>\n      <td>103.0</td>\n      <td>NaN</td>\n      <td>18.77</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"source":"churn","metadata":{"executionTime":155,"lastSuccessfullyExecutedCode":"churn"},"cell_type":"code","id":"f22f27f2-c62d-4a88-b851-3ca29bb19b57","execution_count":23,"outputs":[{"output_type":"execute_result","execution_count":23,"data":{"application/com.datacamp.data-table.v1+json":{"table":{"schema":{"fields":[{"name":"time","type":"string"},{"name":"type","type":"string"},{"name":"exited","type":"string"},{"name":"minutes","type":"number"},{"name":"calls","type":"integer"},{"name":"charge","type":"number"}],"primaryKey":["time","type","exited"],"pandas_version":"1.4.0"},"data":[{"time":"day","type":"International","exited":"churn","minutes":184.5,"calls":97,"charge":31.37},{"time":"day","type":"National","exited":"churn","minutes":129.1,"calls":137,"charge":21.95},{"time":"night","type":"International","exited":"churn","minutes":332.9,"calls":67,"charge":56.59},{"time":"night","type":"National","exited":"no churn","minutes":110.4,"calls":103,"charge":18.77},{"time":"eve","type":"International","exited":"no churn","minutes":119.3,"calls":117,"charge":20.28},{"time":"eve","type":"National","exited":"no churn","minutes":137.1,"calls":88,"charge":23.31}]},"total_rows":6,"truncation_type":null},"text/plain":"                              minutes  calls  charge\ntime  type          exited                          \nday   International churn       184.5     97   31.37\n      National      churn       129.1    137   21.95\nnight International churn       332.9     67   56.59\n      National      no churn    110.4    103   18.77\neve   International no churn    119.3    117   20.28\n      National      no churn    137.1     88   23.31","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>minutes</th>\n      <th>calls</th>\n      <th>charge</th>\n    </tr>\n    <tr>\n      <th>time</th>\n      <th>type</th>\n      <th>exited</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">day</th>\n      <th>International</th>\n      <th>churn</th>\n      <td>184.5</td>\n      <td>97</td>\n      <td>31.37</td>\n    </tr>\n    <tr>\n      <th>National</th>\n      <th>churn</th>\n      <td>129.1</td>\n      <td>137</td>\n      <td>21.95</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">night</th>\n      <th>International</th>\n      <th>churn</th>\n      <td>332.9</td>\n      <td>67</td>\n      <td>56.59</td>\n    </tr>\n    <tr>\n      <th>National</th>\n      <th>no churn</th>\n      <td>110.4</td>\n      <td>103</td>\n      <td>18.77</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">eve</th>\n      <th>International</th>\n      <th>no churn</th>\n      <td>119.3</td>\n      <td>117</td>\n      <td>20.28</td>\n    </tr>\n    <tr>\n      <th>National</th>\n      <th>no churn</th>\n      <td>137.1</td>\n      <td>88</td>\n      <td>23.31</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"source":"# Unstack the time level from churn\nchurn_time = churn.unstack(level='time')\n\n# Print churn_time\ndisplay(churn_time)","metadata":{"executionTime":57,"lastSuccessfullyExecutedCode":"# Unstack the time level from churn\nchurn_time = churn.unstack(level='time')\n\n# Print churn_time\ndisplay(churn_time)"},"cell_type":"code","id":"c033f5ae-3638-4b76-afe5-9f66cf24ae12","execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"                       minutes                calls  ...        charge              \ntime                       day    eve  night    day  ...  night    day    eve  night\ntype          exited                                 ...                            \nInternational churn      184.5    NaN  332.9   97.0  ...   67.0  31.37    NaN  56.59\n              no churn     NaN  119.3    NaN    NaN  ...    NaN    NaN  20.28    NaN\nNational      churn      129.1    NaN    NaN  137.0  ...    NaN  21.95    NaN    NaN\n              no churn     NaN  137.1  110.4    NaN  ...  103.0    NaN  23.31  18.77\n\n[4 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th></th>\n      <th colspan=\"3\" halign=\"left\">minutes</th>\n      <th colspan=\"3\" halign=\"left\">calls</th>\n      <th colspan=\"3\" halign=\"left\">charge</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>time</th>\n      <th>day</th>\n      <th>eve</th>\n      <th>night</th>\n      <th>day</th>\n      <th>eve</th>\n      <th>night</th>\n      <th>day</th>\n      <th>eve</th>\n      <th>night</th>\n    </tr>\n    <tr>\n      <th>type</th>\n      <th>exited</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">International</th>\n      <th>churn</th>\n      <td>184.5</td>\n      <td>NaN</td>\n      <td>332.9</td>\n      <td>97.0</td>\n      <td>NaN</td>\n      <td>67.0</td>\n      <td>31.37</td>\n      <td>NaN</td>\n      <td>56.59</td>\n    </tr>\n    <tr>\n      <th>no churn</th>\n      <td>NaN</td>\n      <td>119.3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>117.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>20.28</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">National</th>\n      <th>churn</th>\n      <td>129.1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>137.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>21.95</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>no churn</th>\n      <td>NaN</td>\n      <td>137.1</td>\n      <td>110.4</td>\n      <td>NaN</td>\n      <td>88.0</td>\n      <td>103.0</td>\n      <td>NaN</td>\n      <td>23.31</td>\n      <td>18.77</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"source":"* `level` argument also takes multiindex value names apart from index level\n\n### Call another time\nYou discover some patterns when you reshaped the DataFrame. Now, you want to unstack the DataFrame again. This time you will choose which level to unstack and reorganize your indices.","metadata":{},"cell_type":"markdown","id":"a92a3216-baf6-49e6-92a2-4e8551f52280"},{"source":"# Sort the index in descending order\nchurn_time = churn.unstack(level='time').sort_index(ascending=False)\n\n# Print churn_time\ndisplay(churn_time)","metadata":{"executionTime":94,"lastSuccessfullyExecutedCode":"# Sort the index in descending order\nchurn_time = churn.unstack(level='time').sort_index(ascending=False)\n\n# Print churn_time\ndisplay(churn_time)"},"cell_type":"code","id":"80c4abce-f878-41e5-92f4-609f2e9fa909","execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"                       minutes                calls  ...        charge              \ntime                       day    eve  night    day  ...  night    day    eve  night\ntype          exited                                 ...                            \nNational      no churn     NaN  137.1  110.4    NaN  ...  103.0    NaN  23.31  18.77\n              churn      129.1    NaN    NaN  137.0  ...    NaN  21.95    NaN    NaN\nInternational no churn     NaN  119.3    NaN    NaN  ...    NaN    NaN  20.28    NaN\n              churn      184.5    NaN  332.9   97.0  ...   67.0  31.37    NaN  56.59\n\n[4 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th></th>\n      <th colspan=\"3\" halign=\"left\">minutes</th>\n      <th colspan=\"3\" halign=\"left\">calls</th>\n      <th colspan=\"3\" halign=\"left\">charge</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>time</th>\n      <th>day</th>\n      <th>eve</th>\n      <th>night</th>\n      <th>day</th>\n      <th>eve</th>\n      <th>night</th>\n      <th>day</th>\n      <th>eve</th>\n      <th>night</th>\n    </tr>\n    <tr>\n      <th>type</th>\n      <th>exited</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">National</th>\n      <th>no churn</th>\n      <td>NaN</td>\n      <td>137.1</td>\n      <td>110.4</td>\n      <td>NaN</td>\n      <td>88.0</td>\n      <td>103.0</td>\n      <td>NaN</td>\n      <td>23.31</td>\n      <td>18.77</td>\n    </tr>\n    <tr>\n      <th>churn</th>\n      <td>129.1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>137.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>21.95</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">International</th>\n      <th>no churn</th>\n      <td>NaN</td>\n      <td>119.3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>117.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>20.28</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>churn</th>\n      <td>184.5</td>\n      <td>NaN</td>\n      <td>332.9</td>\n      <td>97.0</td>\n      <td>NaN</td>\n      <td>67.0</td>\n      <td>31.37</td>\n      <td>NaN</td>\n      <td>56.59</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"source":"### Organizing your voicemail\nYou will perform one final task before moving to a new project. You will reshape the DataFrame churn again. This time, you'll reorganize a row index as a column index. After that, you will move a column index to a row index. To do this, you will first unstack the DataFrame, and then stack it.","metadata":{},"cell_type":"markdown","id":"f6edd7d8-2b7a-49f9-b5ab-cdf68db0d354"},{"source":"# Unstack churn by type level\nchurn_type = churn.unstack(level='type')\n\n# Stack the resulting DataFrame using the first column level\nchurn_final = churn_type.stack(level=0)\n\n# Print churn_type\ndisplay(churn_final)","metadata":{"executionTime":232,"lastSuccessfullyExecutedCode":"# Unstack churn by type level\nchurn_type = churn.unstack(level='type')\n\n# Stack the resulting DataFrame using the first column level\nchurn_final = churn_type.stack(level=0)\n\n# Print churn_type\ndisplay(churn_final)"},"cell_type":"code","id":"5a3ed410-e442-4eb3-8713-6d49cd2b989c","execution_count":26,"outputs":[{"output_type":"display_data","data":{"application/com.datacamp.data-table.v1+json":{"table":{"schema":{"fields":[{"name":"time","type":"string"},{"name":"exited","type":"string"},{"name":"level_2","type":"string"},{"name":"International","type":"number"},{"name":"National","type":"number"}],"primaryKey":["time","exited","level_2"],"pandas_version":"1.4.0"},"data":[{"time":"day","exited":"churn","level_2":"calls","International":97,"National":137},{"time":"day","exited":"churn","level_2":"charge","International":31.37,"National":21.95},{"time":"day","exited":"churn","level_2":"minutes","International":184.5,"National":129.1},{"time":"eve","exited":"no churn","level_2":"calls","International":117,"National":88},{"time":"eve","exited":"no churn","level_2":"charge","International":20.28,"National":23.31},{"time":"eve","exited":"no churn","level_2":"minutes","International":119.3,"National":137.1},{"time":"night","exited":"churn","level_2":"calls","International":67,"National":null},{"time":"night","exited":"churn","level_2":"charge","International":56.59,"National":null},{"time":"night","exited":"churn","level_2":"minutes","International":332.9,"National":null},{"time":"night","exited":"no churn","level_2":"calls","International":null,"National":103},{"time":"night","exited":"no churn","level_2":"charge","International":null,"National":18.77},{"time":"night","exited":"no churn","level_2":"minutes","International":null,"National":110.4}]},"total_rows":12,"truncation_type":null},"text/plain":"type                    International  National\ntime  exited                                   \nday   churn    calls            97.00    137.00\n               charge           31.37     21.95\n               minutes         184.50    129.10\neve   no churn calls           117.00     88.00\n               charge           20.28     23.31\n               minutes         119.30    137.10\nnight churn    calls            67.00       NaN\n               charge           56.59       NaN\n               minutes         332.90       NaN\n      no churn calls              NaN    103.00\n               charge             NaN     18.77\n               minutes            NaN    110.40","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>type</th>\n      <th>International</th>\n      <th>National</th>\n    </tr>\n    <tr>\n      <th>time</th>\n      <th>exited</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">day</th>\n      <th rowspan=\"3\" valign=\"top\">churn</th>\n      <th>calls</th>\n      <td>97.00</td>\n      <td>137.00</td>\n    </tr>\n    <tr>\n      <th>charge</th>\n      <td>31.37</td>\n      <td>21.95</td>\n    </tr>\n    <tr>\n      <th>minutes</th>\n      <td>184.50</td>\n      <td>129.10</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">eve</th>\n      <th rowspan=\"3\" valign=\"top\">no churn</th>\n      <th>calls</th>\n      <td>117.00</td>\n      <td>88.00</td>\n    </tr>\n    <tr>\n      <th>charge</th>\n      <td>20.28</td>\n      <td>23.31</td>\n    </tr>\n    <tr>\n      <th>minutes</th>\n      <td>119.30</td>\n      <td>137.10</td>\n    </tr>\n    <tr>\n      <th rowspan=\"6\" valign=\"top\">night</th>\n      <th rowspan=\"3\" valign=\"top\">churn</th>\n      <th>calls</th>\n      <td>67.00</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>charge</th>\n      <td>56.59</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>minutes</th>\n      <td>332.90</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">no churn</th>\n      <th>calls</th>\n      <td>NaN</td>\n      <td>103.00</td>\n    </tr>\n    <tr>\n      <th>charge</th>\n      <td>NaN</td>\n      <td>18.77</td>\n    </tr>\n    <tr>\n      <th>minutes</th>\n      <td>NaN</td>\n      <td>110.40</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"source":"### Swap your SIM card\nGreat job so far! You were able to reshape your dataset in several ways. Now it's time to go a step further and analyze the data to discover if a customer's cell phone plan is related to the customer leaving.","metadata":{},"cell_type":"markdown","id":"46a26f67-8747-4272-992b-0a15d62644d3"},{"source":"```python\nIn [14]:\nchurn\nOut[14]:\n\nyear                               2019                   2020               \nplan                            minutes voicemail data minutes voicemail data\nexited   state      city                                                     \nchurn    California Los Angeles       0         1    2       1         1    5\nno_churn California Los Angeles       0         1    3       1         0    2\nchurn    New York   New York          1         0    5       0         1    2\nno_churn New York   New York          1         0    4       1         0    6\nIn [15]:\nchurn.columns\nOut[15]:\n\nMultiIndex([('2019',   'minutes'),\n            ('2019', 'voicemail'),\n            ('2019',      'data'),\n            ('2020',   'minutes'),\n            ('2020', 'voicemail'),\n            ('2020',      'data')],\n           names=['year', 'plan'])\nIn [16]:\nchurn.index\nOut[16]:\n\nMultiIndex([(   'churn', 'California', 'Los Angeles'),\n            ('no_churn', 'California', 'Los Angeles'),\n            (   'churn',   'New York',    'New York'),\n            ('no_churn',   'New York',    'New York')],\n           names=['exited', 'state', 'city']\n```\n* This is the default churn dataset provided in the exercise, let's make it\n* Looks like the easiest may be to create a Pandas MultiIndex Series then start unstacking","metadata":{},"cell_type":"markdown","id":"dbb9e343-68da-4b52-882b-1a77fbdf5c9a"},{"source":"```python\n\nIn [11]:\nchurn_s = churn_s.stack()\nIn [12]:\nchurn_s\nOut[12]:\n\nexited    state       city         plan       year\nchurn     California  Los Angeles  data       2019    2\n                                              2020    5\n                                   minutes    2019    0\n                                              2020    1\n                                   voicemail  2019    1\n                                              2020    1\nno_churn  California  Los Angeles  data       2019    3\n                                              2020    2\n                                   minutes    2019    0\n                                              2020    1\n                                   voicemail  2019    1\n                                              2020    0\nchurn     New York    New York     data       2019    5\n                                              2020    2\n                                   minutes    2019    1\n                                              2020    0\n                                   voicemail  2019    0\n                                              2020    1\nno_churn  New York    New York     data       2019    4\n                                              2020    6\n                                   minutes    2019    1\n                                              2020    1\n                                   voicemail  2019    0\n                                              2020    0\ndtype: int64\n```","metadata":{},"cell_type":"markdown","id":"e2ae2726-90f4-4e85-9277-2aa6348bfe9a"},{"source":"arrays_idx = [['churn', 'churn', 'churn', 'churn', 'churn', 'churn', \n               'no_churn', 'no_churn', 'no_churn', 'no_churn', 'no_churn', 'no_churn',\n               'churn', 'churn', 'churn', 'churn', 'churn', 'churn', \n               'no_churn', 'no_churn', 'no_churn', 'no_churn', 'no_churn', 'no_churn',], \n             ['California', 'California', 'California', 'California', 'California', 'California',\n              'California', 'California', 'California', 'California', 'California', 'California',\n              'New York', 'New York', 'New York', 'New York', 'New York', 'New York',\n              'New York', 'New York', 'New York', 'New York', 'New York', 'New York',],\n             ['Los Angeles', 'Los Angeles', 'Los Angeles', 'Los Angeles', 'Los Angeles', 'Los Angeles',\n              'Los Angeles', 'Los Angeles', 'Los Angeles', 'Los Angeles', 'Los Angeles', 'Los Angeles',\n              'New York', 'New York', 'New York', 'New York', 'New York', 'New York',\n              'New York', 'New York', 'New York', 'New York', 'New York', 'New York',],\n             ['data', 'data', 'minutes', 'minutes', 'voicemail', 'voicemail',\n              'data', 'data', 'minutes', 'minutes', 'voicemail', 'voicemail',\n              'data', 'data', 'minutes', 'minutes', 'voicemail', 'voicemail',\n              'data', 'data', 'minutes', 'minutes', 'voicemail', 'voicemail'],\n              [2019,2020,2019,2020, 2019,2020,\n              2019,2020,2019,2020, 2019,2020,\n              2019,2020,2019,2020, 2019,2020,\n              2019,2020,2019,2020, 2019,2020]\n             ]\nmulti_idx_idx = pd.MultiIndex.from_arrays(arrays_idx, names=['exited', 'state', 'city', 'plan', 'year'])\nsim_series_values = [2, 5, 0, 1, 1, 1, 3, 2, 0, 1, 1, 0, 5, 2, 1, 0, 0, 1, 4, 6, 1, 1, 0, 0]\nsim_pd_series = pd.Series(sim_series_values, index=multi_idx_idx)\ndisplay(sim_pd_series)","metadata":{"executionTime":59,"lastSuccessfullyExecutedCode":"arrays_idx = [['churn', 'churn', 'churn', 'churn', 'churn', 'churn', \n               'no_churn', 'no_churn', 'no_churn', 'no_churn', 'no_churn', 'no_churn',\n               'churn', 'churn', 'churn', 'churn', 'churn', 'churn', \n               'no_churn', 'no_churn', 'no_churn', 'no_churn', 'no_churn', 'no_churn',], \n             ['California', 'California', 'California', 'California', 'California', 'California',\n              'California', 'California', 'California', 'California', 'California', 'California',\n              'New York', 'New York', 'New York', 'New York', 'New York', 'New York',\n              'New York', 'New York', 'New York', 'New York', 'New York', 'New York',],\n             ['Los Angeles', 'Los Angeles', 'Los Angeles', 'Los Angeles', 'Los Angeles', 'Los Angeles',\n              'Los Angeles', 'Los Angeles', 'Los Angeles', 'Los Angeles', 'Los Angeles', 'Los Angeles',\n              'New York', 'New York', 'New York', 'New York', 'New York', 'New York',\n              'New York', 'New York', 'New York', 'New York', 'New York', 'New York',],\n             ['data', 'data', 'minutes', 'minutes', 'voicemail', 'voicemail',\n              'data', 'data', 'minutes', 'minutes', 'voicemail', 'voicemail',\n              'data', 'data', 'minutes', 'minutes', 'voicemail', 'voicemail',\n              'data', 'data', 'minutes', 'minutes', 'voicemail', 'voicemail'],\n              [2019,2020,2019,2020, 2019,2020,\n              2019,2020,2019,2020, 2019,2020,\n              2019,2020,2019,2020, 2019,2020,\n              2019,2020,2019,2020, 2019,2020]\n             ]\nmulti_idx_idx = pd.MultiIndex.from_arrays(arrays_idx, names=['exited', 'state', 'city', 'plan', 'year'])\nsim_series_values = [2, 5, 0, 1, 1, 1, 3, 2, 0, 1, 1, 0, 5, 2, 1, 0, 0, 1, 4, 6, 1, 1, 0, 0]\nsim_pd_series = pd.Series(sim_series_values, index=multi_idx_idx)\ndisplay(sim_pd_series)"},"cell_type":"code","id":"a4af2fa5-bf31-4b5e-a091-920e365c06fb","execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"exited    state       city         plan       year\nchurn     California  Los Angeles  data       2019    2\n                                              2020    5\n                                   minutes    2019    0\n                                              2020    1\n                                   voicemail  2019    1\n                                              2020    1\nno_churn  California  Los Angeles  data       2019    3\n                                              2020    2\n                                   minutes    2019    0\n                                              2020    1\n                                   voicemail  2019    1\n                                              2020    0\nchurn     New York    New York     data       2019    5\n                                              2020    2\n                                   minutes    2019    1\n                                              2020    0\n                                   voicemail  2019    0\n                                              2020    1\nno_churn  New York    New York     data       2019    4\n                                              2020    6\n                                   minutes    2019    1\n                                              2020    1\n                                   voicemail  2019    0\n                                              2020    0\ndtype: int64"},"metadata":{}}]},{"source":"* Alright cool so that series looks in good shape, now let's see if we can unstack the level values to get a dataframe similar to the one provided","metadata":{},"cell_type":"markdown","id":"1fb8c3ab-0476-46aa-9b14-403009092c4f"},{"source":"churn_df_ser_unstack = sim_pd_series.unstack('year').unstack('plan')\nchurn_df_ser_unstack","metadata":{"executionTime":69,"lastSuccessfullyExecutedCode":"churn_df_ser_unstack = sim_pd_series.unstack('year').unstack('plan')\nchurn_df_ser_unstack"},"cell_type":"code","id":"fe355496-933f-46cc-a0c3-d09ebb3f5bf1","execution_count":28,"outputs":[{"output_type":"execute_result","execution_count":28,"data":{"text/plain":"year                            2019                   2020                  \nplan                            data minutes voicemail data minutes voicemail\nexited   state      city                                                     \nchurn    California Los Angeles    2       0         1    5       1         1\n         New York   New York       5       1         0    2       0         1\nno_churn California Los Angeles    3       0         1    2       1         0\n         New York   New York       4       1         0    6       1         0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th></th>\n      <th>year</th>\n      <th colspan=\"3\" halign=\"left\">2019</th>\n      <th colspan=\"3\" halign=\"left\">2020</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th></th>\n      <th>plan</th>\n      <th>data</th>\n      <th>minutes</th>\n      <th>voicemail</th>\n      <th>data</th>\n      <th>minutes</th>\n      <th>voicemail</th>\n    </tr>\n    <tr>\n      <th>exited</th>\n      <th>state</th>\n      <th>city</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">churn</th>\n      <th>California</th>\n      <th>Los Angeles</th>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>New York</th>\n      <th>New York</th>\n      <td>5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">no_churn</th>\n      <th>California</th>\n      <th>Los Angeles</th>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>New York</th>\n      <th>New York</th>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>6</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"source":"* We'll ... the values are the same but a slightly different layout for the dataframe compared to provided. ...Say la vie","metadata":{},"cell_type":"markdown","id":"ad9e7134-f0c7-4525-94dd-593e26671f5c"},{"source":"# Let's look at swapping first and third row index\nchurn_swap = churn_df_ser_unstack.swaplevel(0, 2)\ndisplay(churn_swap)\n\n# Reshape by unstacking the last row level \nchurn_unstack = churn_swap.unstack(level=-1)\nprint('\\n')\ndisplay(churn_unstack)","metadata":{"executionTime":115,"lastSuccessfullyExecutedCode":"# Let's look at swapping first and third row index\nchurn_swap = churn_df_ser_unstack.swaplevel(0, 2)\ndisplay(churn_swap)\n\n# Reshape by unstacking the last row level \nchurn_unstack = churn_swap.unstack(level=-1)\nprint('\\n')\ndisplay(churn_unstack)"},"cell_type":"code","id":"539ef838-c4bb-4766-8767-482205535da2","execution_count":29,"outputs":[{"output_type":"display_data","data":{"text/plain":"year                            2019                   2020                  \nplan                            data minutes voicemail data minutes voicemail\ncity        state      exited                                                \nLos Angeles California churn       2       0         1    5       1         1\nNew York    New York   churn       5       1         0    2       0         1\nLos Angeles California no_churn    3       0         1    2       1         0\nNew York    New York   no_churn    4       1         0    6       1         0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th></th>\n      <th>year</th>\n      <th colspan=\"3\" halign=\"left\">2019</th>\n      <th colspan=\"3\" halign=\"left\">2020</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th></th>\n      <th>plan</th>\n      <th>data</th>\n      <th>minutes</th>\n      <th>voicemail</th>\n      <th>data</th>\n      <th>minutes</th>\n      <th>voicemail</th>\n    </tr>\n    <tr>\n      <th>city</th>\n      <th>state</th>\n      <th>exited</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Los Angeles</th>\n      <th>California</th>\n      <th>churn</th>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>New York</th>\n      <th>New York</th>\n      <th>churn</th>\n      <td>5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>Los Angeles</th>\n      <th>California</th>\n      <th>no_churn</th>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>New York</th>\n      <th>New York</th>\n      <th>no_churn</th>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>6</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n\n"},{"output_type":"display_data","data":{"text/plain":"year                    2019                   ...     2020                   \nplan                    data          minutes  ...  minutes voicemail         \nexited                 churn no_churn   churn  ... no_churn     churn no_churn\ncity        state                              ...                            \nLos Angeles California     2        3       0  ...        1         1        0\nNew York    New York       5        4       1  ...        1         1        0\n\n[2 rows x 12 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th>year</th>\n      <th colspan=\"6\" halign=\"left\">2019</th>\n      <th colspan=\"6\" halign=\"left\">2020</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>plan</th>\n      <th colspan=\"2\" halign=\"left\">data</th>\n      <th colspan=\"2\" halign=\"left\">minutes</th>\n      <th colspan=\"2\" halign=\"left\">voicemail</th>\n      <th colspan=\"2\" halign=\"left\">data</th>\n      <th colspan=\"2\" halign=\"left\">minutes</th>\n      <th colspan=\"2\" halign=\"left\">voicemail</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>exited</th>\n      <th>churn</th>\n      <th>no_churn</th>\n      <th>churn</th>\n      <th>no_churn</th>\n      <th>churn</th>\n      <th>no_churn</th>\n      <th>churn</th>\n      <th>no_churn</th>\n      <th>churn</th>\n      <th>no_churn</th>\n      <th>churn</th>\n      <th>no_churn</th>\n    </tr>\n    <tr>\n      <th>city</th>\n      <th>state</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Los Angeles</th>\n      <th>California</th>\n      <td>2</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>New York</th>\n      <th>New York</th>\n      <td>5</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>6</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"source":"* From in exercise terminal\n\n```python\nIn [3]:\nchurn_swap = churn.swaplevel(0, 2)\nIn [4]:\nchurn_swap\nOut[4]:\n\nyear                               2019                   2020               \nplan                            minutes voicemail data minutes voicemail data\ncity        state      exited                                                \nLos Angeles California churn          0         1    2       1         1    5\n                       no_churn       0         1    3       1         0    2\nNew York    New York   churn          1         0    5       0         1    2\n                       no_churn       1         0    4       1         0    6\nIn [5]:\nchurn\nOut[5]:\n\nyear                               2019                   2020               \nplan                            minutes voicemail data minutes voicemail data\nexited   state      city                                                     \nchurn    California Los Angeles       0         1    2       1         1    5\nno_churn California Los Angeles       0         1    3       1         0    2\nchurn    New York   New York          1         0    5       0         1    2\nno_churn New York   New York          1         0    4       1         0    6\n```\n\n```python\n# Reshape by unstacking the last row level \nchurn_unstack = churn_swap.unstack(level=-1)\n\n# Print churn_unstack\nprint(churn_unstack)\n\n<script.py> output:\n    year                      2019                                               2020                                           \n    plan                   minutes          voicemail           data          minutes          voicemail           data         \n    exited                   churn no_churn     churn no_churn churn no_churn   churn no_churn     churn no_churn churn no_churn\n    city        state                                                                                                           \n    Los Angeles California       0        0         1        1     2        3       1        1         1        0     5        2\n    New York    New York         1        1         0        0     5        4       0        1         1        0     2        6\n```","metadata":{},"cell_type":"markdown","id":"cd80a0fb-e698-4033-8ef0-3cd2ea1e9151"},{"source":"* A little bit deeper\n\n```python\n# Unstack the first and second row level of churn\nchurn_unstack = churn.unstack(level=[0, 1])\n\n# Stack the resulting DataFrame using plan and year\nchurn_py = churn_unstack.stack(['plan', 'year'])\n\n# Switch the first and second column levels\nchurn_switch = churn_py.swaplevel(0, 1, axis=1)\n\n# Print churn_switch\nprint(churn_switch)\n\n<script.py> output:\n    state                      California New York California New York\n    exited                          churn    churn   no_churn no_churn\n    city        plan      year                                        \n    Los Angeles data      2019        2.0      NaN        3.0      NaN\n                          2020        5.0      NaN        2.0      NaN\n                minutes   2019        0.0      NaN        0.0      NaN\n                          2020        1.0      NaN        1.0      NaN\n                voicemail 2019        1.0      NaN        1.0      NaN\n                          2020        1.0      NaN        0.0      NaN\n    New York    data      2019        NaN      5.0        NaN      4.0\n                          2020        NaN      2.0        NaN      6.0\n                minutes   2019        NaN      1.0        NaN      1.0\n                          2020        NaN      0.0        NaN      1.0\n                voicemail 2019        NaN      0.0        NaN      0.0\n                          2020        NaN      1.0        NaN      0.0\n```","metadata":{},"cell_type":"markdown","id":"51c238df-ba07-4001-a728-052a11229270"},{"source":"churn_unstack = churn_df_ser_unstack.unstack(level=[0,1])\nchurn_py = churn_unstack.stack(['plan', 'year'])\nchurn_switch = churn_py.swaplevel(0,1,axis=1)\ndisplay(churn_switch)","metadata":{"executionTime":98,"lastSuccessfullyExecutedCode":"churn_unstack = churn_df_ser_unstack.unstack(level=[0,1])\nchurn_py = churn_unstack.stack(['plan', 'year'])\nchurn_switch = churn_py.swaplevel(0,1,axis=1)\ndisplay(churn_switch)"},"cell_type":"code","id":"51ad1e3a-bb62-4eea-aa47-bc8bc92896c0","execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":"state                      California New York California New York\nexited                          churn    churn   no_churn no_churn\ncity        plan      year                                        \nLos Angeles data      2019        2.0      NaN        3.0      NaN\n                      2020        5.0      NaN        2.0      NaN\n            minutes   2019        0.0      NaN        0.0      NaN\n                      2020        1.0      NaN        1.0      NaN\n            voicemail 2019        1.0      NaN        1.0      NaN\n                      2020        1.0      NaN        0.0      NaN\nNew York    data      2019        NaN      5.0        NaN      4.0\n                      2020        NaN      2.0        NaN      6.0\n            minutes   2019        NaN      1.0        NaN      1.0\n                      2020        NaN      0.0        NaN      1.0\n            voicemail 2019        NaN      0.0        NaN      0.0\n                      2020        NaN      1.0        NaN      0.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th></th>\n      <th>state</th>\n      <th>California</th>\n      <th>New York</th>\n      <th>California</th>\n      <th>New York</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th></th>\n      <th>exited</th>\n      <th>churn</th>\n      <th>churn</th>\n      <th>no_churn</th>\n      <th>no_churn</th>\n    </tr>\n    <tr>\n      <th>city</th>\n      <th>plan</th>\n      <th>year</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"6\" valign=\"top\">Los Angeles</th>\n      <th rowspan=\"2\" valign=\"top\">data</th>\n      <th>2019</th>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2020</th>\n      <td>5.0</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">minutes</th>\n      <th>2019</th>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2020</th>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">voicemail</th>\n      <th>2019</th>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2020</th>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th rowspan=\"6\" valign=\"top\">New York</th>\n      <th rowspan=\"2\" valign=\"top\">data</th>\n      <th>2019</th>\n      <td>NaN</td>\n      <td>5.0</td>\n      <td>NaN</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>2020</th>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">minutes</th>\n      <th>2019</th>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2020</th>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">voicemail</th>\n      <th>2019</th>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2020</th>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"source":"### A missed phone call\nYou finished reshaping your churn dataset in the previous exercises. Now, it is ready to be used. You remember that something caught your attention. You are sure you saw a clear pattern in the data.\n\nBefore you fit a classification model, you decide to do something simpler. You want to see what else you can learn from the data. You will reshape your data by unstacking levels, but you know this process will generate missing data that you need to handle.\n\n* dframe from exercise\n\n```python\nIn [1]:\nchurn\nOut[1]:\n\n                                                total_day_calls  total_night_calls\nstate international_plan voice_mail_plan churn                                    \nLA    No                 No              False          106.818             96.909\n                                         True           100.000            119.000\n                         Yes             False          100.000             84.250\nNY    No                 No              False           90.900            100.800\n                                         True            95.000            101.500\n                         Yes             False          115.000            121.000\n      Yes                No              False          109.000             99.000\n                                         True            87.000            113.000\nLA    Yes                No              False           78.000             90.000\n                                         True            69.000            104.000\nNY    Yes                Yes             False          120.000             78.000\nLA    Yes                Yes             False           71.000            101.000\n```\n\n* get index level values for quicker creation\n\n```python\nIn [4]:\nchurn.index.get_level_values(0)\nOut[4]:\nIndex(['LA', 'LA', 'LA', 'NY', 'NY', 'NY', 'NY', 'NY', 'LA', 'LA', 'NY', 'LA'], dtype='object', name='state')\n```","metadata":{},"cell_type":"markdown","id":"ee0f8d5a-5494-4c68-8ca3-c989247c4450"},{"source":"msd_idx_arrays = [['LA', 'LA', 'LA', 'NY', 'NY', 'NY', 'NY', 'NY', 'LA', 'LA', 'NY', 'LA'],\n                 ['No', 'No', 'No', 'No', 'No', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes'],\n                 ['No', 'No', 'Yes', 'No', 'No', 'Yes', 'No', 'No', 'No', 'No', 'Yes', 'Yes'],\n                 [False, True, False, False, True, False, False, True, False, True, False, False]\n                 ]\nmsphc_idx_multi = pd.MultiIndex.from_arrays(msd_idx_arrays, names=['state', 'international_plan', 'voice_mail_plan', 'churn'])\nprint(msphc_idx_multi)","metadata":{"executionTime":51,"lastSuccessfullyExecutedCode":"msd_idx_arrays = [['LA', 'LA', 'LA', 'NY', 'NY', 'NY', 'NY', 'NY', 'LA', 'LA', 'NY', 'LA'],\n                 ['No', 'No', 'No', 'No', 'No', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes'],\n                 ['No', 'No', 'Yes', 'No', 'No', 'Yes', 'No', 'No', 'No', 'No', 'Yes', 'Yes'],\n                 [False, True, False, False, True, False, False, True, False, True, False, False]\n                 ]\nmsphc_idx_multi = pd.MultiIndex.from_arrays(msd_idx_arrays, names=['state', 'international_plan', 'voice_mail_plan', 'churn'])\nprint(msphc_idx_multi)"},"cell_type":"code","id":"db23c3a0-13be-4556-9ed3-7bfa1440f49b","execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":"MultiIndex([('LA',  'No',  'No', False),\n            ('LA',  'No',  'No',  True),\n            ('LA',  'No', 'Yes', False),\n            ('NY',  'No',  'No', False),\n            ('NY',  'No',  'No',  True),\n            ('NY',  'No', 'Yes', False),\n            ('NY', 'Yes',  'No', False),\n            ('NY', 'Yes',  'No',  True),\n            ('LA', 'Yes',  'No', False),\n            ('LA', 'Yes',  'No',  True),\n            ('NY', 'Yes', 'Yes', False),\n            ('LA', 'Yes', 'Yes', False)],\n           names=['state', 'international_plan', 'voice_mail_plan', 'churn'])\n"}]},{"source":"churn_missed_calls = pd.DataFrame({\n    'total_day_calls': [106.818,100.0,100.0,90.9,95.0,115.0,109.0,87.0,78.0,69.0,120.0,71.0],\n    'total_night_calls':[96.909,119.0,84.25,100.8,101.5,121.0,99.0,113.0,90.0,104.0,78.0,101.0]\n}, index=msphc_idx_multi)\ndisplay(churn_missed_calls)","metadata":{"executionTime":278,"lastSuccessfullyExecutedCode":"churn_missed_calls = pd.DataFrame({\n    'total_day_calls': [106.818,100.0,100.0,90.9,95.0,115.0,109.0,87.0,78.0,69.0,120.0,71.0],\n    'total_night_calls':[96.909,119.0,84.25,100.8,101.5,121.0,99.0,113.0,90.0,104.0,78.0,101.0]\n}, index=msphc_idx_multi)\ndisplay(churn_missed_calls)"},"cell_type":"code","id":"9345b487-8052-4965-89a6-8ebefab46f99","execution_count":32,"outputs":[{"output_type":"display_data","data":{"application/com.datacamp.data-table.v1+json":{"table":{"schema":{"fields":[{"name":"state","type":"string"},{"name":"international_plan","type":"string"},{"name":"voice_mail_plan","type":"string"},{"name":"churn","type":"boolean"},{"name":"total_day_calls","type":"number"},{"name":"total_night_calls","type":"number"}],"primaryKey":["state","international_plan","voice_mail_plan","churn"],"pandas_version":"1.4.0"},"data":[{"state":"LA","international_plan":"No","voice_mail_plan":"No","churn":false,"total_day_calls":106.818,"total_night_calls":96.909},{"state":"LA","international_plan":"No","voice_mail_plan":"No","churn":true,"total_day_calls":100,"total_night_calls":119},{"state":"LA","international_plan":"No","voice_mail_plan":"Yes","churn":false,"total_day_calls":100,"total_night_calls":84.25},{"state":"NY","international_plan":"No","voice_mail_plan":"No","churn":false,"total_day_calls":90.9,"total_night_calls":100.8},{"state":"NY","international_plan":"No","voice_mail_plan":"No","churn":true,"total_day_calls":95,"total_night_calls":101.5},{"state":"NY","international_plan":"No","voice_mail_plan":"Yes","churn":false,"total_day_calls":115,"total_night_calls":121},{"state":"NY","international_plan":"Yes","voice_mail_plan":"No","churn":false,"total_day_calls":109,"total_night_calls":99},{"state":"NY","international_plan":"Yes","voice_mail_plan":"No","churn":true,"total_day_calls":87,"total_night_calls":113},{"state":"LA","international_plan":"Yes","voice_mail_plan":"No","churn":false,"total_day_calls":78,"total_night_calls":90},{"state":"LA","international_plan":"Yes","voice_mail_plan":"No","churn":true,"total_day_calls":69,"total_night_calls":104},{"state":"NY","international_plan":"Yes","voice_mail_plan":"Yes","churn":false,"total_day_calls":120,"total_night_calls":78},{"state":"LA","international_plan":"Yes","voice_mail_plan":"Yes","churn":false,"total_day_calls":71,"total_night_calls":101}]},"total_rows":12,"truncation_type":null},"text/plain":"                                                total_day_calls  total_night_calls\nstate international_plan voice_mail_plan churn                                    \nLA    No                 No              False          106.818             96.909\n                                         True           100.000            119.000\n                         Yes             False          100.000             84.250\nNY    No                 No              False           90.900            100.800\n                                         True            95.000            101.500\n                         Yes             False          115.000            121.000\n      Yes                No              False          109.000             99.000\n                                         True            87.000            113.000\nLA    Yes                No              False           78.000             90.000\n                                         True            69.000            104.000\nNY    Yes                Yes             False          120.000             78.000\nLA    Yes                Yes             False           71.000            101.000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>total_day_calls</th>\n      <th>total_night_calls</th>\n    </tr>\n    <tr>\n      <th>state</th>\n      <th>international_plan</th>\n      <th>voice_mail_plan</th>\n      <th>churn</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">LA</th>\n      <th rowspan=\"3\" valign=\"top\">No</th>\n      <th rowspan=\"2\" valign=\"top\">No</th>\n      <th>False</th>\n      <td>106.818</td>\n      <td>96.909</td>\n    </tr>\n    <tr>\n      <th>True</th>\n      <td>100.000</td>\n      <td>119.000</td>\n    </tr>\n    <tr>\n      <th>Yes</th>\n      <th>False</th>\n      <td>100.000</td>\n      <td>84.250</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">NY</th>\n      <th rowspan=\"3\" valign=\"top\">No</th>\n      <th rowspan=\"2\" valign=\"top\">No</th>\n      <th>False</th>\n      <td>90.900</td>\n      <td>100.800</td>\n    </tr>\n    <tr>\n      <th>True</th>\n      <td>95.000</td>\n      <td>101.500</td>\n    </tr>\n    <tr>\n      <th>Yes</th>\n      <th>False</th>\n      <td>115.000</td>\n      <td>121.000</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">Yes</th>\n      <th rowspan=\"2\" valign=\"top\">No</th>\n      <th>False</th>\n      <td>109.000</td>\n      <td>99.000</td>\n    </tr>\n    <tr>\n      <th>True</th>\n      <td>87.000</td>\n      <td>113.000</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">LA</th>\n      <th rowspan=\"2\" valign=\"top\">Yes</th>\n      <th rowspan=\"2\" valign=\"top\">No</th>\n      <th>False</th>\n      <td>78.000</td>\n      <td>90.000</td>\n    </tr>\n    <tr>\n      <th>True</th>\n      <td>69.000</td>\n      <td>104.000</td>\n    </tr>\n    <tr>\n      <th>NY</th>\n      <th>Yes</th>\n      <th>Yes</th>\n      <th>False</th>\n      <td>120.000</td>\n      <td>78.000</td>\n    </tr>\n    <tr>\n      <th>LA</th>\n      <th>Yes</th>\n      <th>Yes</th>\n      <th>False</th>\n      <td>71.000</td>\n      <td>101.000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"source":"churn_missed_calls.index.names","metadata":{"executionTime":31,"lastSuccessfullyExecutedCode":"churn_missed_calls.index.names"},"cell_type":"code","id":"06ceaede-730b-43e7-bdeb-ac61aa9c8acc","execution_count":33,"outputs":[{"output_type":"execute_result","execution_count":33,"data":{"text/plain":"FrozenList(['state', 'international_plan', 'voice_mail_plan', 'churn'])"},"metadata":{}}]},{"source":"# Unstack churn level and fill missing values with zero\nchurn_mc = churn_missed_calls.unstack(level='churn', fill_value=0)\n\n# Sort by descending voice mail plan and ascending international plan\nchurn_sorted = churn_mc.sort_values(by=['voice_mail_plan', 'international_plan'], \n                          ascending=[False, True])\n\n# Print final DataFrame and observe pattern\ndisplay(churn_sorted)","metadata":{"executionTime":47,"lastSuccessfullyExecutedCode":"# Unstack churn level and fill missing values with zero\nchurn_mc = churn_missed_calls.unstack(level='churn', fill_value=0)\n\n# Sort by descending voice mail plan and ascending international plan\nchurn_sorted = churn_mc.sort_values(by=['voice_mail_plan', 'international_plan'], \n                          ascending=[False, True])\n\n# Print final DataFrame and observe pattern\ndisplay(churn_sorted)"},"cell_type":"code","id":"f6fc0535-48c4-46c0-8015-64d327cc7fba","execution_count":34,"outputs":[{"output_type":"display_data","data":{"text/plain":"                                         total_day_calls  ... total_night_calls\nchurn                                              False  ...             True \nstate international_plan voice_mail_plan                  ...                  \nLA    No                 Yes                     100.000  ...               0.0\nNY    No                 Yes                     115.000  ...               0.0\nLA    Yes                Yes                      71.000  ...               0.0\nNY    Yes                Yes                     120.000  ...               0.0\nLA    No                 No                      106.818  ...             119.0\nNY    No                 No                       90.900  ...             101.5\nLA    Yes                No                       78.000  ...             104.0\nNY    Yes                No                      109.000  ...             113.0\n\n[8 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th colspan=\"2\" halign=\"left\">total_day_calls</th>\n      <th colspan=\"2\" halign=\"left\">total_night_calls</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th></th>\n      <th>churn</th>\n      <th>False</th>\n      <th>True</th>\n      <th>False</th>\n      <th>True</th>\n    </tr>\n    <tr>\n      <th>state</th>\n      <th>international_plan</th>\n      <th>voice_mail_plan</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>LA</th>\n      <th>No</th>\n      <th>Yes</th>\n      <td>100.000</td>\n      <td>0.0</td>\n      <td>84.250</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>NY</th>\n      <th>No</th>\n      <th>Yes</th>\n      <td>115.000</td>\n      <td>0.0</td>\n      <td>121.000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>LA</th>\n      <th>Yes</th>\n      <th>Yes</th>\n      <td>71.000</td>\n      <td>0.0</td>\n      <td>101.000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>NY</th>\n      <th>Yes</th>\n      <th>Yes</th>\n      <td>120.000</td>\n      <td>0.0</td>\n      <td>78.000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>LA</th>\n      <th>No</th>\n      <th>No</th>\n      <td>106.818</td>\n      <td>100.0</td>\n      <td>96.909</td>\n      <td>119.0</td>\n    </tr>\n    <tr>\n      <th>NY</th>\n      <th>No</th>\n      <th>No</th>\n      <td>90.900</td>\n      <td>95.0</td>\n      <td>100.800</td>\n      <td>101.5</td>\n    </tr>\n    <tr>\n      <th>LA</th>\n      <th>Yes</th>\n      <th>No</th>\n      <td>78.000</td>\n      <td>69.0</td>\n      <td>90.000</td>\n      <td>104.0</td>\n    </tr>\n    <tr>\n      <th>NY</th>\n      <th>Yes</th>\n      <th>No</th>\n      <td>109.000</td>\n      <td>87.0</td>\n      <td>99.000</td>\n      <td>113.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"source":"* Note here that the `sort_values` call accepts **index_levels** when axis=0 or the default argument for the method","metadata":{},"cell_type":"markdown","id":"99c75cb8-488d-4b88-ba41-749a7387ebbf"},{"source":"### Don't drop the stack\nIt's almost time to go home, but first, you need to finish your last task. You have a small dataset containing the total number of calls made by customers.\n\nTo perform your analysis, you need to reshape your churn data by stacking different levels. You know this process will generate missing data. You want to check if it is worth keeping the rows that contain all missing values, or if it's better to drop that information.\n\nThe churn DataFrame is available for you.\n\n```python\nIn [1]:\nchurn\nOut[1]:\n\ntype  total_day_calls total_night_calls         \nscope   international     international national\nLA                 23                30      NaN\nNY                  8                34     24.0\nCA                  8                34     24.0\nIn [2]:\nchurn.columns\nOut[2]:\n\nMultiIndex([(  'total_day_calls', 'international'),\n            ('total_night_calls', 'international'),\n            ('total_night_calls',      'national')],\n           names=['type', 'scope'])\n```\n\n* Reshape the churn DataFrame by stacking the type level. Then, fill the missing values generated with the value zero.\n\n```python\n# Stack the level type from churn\nchurn_stack = churn.stack(level='type')\n\n# Fill the resulting missing values with zero \nchurn_fill = churn_stack.fillna(0)\n\n# Print churn_fill\nprint(churn_fill)\n\nscope                 international  national\n   type                                      \nLA total_day_calls               23       0.0\n   total_night_calls             30       0.0\nNY total_day_calls                8       0.0\n   total_night_calls             34      24.0\nCA total_day_calls                8       0.0\n   total_night_calls             34      24.0\n```\n\n* Stack the scope level of churn without dropping the rows with missing values. Then, fill the missing values with zero.\n\n```python\n# Stack the level scope without dropping rows with missing values\nchurn_stack = churn.stack(level='scope', dropna=False)\n\n# Fill the resulting missing values with zero\nchurn_fill = churn_stack.fillna(0)\n\n# Print churn_fill\nprint(churn_fill)\n\ntype              total_day_calls  total_night_calls\n   scope                                            \nLA international             23.0               30.0\n   national                   0.0                0.0\nNY international              8.0               34.0\n   national                   0.0               24.0\nCA international              8.0               34.0\n   national                   0.0               24.0\n```","metadata":{},"cell_type":"markdown","id":"967679c8-bb48-43a7-9fde-e6d569d44f05"},{"source":"### Advanced Reshaping\nYou'll finish by learning how to combine the reshaping process with grouping to produce quick data manipulations. Lastly, you'll discover how to transform list-like columns and handle complex nested data, such as nested JSON files.","metadata":{},"cell_type":"markdown","id":"1fc393ba-9738-4106-bab1-4bf2c502115a"},{"source":"obesity = pd.read_csv('datasets/obesity_list.csv')\nobesity","metadata":{"executionTime":120,"lastSuccessfullyExecutedCode":"obesity = pd.read_csv('datasets/obesity_list.csv')\nobesity"},"cell_type":"code","id":"180d7cc3-b781-466a-86e7-2e146db0e7d6","execution_count":36,"outputs":[{"output_type":"execute_result","execution_count":36,"data":{"application/com.datacamp.data-table.v1+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"country","type":"string"},{"name":"perc_obesity","type":"number"},{"name":"bounds","type":"string"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":[{"index":0,"country":"Argentina","perc_obesity":21.5,"bounds":"[15.4, 31.5]"},{"index":1,"country":"Germany","perc_obesity":22.3,"bounds":"[16.2, 32.4]"},{"index":2,"country":"Japan","perc_obesity":2.5,"bounds":"[1.1, 3.5]"},{"index":3,"country":"Norway","perc_obesity":23,"bounds":"[13.1, 33.0]"}]},"total_rows":4,"truncation_type":null},"text/plain":"     country  perc_obesity        bounds\n0  Argentina          21.5  [15.4, 31.5]\n1    Germany          22.3  [16.2, 32.4]\n2      Japan           2.5    [1.1, 3.5]\n3     Norway          23.0  [13.1, 33.0]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>country</th>\n      <th>perc_obesity</th>\n      <th>bounds</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Argentina</td>\n      <td>21.5</td>\n      <td>[15.4, 31.5]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Germany</td>\n      <td>22.3</td>\n      <td>[16.2, 32.4]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Japan</td>\n      <td>2.5</td>\n      <td>[1.1, 3.5]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Norway</td>\n      <td>23.0</td>\n      <td>[13.1, 33.0]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"source":"* We'll that's not the dataframe we're using","metadata":{},"cell_type":"markdown","id":"1eb4878a-3ec1-4f5e-9e22-98794ae87cde"},{"source":"obesity_idx_arrays = [['Argentina', 'Argentina', 'Argentina', 'Argentina', 'Japan', 'Japan', 'Japan', 'Japan', 'Norway', 'Norway',                          'Norway', 'Norway'],\n                     ['Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female'],\n                     [2005, 2005, 2015, 2015, 2005, 2005, 2015, 2015, 2005, 2005, 2015, 2015]]\nobesity_idx_mt = pd.MultiIndex.from_arrays(obesity_idx_arrays, names=['country', 'biological_sex', 'year'])\nobesity = pd.DataFrame({\n    'perc_obesity':[21.5, 24.2, 26.8, 28.5, 2.5, 2.6, 4.6, 3.6, 17.6, 18.6, 23.0, 22.2]\n}, index=obesity_idx_mt)\ndisplay(obesity)","metadata":{"executionTime":138,"lastSuccessfullyExecutedCode":"obesity_idx_arrays = [['Argentina', 'Argentina', 'Argentina', 'Argentina', 'Japan', 'Japan', 'Japan', 'Japan', 'Norway', 'Norway',                          'Norway', 'Norway'],\n                     ['Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female'],\n                     [2005, 2005, 2015, 2015, 2005, 2005, 2015, 2015, 2005, 2005, 2015, 2015]]\nobesity_idx_mt = pd.MultiIndex.from_arrays(obesity_idx_arrays, names=['country', 'biological_sex', 'year'])\nobesity = pd.DataFrame({\n    'perc_obesity':[21.5, 24.2, 26.8, 28.5, 2.5, 2.6, 4.6, 3.6, 17.6, 18.6, 23.0, 22.2]\n}, index=obesity_idx_mt)\ndisplay(obesity)"},"cell_type":"code","id":"388fceae-e036-44b6-956b-e5ae4994d525","execution_count":37,"outputs":[{"output_type":"display_data","data":{"application/com.datacamp.data-table.v1+json":{"table":{"schema":{"fields":[{"name":"country","type":"string"},{"name":"biological_sex","type":"string"},{"name":"year","type":"integer"},{"name":"perc_obesity","type":"number"}],"primaryKey":["country","biological_sex","year"],"pandas_version":"1.4.0"},"data":[{"country":"Argentina","biological_sex":"Male","year":2005,"perc_obesity":21.5},{"country":"Argentina","biological_sex":"Female","year":2005,"perc_obesity":24.2},{"country":"Argentina","biological_sex":"Male","year":2015,"perc_obesity":26.8},{"country":"Argentina","biological_sex":"Female","year":2015,"perc_obesity":28.5},{"country":"Japan","biological_sex":"Male","year":2005,"perc_obesity":2.5},{"country":"Japan","biological_sex":"Female","year":2005,"perc_obesity":2.6},{"country":"Japan","biological_sex":"Male","year":2015,"perc_obesity":4.6},{"country":"Japan","biological_sex":"Female","year":2015,"perc_obesity":3.6},{"country":"Norway","biological_sex":"Male","year":2005,"perc_obesity":17.6},{"country":"Norway","biological_sex":"Female","year":2005,"perc_obesity":18.6},{"country":"Norway","biological_sex":"Male","year":2015,"perc_obesity":23},{"country":"Norway","biological_sex":"Female","year":2015,"perc_obesity":22.2}]},"total_rows":12,"truncation_type":null},"text/plain":"                               perc_obesity\ncountry   biological_sex year              \nArgentina Male           2005          21.5\n          Female         2005          24.2\n          Male           2015          26.8\n          Female         2015          28.5\nJapan     Male           2005           2.5\n          Female         2005           2.6\n          Male           2015           4.6\n          Female         2015           3.6\nNorway    Male           2005          17.6\n          Female         2005          18.6\n          Male           2015          23.0\n          Female         2015          22.2","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>perc_obesity</th>\n    </tr>\n    <tr>\n      <th>country</th>\n      <th>biological_sex</th>\n      <th>year</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"4\" valign=\"top\">Argentina</th>\n      <th>Male</th>\n      <th>2005</th>\n      <td>21.5</td>\n    </tr>\n    <tr>\n      <th>Female</th>\n      <th>2005</th>\n      <td>24.2</td>\n    </tr>\n    <tr>\n      <th>Male</th>\n      <th>2015</th>\n      <td>26.8</td>\n    </tr>\n    <tr>\n      <th>Female</th>\n      <th>2015</th>\n      <td>28.5</td>\n    </tr>\n    <tr>\n      <th rowspan=\"4\" valign=\"top\">Japan</th>\n      <th>Male</th>\n      <th>2005</th>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>Female</th>\n      <th>2005</th>\n      <td>2.6</td>\n    </tr>\n    <tr>\n      <th>Male</th>\n      <th>2015</th>\n      <td>4.6</td>\n    </tr>\n    <tr>\n      <th>Female</th>\n      <th>2015</th>\n      <td>3.6</td>\n    </tr>\n    <tr>\n      <th rowspan=\"4\" valign=\"top\">Norway</th>\n      <th>Male</th>\n      <th>2005</th>\n      <td>17.6</td>\n    </tr>\n    <tr>\n      <th>Female</th>\n      <th>2005</th>\n      <td>18.6</td>\n    </tr>\n    <tr>\n      <th>Male</th>\n      <th>2015</th>\n      <td>23.0</td>\n    </tr>\n    <tr>\n      <th>Female</th>\n      <th>2015</th>\n      <td>22.2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"source":"# Unstack the first level and calculate the mean of the columns (odd as what they want is the mean for each sex_year over the countries for the answer ... not the columns which suggest the country unstacked from the index)\nobesity_general = obesity.unstack(level=0)\n\n# Print obesity_general\nprint(obesity_general, '\\n', obesity_general.mean(axis=1), '\\n', obesity_general.mean(axis=0), '\\n')\n\n# Accurate per dcamp\nobesity_general_dc = obesity.unstack(level=0).mean(axis=1)\nprint(obesity_general_dc)","metadata":{"executionTime":64,"lastSuccessfullyExecutedCode":"# Unstack the first level and calculate the mean of the columns (odd as what they want is the mean for each sex_year over the countries for the answer ... not the columns which suggest the country unstacked from the index)\nobesity_general = obesity.unstack(level=0)\n\n# Print obesity_general\nprint(obesity_general, '\\n', obesity_general.mean(axis=1), '\\n', obesity_general.mean(axis=0), '\\n')\n\n# Accurate per dcamp\nobesity_general_dc = obesity.unstack(level=0).mean(axis=1)\nprint(obesity_general_dc)"},"cell_type":"code","id":"fbcbacdb-6bbb-45f3-a975-6c6707d0179a","execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":"                    perc_obesity             \ncountry                Argentina Japan Norway\nbiological_sex year                          \nFemale         2005         24.2   2.6   18.6\n               2015         28.5   3.6   22.2\nMale           2005         21.5   2.5   17.6\n               2015         26.8   4.6   23.0 \n biological_sex  year\nFemale          2005    15.133333\n                2015    18.100000\nMale            2005    13.866667\n                2015    18.133333\ndtype: float64 \n               country  \nperc_obesity  Argentina    25.250\n              Japan         3.325\n              Norway       20.350\ndtype: float64 \n\nbiological_sex  year\nFemale          2005    15.133333\n                2015    18.100000\nMale            2005    13.866667\n                2015    18.133333\ndtype: float64\n"}]},{"source":"# Unstack the second level and calculate the mean of the columns\nobesity_mean = obesity.unstack(level='biological_sex').mean(axis=1)\n\n# Print obesity_mean\nprint(obesity.unstack(level='biological_sex'), '\\n',obesity_mean)","metadata":{"executionTime":53,"lastSuccessfullyExecutedCode":"# Unstack the second level and calculate the mean of the columns\nobesity_mean = obesity.unstack(level='biological_sex').mean(axis=1)\n\n# Print obesity_mean\nprint(obesity.unstack(level='biological_sex'), '\\n',obesity_mean)"},"cell_type":"code","id":"19671367-d641-4dde-a5d6-573c320d12c5","execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":"               perc_obesity      \nbiological_sex       Female  Male\ncountry   year                   \nArgentina 2005         24.2  21.5\n          2015         28.5  26.8\nJapan     2005          2.6   2.5\n          2015          3.6   4.6\nNorway    2005         18.6  17.6\n          2015         22.2  23.0 \n country    year\nArgentina  2005    22.85\n           2015    27.65\nJapan      2005     2.55\n           2015     4.10\nNorway     2005    18.10\n           2015    22.60\ndtype: float64\n"}]},{"source":"# Unstack the third level and calculate the difference between columns\nobesity_variation = obesity.unstack(level=-1).diff(axis=1)\n\n# Print obesity_variation\nprint(obesity.unstack(level=-1), '\\n\\n', obesity_variation)","metadata":{"executionTime":111,"lastSuccessfullyExecutedCode":"# Unstack the third level and calculate the difference between columns\nobesity_variation = obesity.unstack(level=-1).diff(axis=1)\n\n# Print obesity_variation\nprint(obesity.unstack(level=-1), '\\n\\n', obesity_variation)"},"cell_type":"code","id":"95d3185b-c7d3-4404-ac87-0cb582c075ca","execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":"                         perc_obesity      \nyear                             2005  2015\ncountry   biological_sex                   \nArgentina Female                 24.2  28.5\n          Male                   21.5  26.8\nJapan     Female                  2.6   3.6\n          Male                    2.5   4.6\nNorway    Female                 18.6  22.2\n          Male                   17.6  23.0 \n\n                          perc_obesity     \nyear                             2005 2015\ncountry   biological_sex                  \nArgentina Female                  NaN  4.3\n          Male                    NaN  5.3\nJapan     Female                  NaN  1.0\n          Male                    NaN  2.1\nNorway    Female                  NaN  3.6\n          Male                    NaN  5.4\n"}]},{"source":"### Only going up\nAfter your last analysis, you are excited to keep working with the obesity dataset. You have added an extra column, the variation column, which indicates the range in which the percentage varies through regions in the same country. You are not sure if the mean is the best metric to summarize obesity levels.\n\nSo you decide to explore the median percentage and variation of obesity by year and biological sex. Also, you want to get the maximum percentage observed by country, year, and biological sex.","metadata":{},"cell_type":"markdown","id":"90ae3b98-f0b5-4e4b-a83f-a36e198f6369"},{"source":"obesity_2_idx_vals = [['France', 'France', 'France', 'France', 'Germany', 'Germany', 'Germany', 'Germany'],\n                     ['Female', 'Female', 'Male', 'Male', 'Female', 'Female', 'Male', 'Male'],\n                     ['perc_obesity', 'variation', 'perc_obesity', 'variation', 'perc_obesity', 'variation', 'perc_obesity', 'variation']]\nobesity_2_idx_vals_midx = pd.MultiIndex.from_arrays(obesity_2_idx_vals, names=['country', 'biological_sex', None])\nobesity_2_df = pd.DataFrame({\n    1995:[15.3,  7.7, 12.8,  7.6, 14.4,  4.6, 14.4,  5.1],\n    2005:[18.1,  8.2, 16.9,  8.4, 17.2,  5.2, 18.7,  5.9],\n    2015:[20.8, 11.3, 21.5, 11.8, 20.1,  8.4, 23.6,  9.8]\n},index=obesity_2_idx_vals_midx)\nobesity_2_df.columns.name = 'year'\ndisplay(obesity_2_df)","metadata":{"executionTime":139,"lastSuccessfullyExecutedCode":"obesity_2_idx_vals = [['France', 'France', 'France', 'France', 'Germany', 'Germany', 'Germany', 'Germany'],\n                     ['Female', 'Female', 'Male', 'Male', 'Female', 'Female', 'Male', 'Male'],\n                     ['perc_obesity', 'variation', 'perc_obesity', 'variation', 'perc_obesity', 'variation', 'perc_obesity', 'variation']]\nobesity_2_idx_vals_midx = pd.MultiIndex.from_arrays(obesity_2_idx_vals, names=['country', 'biological_sex', None])\nobesity_2_df = pd.DataFrame({\n    1995:[15.3,  7.7, 12.8,  7.6, 14.4,  4.6, 14.4,  5.1],\n    2005:[18.1,  8.2, 16.9,  8.4, 17.2,  5.2, 18.7,  5.9],\n    2015:[20.8, 11.3, 21.5, 11.8, 20.1,  8.4, 23.6,  9.8]\n},index=obesity_2_idx_vals_midx)\nobesity_2_df.columns.name = 'year'\ndisplay(obesity_2_df)"},"cell_type":"code","id":"5c803149-29e7-43ca-b7b2-a995144812df","execution_count":50,"outputs":[{"output_type":"display_data","data":{"application/com.datacamp.data-table.v1+json":{"table":{"schema":{"fields":[{"name":"country","type":"string"},{"name":"biological_sex","type":"string"},{"name":"level_2","type":"string"},{"name":1995,"type":"number"},{"name":2005,"type":"number"},{"name":2015,"type":"number"}],"primaryKey":["country","biological_sex","level_2"],"pandas_version":"1.4.0"},"data":[{"1995":15.3,"2005":18.1,"2015":20.8,"country":"France","biological_sex":"Female","level_2":"perc_obesity"},{"1995":7.7,"2005":8.2,"2015":11.3,"country":"France","biological_sex":"Female","level_2":"variation"},{"1995":12.8,"2005":16.9,"2015":21.5,"country":"France","biological_sex":"Male","level_2":"perc_obesity"},{"1995":7.6,"2005":8.4,"2015":11.8,"country":"France","biological_sex":"Male","level_2":"variation"},{"1995":14.4,"2005":17.2,"2015":20.1,"country":"Germany","biological_sex":"Female","level_2":"perc_obesity"},{"1995":4.6,"2005":5.2,"2015":8.4,"country":"Germany","biological_sex":"Female","level_2":"variation"},{"1995":14.4,"2005":18.7,"2015":23.6,"country":"Germany","biological_sex":"Male","level_2":"perc_obesity"},{"1995":5.1,"2005":5.9,"2015":9.8,"country":"Germany","biological_sex":"Male","level_2":"variation"}]},"total_rows":8,"truncation_type":null},"text/plain":"year                                 1995  2005  2015\ncountry biological_sex                               \nFrance  Female         perc_obesity  15.3  18.1  20.8\n                       variation      7.7   8.2  11.3\n        Male           perc_obesity  12.8  16.9  21.5\n                       variation      7.6   8.4  11.8\nGermany Female         perc_obesity  14.4  17.2  20.1\n                       variation      4.6   5.2   8.4\n        Male           perc_obesity  14.4  18.7  23.6\n                       variation      5.1   5.9   9.8","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>year</th>\n      <th>1995</th>\n      <th>2005</th>\n      <th>2015</th>\n    </tr>\n    <tr>\n      <th>country</th>\n      <th>biological_sex</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"4\" valign=\"top\">France</th>\n      <th rowspan=\"2\" valign=\"top\">Female</th>\n      <th>perc_obesity</th>\n      <td>15.3</td>\n      <td>18.1</td>\n      <td>20.8</td>\n    </tr>\n    <tr>\n      <th>variation</th>\n      <td>7.7</td>\n      <td>8.2</td>\n      <td>11.3</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">Male</th>\n      <th>perc_obesity</th>\n      <td>12.8</td>\n      <td>16.9</td>\n      <td>21.5</td>\n    </tr>\n    <tr>\n      <th>variation</th>\n      <td>7.6</td>\n      <td>8.4</td>\n      <td>11.8</td>\n    </tr>\n    <tr>\n      <th rowspan=\"4\" valign=\"top\">Germany</th>\n      <th rowspan=\"2\" valign=\"top\">Female</th>\n      <th>perc_obesity</th>\n      <td>14.4</td>\n      <td>17.2</td>\n      <td>20.1</td>\n    </tr>\n    <tr>\n      <th>variation</th>\n      <td>4.6</td>\n      <td>5.2</td>\n      <td>8.4</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">Male</th>\n      <th>perc_obesity</th>\n      <td>14.4</td>\n      <td>18.7</td>\n      <td>23.6</td>\n    </tr>\n    <tr>\n      <th>variation</th>\n      <td>5.1</td>\n      <td>5.9</td>\n      <td>9.8</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"source":"obesity_2_us_vals = obesity_2_df.unstack(level=-1)\nobesity_2_us_vals","metadata":{"executionTime":199,"lastSuccessfullyExecutedCode":"obesity_2_us_vals = obesity_2_df.unstack(level=-1)\nobesity_2_us_vals"},"cell_type":"code","id":"f695a6ac-f79b-40c9-bc40-c921aab5c78e","execution_count":51,"outputs":[{"output_type":"execute_result","execution_count":51,"data":{"text/plain":"year                           1995            ...         2015          \n                       perc_obesity variation  ... perc_obesity variation\ncountry biological_sex                         ...                       \nFrance  Female                 15.3       7.7  ...         20.8      11.3\n        Male                   12.8       7.6  ...         21.5      11.8\nGermany Female                 14.4       4.6  ...         20.1       8.4\n        Male                   14.4       5.1  ...         23.6       9.8\n\n[4 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th>year</th>\n      <th colspan=\"2\" halign=\"left\">1995</th>\n      <th colspan=\"2\" halign=\"left\">2005</th>\n      <th colspan=\"2\" halign=\"left\">2015</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th></th>\n      <th>perc_obesity</th>\n      <th>variation</th>\n      <th>perc_obesity</th>\n      <th>variation</th>\n      <th>perc_obesity</th>\n      <th>variation</th>\n    </tr>\n    <tr>\n      <th>country</th>\n      <th>biological_sex</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">France</th>\n      <th>Female</th>\n      <td>15.3</td>\n      <td>7.7</td>\n      <td>18.1</td>\n      <td>8.2</td>\n      <td>20.8</td>\n      <td>11.3</td>\n    </tr>\n    <tr>\n      <th>Male</th>\n      <td>12.8</td>\n      <td>7.6</td>\n      <td>16.9</td>\n      <td>8.4</td>\n      <td>21.5</td>\n      <td>11.8</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">Germany</th>\n      <th>Female</th>\n      <td>14.4</td>\n      <td>4.6</td>\n      <td>17.2</td>\n      <td>5.2</td>\n      <td>20.1</td>\n      <td>8.4</td>\n    </tr>\n    <tr>\n      <th>Male</th>\n      <td>14.4</td>\n      <td>5.1</td>\n      <td>18.7</td>\n      <td>5.9</td>\n      <td>23.6</td>\n      <td>9.8</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"source":"# Stack obesity, get median of columns and unstack again (again of the column is unstacked by the row)\nmedian_obesity = obesity_2_us_vals.stack(level=-1).median(axis=1).unstack()\ndisplay(median_obesity)\n\nprint('\\n', obesity_2_us_vals.stack(level=-1))","metadata":{"executionTime":101,"lastSuccessfullyExecutedCode":"# Stack obesity, get median of columns and unstack again (again of the column is unstacked by the row)\nmedian_obesity = obesity_2_us_vals.stack(level=-1).median(axis=1).unstack()\ndisplay(median_obesity)\n\nprint('\\n', obesity_2_us_vals.stack(level=-1))"},"cell_type":"code","id":"16ef1a42-6f3b-4f92-a4b7-5f5a37a9162f","execution_count":54,"outputs":[{"output_type":"display_data","data":{"application/com.datacamp.data-table.v1+json":{"table":{"schema":{"fields":[{"name":"country","type":"string"},{"name":"biological_sex","type":"string"},{"name":"perc_obesity","type":"number"},{"name":"variation","type":"number"}],"primaryKey":["country","biological_sex"],"pandas_version":"1.4.0"},"data":[{"country":"France","biological_sex":"Female","perc_obesity":18.1,"variation":8.2},{"country":"France","biological_sex":"Male","perc_obesity":16.9,"variation":8.4},{"country":"Germany","biological_sex":"Female","perc_obesity":17.2,"variation":5.2},{"country":"Germany","biological_sex":"Male","perc_obesity":18.7,"variation":5.9}]},"total_rows":4,"truncation_type":null},"text/plain":"                        perc_obesity  variation\ncountry biological_sex                         \nFrance  Female                  18.1        8.2\n        Male                    16.9        8.4\nGermany Female                  17.2        5.2\n        Male                    18.7        5.9","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>perc_obesity</th>\n      <th>variation</th>\n    </tr>\n    <tr>\n      <th>country</th>\n      <th>biological_sex</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">France</th>\n      <th>Female</th>\n      <td>18.1</td>\n      <td>8.2</td>\n    </tr>\n    <tr>\n      <th>Male</th>\n      <td>16.9</td>\n      <td>8.4</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">Germany</th>\n      <th>Female</th>\n      <td>17.2</td>\n      <td>5.2</td>\n    </tr>\n    <tr>\n      <th>Male</th>\n      <td>18.7</td>\n      <td>5.9</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n year                                 1995  2005  2015\ncountry biological_sex                               \nFrance  Female         perc_obesity  15.3  18.1  20.8\n                       variation      7.7   8.2  11.3\n        Male           perc_obesity  12.8  16.9  21.5\n                       variation      7.6   8.4  11.8\nGermany Female         perc_obesity  14.4  17.2  20.1\n                       variation      4.6   5.2   8.4\n        Male           perc_obesity  14.4  18.7  23.6\n                       variation      5.1   5.9   9.8\n"}]},{"source":"# Stack obesity by the first level (year col value of obesity_2_us_vals dframe - that frame matches their obesity frame from exercises , get the sum of the columns, and finally, unstack the DataFrame by the second level.\nobesity_sum = obesity_2_us_vals.stack(level=0)\ndisplay(obesity_sum)\n\nobesity_sum = obesity_2_us_vals.stack(level=0).sum(axis=1)\nprint('\\n')\ndisplay(obesity_sum)\n\nprint('\\n')\ndisplay(obesity_sum.unstack(level=1))","metadata":{"executionTime":182,"lastSuccessfullyExecutedCode":"# Stack obesity by the first level (year col value of obesity_2_us_vals dframe - that frame matches their obesity frame from exercises , get the sum of the columns, and finally, unstack the DataFrame by the second level.\nobesity_sum = obesity_2_us_vals.stack(level=0)\ndisplay(obesity_sum)\n\nobesity_sum = obesity_2_us_vals.stack(level=0).sum(axis=1)\nprint('\\n')\ndisplay(obesity_sum)\n\nprint('\\n')\ndisplay(obesity_sum.unstack(level=1))"},"cell_type":"code","id":"2d0bc4f0-576b-4871-8f8d-99a92b785819","execution_count":60,"outputs":[{"output_type":"display_data","data":{"application/com.datacamp.data-table.v1+json":{"table":{"schema":{"fields":[{"name":"country","type":"string"},{"name":"biological_sex","type":"string"},{"name":"year","type":"integer"},{"name":"perc_obesity","type":"number"},{"name":"variation","type":"number"}],"primaryKey":["country","biological_sex","year"],"pandas_version":"1.4.0"},"data":[{"country":"France","biological_sex":"Female","year":1995,"perc_obesity":15.3,"variation":7.7},{"country":"France","biological_sex":"Female","year":2005,"perc_obesity":18.1,"variation":8.2},{"country":"France","biological_sex":"Female","year":2015,"perc_obesity":20.8,"variation":11.3},{"country":"France","biological_sex":"Male","year":1995,"perc_obesity":12.8,"variation":7.6},{"country":"France","biological_sex":"Male","year":2005,"perc_obesity":16.9,"variation":8.4},{"country":"France","biological_sex":"Male","year":2015,"perc_obesity":21.5,"variation":11.8},{"country":"Germany","biological_sex":"Female","year":1995,"perc_obesity":14.4,"variation":4.6},{"country":"Germany","biological_sex":"Female","year":2005,"perc_obesity":17.2,"variation":5.2},{"country":"Germany","biological_sex":"Female","year":2015,"perc_obesity":20.1,"variation":8.4},{"country":"Germany","biological_sex":"Male","year":1995,"perc_obesity":14.4,"variation":5.1},{"country":"Germany","biological_sex":"Male","year":2005,"perc_obesity":18.7,"variation":5.9},{"country":"Germany","biological_sex":"Male","year":2015,"perc_obesity":23.6,"variation":9.8}]},"total_rows":12,"truncation_type":null},"text/plain":"                             perc_obesity  variation\ncountry biological_sex year                         \nFrance  Female         1995          15.3        7.7\n                       2005          18.1        8.2\n                       2015          20.8       11.3\n        Male           1995          12.8        7.6\n                       2005          16.9        8.4\n                       2015          21.5       11.8\nGermany Female         1995          14.4        4.6\n                       2005          17.2        5.2\n                       2015          20.1        8.4\n        Male           1995          14.4        5.1\n                       2005          18.7        5.9\n                       2015          23.6        9.8","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>perc_obesity</th>\n      <th>variation</th>\n    </tr>\n    <tr>\n      <th>country</th>\n      <th>biological_sex</th>\n      <th>year</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"6\" valign=\"top\">France</th>\n      <th rowspan=\"3\" valign=\"top\">Female</th>\n      <th>1995</th>\n      <td>15.3</td>\n      <td>7.7</td>\n    </tr>\n    <tr>\n      <th>2005</th>\n      <td>18.1</td>\n      <td>8.2</td>\n    </tr>\n    <tr>\n      <th>2015</th>\n      <td>20.8</td>\n      <td>11.3</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">Male</th>\n      <th>1995</th>\n      <td>12.8</td>\n      <td>7.6</td>\n    </tr>\n    <tr>\n      <th>2005</th>\n      <td>16.9</td>\n      <td>8.4</td>\n    </tr>\n    <tr>\n      <th>2015</th>\n      <td>21.5</td>\n      <td>11.8</td>\n    </tr>\n    <tr>\n      <th rowspan=\"6\" valign=\"top\">Germany</th>\n      <th rowspan=\"3\" valign=\"top\">Female</th>\n      <th>1995</th>\n      <td>14.4</td>\n      <td>4.6</td>\n    </tr>\n    <tr>\n      <th>2005</th>\n      <td>17.2</td>\n      <td>5.2</td>\n    </tr>\n    <tr>\n      <th>2015</th>\n      <td>20.1</td>\n      <td>8.4</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">Male</th>\n      <th>1995</th>\n      <td>14.4</td>\n      <td>5.1</td>\n    </tr>\n    <tr>\n      <th>2005</th>\n      <td>18.7</td>\n      <td>5.9</td>\n    </tr>\n    <tr>\n      <th>2015</th>\n      <td>23.6</td>\n      <td>9.8</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n\n"},{"output_type":"display_data","data":{"text/plain":"country  biological_sex  year\nFrance   Female          1995    23.0\n                         2005    26.3\n                         2015    32.1\n         Male            1995    20.4\n                         2005    25.3\n                         2015    33.3\nGermany  Female          1995    19.0\n                         2005    22.4\n                         2015    28.5\n         Male            1995    19.5\n                         2005    24.6\n                         2015    33.4\ndtype: float64"},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n\n"},{"output_type":"display_data","data":{"application/com.datacamp.data-table.v1+json":{"table":{"schema":{"fields":[{"name":"country","type":"string"},{"name":"year","type":"integer"},{"name":"Female","type":"number"},{"name":"Male","type":"number"}],"primaryKey":["country","year"],"pandas_version":"1.4.0"},"data":[{"country":"France","year":1995,"Female":23,"Male":20.4},{"country":"France","year":2005,"Female":26.3,"Male":25.3},{"country":"France","year":2015,"Female":32.1,"Male":33.3},{"country":"Germany","year":1995,"Female":19,"Male":19.5},{"country":"Germany","year":2005,"Female":22.4,"Male":24.6},{"country":"Germany","year":2015,"Female":28.5,"Male":33.4}]},"total_rows":6,"truncation_type":null},"text/plain":"biological_sex  Female  Male\ncountry year                \nFrance  1995      23.0  20.4\n        2005      26.3  25.3\n        2015      32.1  33.3\nGermany 1995      19.0  19.5\n        2005      22.4  24.6\n        2015      28.5  33.4","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>biological_sex</th>\n      <th>Female</th>\n      <th>Male</th>\n    </tr>\n    <tr>\n      <th>country</th>\n      <th>year</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">France</th>\n      <th>1995</th>\n      <td>23.0</td>\n      <td>20.4</td>\n    </tr>\n    <tr>\n      <th>2005</th>\n      <td>26.3</td>\n      <td>25.3</td>\n    </tr>\n    <tr>\n      <th>2015</th>\n      <td>32.1</td>\n      <td>33.3</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">Germany</th>\n      <th>1995</th>\n      <td>19.0</td>\n      <td>19.5</td>\n    </tr>\n    <tr>\n      <th>2005</th>\n      <td>22.4</td>\n      <td>24.6</td>\n    </tr>\n    <tr>\n      <th>2015</th>\n      <td>28.5</td>\n      <td>33.4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"source":"### A group analysis\nYou are almost done working for the day, but there is an extra analysis you want to do. You want to know if the mean and median percentage of obesity by country are different.\n\nYou analyze the DataFrame obesity. You realize that country is part of the column labels, so you need to reshape the DataFrame so country is part of the index.\n\nYou want to take a different approach. You will perform the desired calculations, combining the stacking process and .groupby() function.\n\nThe obesity DataFrame is available in your session.\n\n```python\nn [1]:\nobesity\nOut[1]:\n                    perc_obesity              \ncountry                Argentina Brazil France\nyear biological_sex                           \n1995 Female                 20.2   15.3   15.3\n     Male                   16.8    8.9   12.8\n2005 Female                 24.2   20.1   18.1\n     Male                   21.5   13.2   16.9\n2015 Female                 28.5   24.9   20.8\n     Male                   26.8   18.0   21.5\n```\n* dataframe we'll be working on \n\n* Stack the country level of obesity, group it by country, and take the mean of all the columns.\n```python\nobesity_mean = obesity.stack(level='country')\n\nobesity.stack(level='country')\nOut[5]:\n\n                               perc_obesity\nyear biological_sex country                \n1995 Female         Argentina          20.2\n                    Brazil             15.3\n                    France             15.3\n     Male           Argentina          16.8\n                    Brazil              8.9\n                    France             12.8\n2005 Female         Argentina          24.2\n                    Brazil             20.1\n                    France             18.1\n     Male           Argentina          21.5\n                    Brazil             13.2\n                    France             16.9\n2015 Female         Argentina          28.5\n                    Brazil             24.9\n                    France             20.8\n     Male           Argentina          26.8\n                    Brazil             18.0\n                    France             21.5\n            \nobesity_mean = obesity.stack(level='country').groupby('country').mean()\n\nprint(obesity_mean)\n           perc_obesity\ncountry                \nArgentina        23.000\nBrazil           16.733\nFrance           17.567\n```\n\n* Stack the country level of obesity, group by country, and take the median of all the columns.\n\n```python\nobesity_median = obesity.stack(level='country').groupby('country').median()\nprint(obesity_median)\n\n           perc_obesity\ncountry                \nArgentina         22.85\nBrazil            16.65\nFrance            17.50\n```","metadata":{},"cell_type":"markdown","id":"e7f44562-df82-4a40-8f42-d5b2c9419b2b"},{"source":"### Merge it all\nTime to keep working with the obesity project! You will analyze the mean obesity percentage in different countries, but this time, the obesity DataFrame has a new column named bounds. It contains the minimum and maximum values you can find in different parts of the same country.\n\nYou notice that these values are given in a list, so you decide that you need to transform that column. You would like to have each element in a new row.\n\n```python\nIn [1]:\nobesity\nOut[1]:\n\n     country  perc_obesity        bounds\n0  Argentina          21.5  [15.4, 31.5]\n1    Germany          22.3  [16.2, 32.4]\n2      Japan           2.5    [1.1, 3.5]\n3     Norway          23.0  [13.1, 33.0]\n```","metadata":{},"cell_type":"markdown","id":"af2a4f1e-46ee-4677-a023-d49bdf8ca028"},{"source":"obesity = pd.DataFrame({\n    'country':['Argentina', 'Germany', 'Japan', 'Norway'],\n    'perc_obesity':[21.5, 22.3, 2.5, 23.0],\n    'bounds':[[15.4, 31.5], [16.2, 32.4], [1.1, 3.5], [13.1, 33.0]]\n})\ndisplay(obesity)\n\n# Explode the values of bounds to a separate row\nobesity_bounds = obesity['bounds'].explode()\n\nprint('\\n', obesity_bounds)","metadata":{"executionTime":109,"lastSuccessfullyExecutedCode":"obesity = pd.DataFrame({\n    'country':['Argentina', 'Germany', 'Japan', 'Norway'],\n    'perc_obesity':[21.5, 22.3, 2.5, 23.0],\n    'bounds':[[15.4, 31.5], [16.2, 32.4], [1.1, 3.5], [13.1, 33.0]]\n})\ndisplay(obesity)\n\n# Explode the values of bounds to a separate row\nobesity_bounds = obesity['bounds'].explode()\n\nprint('\\n', obesity_bounds)"},"cell_type":"code","id":"e129dab0-1d23-43ef-b49e-65347077ce8d","execution_count":62,"outputs":[{"output_type":"display_data","data":{"application/com.datacamp.data-table.v1+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"country","type":"string"},{"name":"perc_obesity","type":"number"},{"name":"bounds","type":"string"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":[{"index":0,"country":"Argentina","perc_obesity":21.5,"bounds":[15.4,31.5]},{"index":1,"country":"Germany","perc_obesity":22.3,"bounds":[16.2,32.4]},{"index":2,"country":"Japan","perc_obesity":2.5,"bounds":[1.1,3.5]},{"index":3,"country":"Norway","perc_obesity":23,"bounds":[13.1,33]}]},"total_rows":4,"truncation_type":null},"text/plain":"     country  perc_obesity        bounds\n0  Argentina          21.5  [15.4, 31.5]\n1    Germany          22.3  [16.2, 32.4]\n2      Japan           2.5    [1.1, 3.5]\n3     Norway          23.0  [13.1, 33.0]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>country</th>\n      <th>perc_obesity</th>\n      <th>bounds</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Argentina</td>\n      <td>21.5</td>\n      <td>[15.4, 31.5]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Germany</td>\n      <td>22.3</td>\n      <td>[16.2, 32.4]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Japan</td>\n      <td>2.5</td>\n      <td>[1.1, 3.5]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Norway</td>\n      <td>23.0</td>\n      <td>[13.1, 33.0]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n 0    15.4\n0    31.5\n1    16.2\n1    32.4\n2     1.1\n2     3.5\n3    13.1\n3    33.0\nName: bounds, dtype: object\n"}]},{"source":"# Merge obesity_bounds with country and perc_obesity columns of obesity using the indexes\nobesity_final = obesity[['country', 'perc_obesity']].merge(obesity_bounds, right_index=True, left_index=True)\ndisplay(obesity_final)","metadata":{"executionTime":85,"lastSuccessfullyExecutedCode":"# Merge obesity_bounds with country and perc_obesity columns of obesity using the indexes\nobesity_final = obesity[['country', 'perc_obesity']].merge(obesity_bounds, right_index=True, left_index=True)\ndisplay(obesity_final)"},"cell_type":"code","id":"c3224051-039f-41b4-93fb-f761e5be8cf8","execution_count":63,"outputs":[{"output_type":"display_data","data":{"application/com.datacamp.data-table.v1+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"country","type":"string"},{"name":"perc_obesity","type":"number"},{"name":"bounds","type":"string"}],"pandas_version":"1.4.0"},"data":[{"index":0,"country":"Argentina","perc_obesity":21.5,"bounds":15.4},{"index":0,"country":"Argentina","perc_obesity":21.5,"bounds":31.5},{"index":1,"country":"Germany","perc_obesity":22.3,"bounds":16.2},{"index":1,"country":"Germany","perc_obesity":22.3,"bounds":32.4},{"index":2,"country":"Japan","perc_obesity":2.5,"bounds":1.1},{"index":2,"country":"Japan","perc_obesity":2.5,"bounds":3.5},{"index":3,"country":"Norway","perc_obesity":23,"bounds":13.1},{"index":3,"country":"Norway","perc_obesity":23,"bounds":33}]},"total_rows":8,"truncation_type":null},"text/plain":"     country  perc_obesity bounds\n0  Argentina          21.5   15.4\n0  Argentina          21.5   31.5\n1    Germany          22.3   16.2\n1    Germany          22.3   32.4\n2      Japan           2.5    1.1\n2      Japan           2.5    3.5\n3     Norway          23.0   13.1\n3     Norway          23.0   33.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>country</th>\n      <th>perc_obesity</th>\n      <th>bounds</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Argentina</td>\n      <td>21.5</td>\n      <td>15.4</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Argentina</td>\n      <td>21.5</td>\n      <td>31.5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Germany</td>\n      <td>22.3</td>\n      <td>16.2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Germany</td>\n      <td>22.3</td>\n      <td>32.4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Japan</td>\n      <td>2.5</td>\n      <td>1.1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Japan</td>\n      <td>2.5</td>\n      <td>3.5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Norway</td>\n      <td>23.0</td>\n      <td>13.1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Norway</td>\n      <td>23.0</td>\n      <td>33.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"source":"### Explode the bounds\nYou were able to transform the list-like column successfully, but you are not satisfied with the steps you had to take. You want to find an easier way to get the same reshaped DataFrame.\n\nYou remembered what you learned about exploding list-like columns, and you will apply a new strategy.\n\nThe same DataFrame obesity is available in your session. It contains the country, perc_obesity, and the column bounds with the minimum and maximum values you can find in different parts of the same country.","metadata":{},"cell_type":"markdown","id":"5e39cc30-057b-4a3b-a0fe-e32b8bea24e4"},{"source":"# Transform the list-like column named bounds \nobesity_explode = obesity.explode('bounds')\n\n# Modify obesity_explode by resetting the index\nobesity_explode.reset_index(drop=True, inplace=True)\n\n# Print obesity_explode\nprint(obesity_explode)","metadata":{"executionTime":81,"lastSuccessfullyExecutedCode":"# Transform the list-like column named bounds \nobesity_explode = obesity.explode('bounds')\n\n# Modify obesity_explode by resetting the index\nobesity_explode.reset_index(drop=True, inplace=True)\n\n# Print obesity_explode\nprint(obesity_explode)"},"cell_type":"code","id":"32cf5fb5-35b8-46fe-96f4-290194470a9a","execution_count":64,"outputs":[{"output_type":"stream","name":"stdout","text":"     country  perc_obesity bounds\n0  Argentina          21.5   15.4\n1  Argentina          21.5   31.5\n2    Germany          22.3   16.2\n3    Germany          22.3   32.4\n4      Japan           2.5    1.1\n5      Japan           2.5    3.5\n6     Norway          23.0   13.1\n7     Norway          23.0   33.0\n"}]},{"source":"### The good old split\nYou have to do one last task for the obesity project. Your colleague gave you a new dataset to analyze with which you will perform the same analysis as before.\n\nAfter inspecting the dataset obesity, you realize that you have the same columns as before, but the bounds column is not a list. This time, the column contains two values separated with a hyphen in the form of string.\n\nYou will process the string and then transform the column.\n\n```python\nIn [1]:\nobesity\nOut[1]:\n\n        country  perc_obesity     bounds\n0        France          14.5  11.4-25.5\n1        Mexico          25.3  16.2-32.4\n2         Spain          12.5   8.1-16.5\n3  South Africa          11.3   9.1-20.1\n```","metadata":{},"cell_type":"markdown","id":"a055d1fd-396e-44cc-a12c-31c03c0267b3"},{"source":"obesity = pd.DataFrame({\n    'country':['France', 'Mexico', 'Spain', 'South Africa'],\n    'perc_obesity':[14.5,25.3,12.5,11.3],\n    'bounds':['11.4-25.5', '16.2-32.4', '8.1-16.5', '9.1-20.1']\n})\ndisplay(obesity)","metadata":{"executionTime":158,"lastSuccessfullyExecutedCode":"obesity = pd.DataFrame({\n    'country':['France', 'Mexico', 'Spain', 'South Africa'],\n    'perc_obesity':[14.5,25.3,12.5,11.3],\n    'bounds':['11.4-25.5', '16.2-32.4', '8.1-16.5', '9.1-20.1']\n})\ndisplay(obesity)"},"cell_type":"code","id":"40abdd32-ec08-4038-841a-1d5aa1350927","execution_count":65,"outputs":[{"output_type":"display_data","data":{"application/com.datacamp.data-table.v1+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"country","type":"string"},{"name":"perc_obesity","type":"number"},{"name":"bounds","type":"string"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":[{"index":0,"country":"France","perc_obesity":14.5,"bounds":"11.4-25.5"},{"index":1,"country":"Mexico","perc_obesity":25.3,"bounds":"16.2-32.4"},{"index":2,"country":"Spain","perc_obesity":12.5,"bounds":"8.1-16.5"},{"index":3,"country":"South Africa","perc_obesity":11.3,"bounds":"9.1-20.1"}]},"total_rows":4,"truncation_type":null},"text/plain":"        country  perc_obesity     bounds\n0        France          14.5  11.4-25.5\n1        Mexico          25.3  16.2-32.4\n2         Spain          12.5   8.1-16.5\n3  South Africa          11.3   9.1-20.1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>country</th>\n      <th>perc_obesity</th>\n      <th>bounds</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>France</td>\n      <td>14.5</td>\n      <td>11.4-25.5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Mexico</td>\n      <td>25.3</td>\n      <td>16.2-32.4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Spain</td>\n      <td>12.5</td>\n      <td>8.1-16.5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>South Africa</td>\n      <td>11.3</td>\n      <td>9.1-20.1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"source":"# Split the columns bounds using a hyphen as delimiter\nobesity_split = obesity['bounds'].str.split('-')\n\nprint(obesity_split, '\\n')\n\n# Assign the result of the split to the bounds column\nobesity_split = obesity.assign(bounds=obesity['bounds'].str.split('-'))\n\n# Print obesity\nprint(obesity_split, '\\n')\n\n# Transform the column bounds in the obesity DataFrame\nobesity_split = obesity.assign(bounds=obesity['bounds'].str.split('-')).explode('bounds')\n\n# Print obesity_split\nprint(obesity_split)","metadata":{"executionTime":464,"lastSuccessfullyExecutedCode":"# Split the columns bounds using a hyphen as delimiter\nobesity_split = obesity['bounds'].str.split('-')\n\nprint(obesity_split, '\\n')\n\n# Assign the result of the split to the bounds column\nobesity_split = obesity.assign(bounds=obesity['bounds'].str.split('-'))\n\n# Print obesity\nprint(obesity_split, '\\n')\n\n# Transform the column bounds in the obesity DataFrame\nobesity_split = obesity.assign(bounds=obesity['bounds'].str.split('-')).explode('bounds')\n\n# Print obesity_split\nprint(obesity_split)"},"cell_type":"code","id":"5c3971a2-51c0-45af-9c7a-f770282e3c20","execution_count":68,"outputs":[{"output_type":"stream","name":"stdout","text":"0    [11.4, 25.5]\n1    [16.2, 32.4]\n2     [8.1, 16.5]\n3     [9.1, 20.1]\nName: bounds, dtype: object \n\n        country  perc_obesity        bounds\n0        France          14.5  [11.4, 25.5]\n1        Mexico          25.3  [16.2, 32.4]\n2         Spain          12.5   [8.1, 16.5]\n3  South Africa          11.3   [9.1, 20.1] \n\n        country  perc_obesity bounds\n0        France          14.5   11.4\n0        France          14.5   25.5\n1        Mexico          25.3   16.2\n1        Mexico          25.3   32.4\n2         Spain          12.5    8.1\n2         Spain          12.5   16.5\n3  South Africa          11.3    9.1\n3  South Africa          11.3   20.1\n"}]},{"source":"### Nested movies\nYou are curious about a movies dataset you've had on your computer for some time now that contains data about different movies. You would like to analyze that data, but you realize it's in a nested JSON format.\n\nTo read it into a DataFrame, you will need to use the function you have just learned. After that, you will reshape the resulting DataFrame to make it easier to work with.\n\n\n```python\n\nIn [1]:\nmovies\nOut[1]:\n\n[{'director': 'Woody Allen',\n  'producer': 'Letty Aronson',\n  'features': {'title': 'Magic in the Moonlight', 'year': 2014}},\n {'director': 'Niki Caro',\n  'producer': 'Jason Reed',\n  'features': {'title': 'Mulan', 'year': 2020}}]\n\n\n# Import the json_normalize function\nfrom pandas import json_normalize\n\n# Normalize movies and separate the new columns with an underscore\nmovies_norm = json_normalize(movies, sep='_')\n\n# Reshape using director and producer as index, create movies from column starting from features\nmovies_long = pd.wide_to_long(movies_norm, stubnames='features', \n                              i=['director', 'producer'], j='movies', \n                              sep='_', suffix='\\w+')\n\n# print movies_norm\nprint(movies_norm, '\\n')\n\n# Print movies_long\nprint(movies_long)\n\n\n      director       producer          features_title  features_year\n0  Woody Allen  Letty Aronson  Magic in the Moonlight           2014\n1    Niki Caro     Jason Reed                   Mulan           2020 \n\n                                                features\ndirector    producer      movies                        \nWoody Allen Letty Aronson title   Magic in the Moonlight\n                          year                      2014\nNiki Caro   Jason Reed    title                    Mulan\n                          year                      2020\n```\n\n* Start normalizing\n\n```python\n# Normalize the JSON contained in movies\nnormalize_movies = json_normalize(movies)\n\n# Print normalize_movies\nprint(normalize_movies)\n\n      director       producer                                           features\n0  Woody Allen  Letty Aronson  [{'title': 'Magic in the Moonlight', 'year': 2...\n1    Niki Caro     Jason Reed                 [{'title': 'Mulan', 'year': 2020}]\n```\n\n* Specify features\n\n```python\n# Specify the features column as the list of records \nnormalize_movies = json_normalize(movies, \n                                  record_path='features')\n\n# Print normalize_movies\nprint(normalize_movies)\n\n\n                      title  year\n0    Magic in the Moonlight  2014\n1  Vicky Cristina Barcelona  2008\n2         Midnight in Paris  2011\n3                     Mulan  2020\n```\n\n* Put it together\n```python\n# Specify director and producer to use as metadata for each record \nnormalize_movies = json_normalize(movies, \n                                  record_path='features', \n                                  meta=['director', 'producer'])\n\n# Print normalize_movies\nprint(normalize_movies)\n\n<script.py> output:\n                          title  year     director       producer\n    0    Magic in the Moonlight  2014  Woody Allen  Letty Aronson\n    1  Vicky Cristina Barcelona  2008  Woody Allen  Letty Aronson\n    2         Midnight in Paris  2011  Woody Allen  Letty Aronson\n    3                     Mulan  2020    Niki Caro     Jason Reed\n```","metadata":{},"cell_type":"markdown","id":"89ad52ff-e531-4b01-93cc-8b9c8e78ca9c"},{"source":"## Dealing with nested data columns\n```python\nwriters = ['Mary Shelley', 'Ernest Hemingway']\nbooks = ['{\"title\": \"Frankenstein\", \"year\":\"1818\"}',\n        '{\"title\": \"Old Man & The Sea\", \"year\":\"1951\"}']\ncollection = pd.DataFrame(dict(writers=writes, books=books))\n\n         writers  books   \n    0    Mary Shelley  {'title':'Frankenstein', 'year':1818}  \n    1    Ernest Hemingway  {'title':'Old Man & The Sea', 'year':1951}   \n```","metadata":{},"cell_type":"markdown","id":"fc02f1b4-efe6-487a-8979-224f575c2c62"},{"source":"### Un-nesting birds\nFinally, your job for the day is done, but your colleague asked you a last minute favor. A client has provided data about birds he wants to classify.\n\nYou examine the data and realize that it's in a bad format - the list of birds is in one file, and the characteristics of the birds are in another.\n\nYou manage to read the bird names into a list called names. You read the bird facts into another list called bird_facts, but this list contains dictionaries in string format.","metadata":{},"cell_type":"markdown","id":"7fe62a9f-ce6e-4529-8d97-64fcded5f357"},{"source":"names = ['Killdeer', 'Chipping Sparrow', 'Cedar Waxwing']\nbird_facts = ['{\"Size\" : \"Large\", \"Color\": \"Golden brown\", \"Behavior\": \"Runs swiftly along ground\", \"Habitat\": \"Rocky areas\"}',\n '{\"Size\":\"Small\", \"Color\": \"Gray-white\", \"Behavior\": \"Often in flocks\", \"Habitat\": \"Open woodlands\"}',\n '{\"Size\":\"Small\", \"Color\": \"Gray-brown\", \"Behavior\": \"Catch insects over open water\", \"Habitat\": \"Parks\"}']\n\n# Define birds reading names and bird_facts lists into names and bird_facts columns \nbirds = pd.DataFrame(dict(names=names, bird_facts=bird_facts))\n\n# Print birds\nprint(birds)","metadata":{"executionTime":273,"lastSuccessfullyExecutedCode":"names = ['Killdeer', 'Chipping Sparrow', 'Cedar Waxwing']\nbird_facts = ['{\"Size\" : \"Large\", \"Color\": \"Golden brown\", \"Behavior\": \"Runs swiftly along ground\", \"Habitat\": \"Rocky areas\"}',\n '{\"Size\":\"Small\", \"Color\": \"Gray-white\", \"Behavior\": \"Often in flocks\", \"Habitat\": \"Open woodlands\"}',\n '{\"Size\":\"Small\", \"Color\": \"Gray-brown\", \"Behavior\": \"Catch insects over open water\", \"Habitat\": \"Parks\"}']\n\n# Define birds reading names and bird_facts lists into names and bird_facts columns \nbirds = pd.DataFrame(dict(names=names, bird_facts=bird_facts))\n\n# Print birds\nprint(birds)"},"cell_type":"code","id":"89947993-4e6e-48fd-93e9-db9a4962e127","execution_count":69,"outputs":[{"output_type":"stream","name":"stdout","text":"              names                                         bird_facts\n0          Killdeer  {\"Size\" : \"Large\", \"Color\": \"Golden brown\", \"B...\n1  Chipping Sparrow  {\"Size\":\"Small\", \"Color\": \"Gray-white\", \"Behav...\n2     Cedar Waxwing  {\"Size\":\"Small\", \"Color\": \"Gray-brown\", \"Behav...\n"}]},{"source":"import json\n# Apply the function json.loads function to the bird_facts column\ndata_split = birds['bird_facts'].apply(json.loads).apply(pd.Series)\n\n# Print birds\nprint(data_split)","metadata":{"executionTime":78,"lastSuccessfullyExecutedCode":"import json\n# Apply the function json.loads function to the bird_facts column\ndata_split = birds['bird_facts'].apply(json.loads).apply(pd.Series)\n\n# Print birds\nprint(data_split)"},"cell_type":"code","id":"414d3475-af9a-48f0-b8ea-1b1044bf58a3","execution_count":71,"outputs":[{"output_type":"stream","name":"stdout","text":"    Size         Color                       Behavior         Habitat\n0  Large  Golden brown      Runs swiftly along ground     Rocky areas\n1  Small    Gray-white                Often in flocks  Open woodlands\n2  Small    Gray-brown  Catch insects over open water           Parks\n"}]},{"source":"# Define birds reading names and bird_facts lists into names and bird_facts columns\nbirds = pd.DataFrame(dict(names=names, bird_facts=bird_facts))\n\n# Apply to bird_facts column the function loads from json module\ndata_split = birds['bird_facts'].apply(json.loads).apply(pd.Series)\n\n# Remove the bird_facts column from birds\nbirds = birds.drop(columns='bird_facts')\n\n# Concatenate the columns of birds and data_split\nbirds = pd.concat([birds,  data_split], axis=1)\n\n# Print birds\ndisplay(birds)","metadata":{"executionTime":121,"lastSuccessfullyExecutedCode":"# Define birds reading names and bird_facts lists into names and bird_facts columns\nbirds = pd.DataFrame(dict(names=names, bird_facts=bird_facts))\n\n# Apply to bird_facts column the function loads from json module\ndata_split = birds['bird_facts'].apply(json.loads).apply(pd.Series)\n\n# Remove the bird_facts column from birds\nbirds = birds.drop(columns='bird_facts')\n\n# Concatenate the columns of birds and data_split\nbirds = pd.concat([birds,  data_split], axis=1)\n\n# Print birds\ndisplay(birds)"},"cell_type":"code","id":"0ccfb77a-a28a-4b4e-a47b-d34786d469c2","execution_count":73,"outputs":[{"output_type":"display_data","data":{"application/com.datacamp.data-table.v1+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"names","type":"string"},{"name":"Size","type":"string"},{"name":"Color","type":"string"},{"name":"Behavior","type":"string"},{"name":"Habitat","type":"string"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":[{"index":0,"names":"Killdeer","Size":"Large","Color":"Golden brown","Behavior":"Runs swiftly along ground","Habitat":"Rocky areas"},{"index":1,"names":"Chipping Sparrow","Size":"Small","Color":"Gray-white","Behavior":"Often in flocks","Habitat":"Open woodlands"},{"index":2,"names":"Cedar Waxwing","Size":"Small","Color":"Gray-brown","Behavior":"Catch insects over open water","Habitat":"Parks"}]},"total_rows":3,"truncation_type":null},"text/plain":"              names   Size  ...                       Behavior         Habitat\n0          Killdeer  Large  ...      Runs swiftly along ground     Rocky areas\n1  Chipping Sparrow  Small  ...                Often in flocks  Open woodlands\n2     Cedar Waxwing  Small  ...  Catch insects over open water           Parks\n\n[3 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>names</th>\n      <th>Size</th>\n      <th>Color</th>\n      <th>Behavior</th>\n      <th>Habitat</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Killdeer</td>\n      <td>Large</td>\n      <td>Golden brown</td>\n      <td>Runs swiftly along ground</td>\n      <td>Rocky areas</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Chipping Sparrow</td>\n      <td>Small</td>\n      <td>Gray-white</td>\n      <td>Often in flocks</td>\n      <td>Open woodlands</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Cedar Waxwing</td>\n      <td>Small</td>\n      <td>Gray-brown</td>\n      <td>Catch insects over open water</td>\n      <td>Parks</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"source":"### Don't dump the bird\nYou want to read the birds data into a DataFrame like you did in the previous exercise, but this time, you would like to try a different approach.\n\nYou would like to have a code that you can reuse in this situations, so you want to establish the fastest strategy to convert it into a usable DataFrame. You think that working with the json format could speed up the process.\n\n```python\nIn [3]:\nbirds\nOut[3]:\n\n              names                                         bird_facts\n0          Killdeer  {\"Size\" : \"Large\", \"Color\": \"Golden brown\", \"B...\n1  Chipping Sparrow  {\"Size\":\"Small\", \"Color\": \"Gray-white\", \"Behav...\n2     Cedar Waxwing  {\"Size\":\"Small\", \"Color\": \"Gray-brown\", \"Behav...                 \n```\n\n```python\n# Apply json.loads to the bird_facts column and transform it to a list\nbirds_facts = birds['bird_facts'].apply(json.loads).to_list()\n\n# Convert birds_fact into a JSON \nbirds_dump = json.dumps(birds_facts)\nprint(type(birds_dump), type(birds_facts))\n\n# Read the JSON birds_dump into a DataFrame \nbirds_df = pd.read_json(birds_dump)\n\n# Concatenate the 'names' column of birds with birds_df \nbirds_final = pd.concat([birds['names'], birds_df], axis=1)\n\n# Print birds_final\nprint(birds_final)\n\n\n<class 'str'>-birds_dump <class 'list'> birds_facts\n              names   Size         Color                       Behavior         Habitat\n0          Killdeer  Large  Golden brown      Runs swiftly along ground     Rocky areas\n1  Chipping Sparrow  Small    Gray-white                Often in flocks  Open woodlands\n2     Cedar Waxwing  Small    Gray-brown  Catch insects over open water           Parks\n```","metadata":{},"cell_type":"markdown","id":"fe77e9b4-bc38-4296-8798-959ac194d3bb"}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"editor":"DataCamp Workspace"},"nbformat":4,"nbformat_minor":5}