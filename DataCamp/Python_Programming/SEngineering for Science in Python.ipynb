{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d6e0b57",
   "metadata": {},
   "source": [
    "## Software Engineering for Data Scientists in Python\n",
    "* Modularity\n",
    "* Documentation\n",
    "* Automated Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ba1ef9",
   "metadata": {},
   "source": [
    "### Python Modularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62ee152b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 3 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "# import the numpy package\n",
    "import numpy as np\n",
    "\n",
    "# create an array class object\n",
    "arr = np.array([8,6,7,5,3,0,9])\n",
    "\n",
    "# use arr sort method\n",
    "arr.sort()\n",
    "\n",
    "# print sorted array\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602b3c4f",
   "metadata": {},
   "source": [
    "* Note here and reminder of the np.sort method returning a NoneType and modifying the array in place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "932ad30e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(arr.sort())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5ecb47",
   "metadata": {},
   "source": [
    "### Leveraging documentation\n",
    "When writing code for Data Science, it's inevitable that you'll need to install and use someone else's code. You'll quickly learn that using someone else's code is much more pleasant when they use good software engineering practices. In particular, good documentation makes the right way to call a function obvious. In this exercise you'll use python's help() method to view a function's documentation so you can determine how to correctly call a new method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9304a24f",
   "metadata": {},
   "source": [
    "```python\n",
    "# load the Counter function into our environment\n",
    "from collections import Counter\n",
    "\n",
    "# View the documentation for Counter.most_common\n",
    "print(help(Counter.most_common))\n",
    "\n",
    "most_common(self, n=None)\n",
    "    List the n most common elements and their counts from the most\n",
    "    common to the least.  If n is None, then list all element counts.\n",
    "    \n",
    "    >>> Counter('abracadabra').most_common(3)\n",
    "    [('a', 5), ('b', 2), ('r', 2)]\n",
    "```\n",
    "* We can see the modules most_common method and how the Counter takes arguments and the return type of each counted object being listed in a list of tuples\n",
    "\n",
    "```python\n",
    "# use Counter to find the top 5 most common words\n",
    "top_5_words = Counter(words).most_common(n=5)\n",
    "\n",
    "# display the top 5 most common words\n",
    "print(top_5_words)\n",
    "\n",
    "# Output\n",
    "[('@DataCamp', 299), ('to', 263), ('the', 251), ('in', 164), ('RT', 158)]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b852f3",
   "metadata": {},
   "source": [
    "### Using pycodestyle\n",
    "We saw earlier that pycodestyle can be run from the command line to check a file for PEP 8 compliance. Sometimes it's useful to run this kind of check from a Python script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4aff45",
   "metadata": {},
   "source": [
    "```python\n",
    "# Import needed package\n",
    "import pycodestyle\n",
    "\n",
    "# Create a StyleGuide instance\n",
    "style_checker = pycodestyle.StyleGuide()\n",
    "\n",
    "# Run PEP 8 check on multiple files\n",
    "result = style_checker.check_files(['nay_pep8.py', 'yay_pep8.py'])\n",
    "\n",
    "# Print result of PEP 8 style check\n",
    "print(result.messages)\n",
    "\n",
    "```\n",
    "\n",
    "```python\n",
    "nay_pep8.py:1:1: E265 block comment should start with '# '\n",
    "nay_pep8.py:2:6: E225 missing whitespace around operator\n",
    "nay_pep8.py:4:2: E131 continuation line unaligned for hanging indent\n",
    "nay_pep8.py:5:6: E131 continuation line unaligned for hanging indent\n",
    "nay_pep8.py:6:1: E122 continuation line missing indentation or outdented\n",
    "nay_pep8.py:7:1: E265 block comment should start with '# '\n",
    "nay_pep8.py:8:1: E402 module level import not at top of file\n",
    "nay_pep8.py:9:1: E265 block comment should start with '# '\n",
    "nay_pep8.py:10:1: E302 expected 2 blank lines, found 0\n",
    "nay_pep8.py:10:18: E231 missing whitespace after ','\n",
    "nay_pep8.py:11:2: E111 indentation is not a multiple of 4\n",
    "nay_pep8.py:12:2: E111 indentation is not a multiple of 4\n",
    "nay_pep8.py:14:1: E265 block comment should start with '# '\n",
    "nay_pep8.py:15:1: E305 expected 2 blank lines after class or function definition, found 1\n",
    "nay_pep8.py:16:11: E111 indentation is not a multiple of 4\n",
    "nay_pep8.py:16:11: E117 over-indented\n",
    "nay_pep8.py:16:17: E225 missing whitespace around operator\n",
    "nay_pep8.py:16:32: E222 multiple spaces after operator\n",
    "nay_pep8.py:16:32: E251 unexpected spaces around keyword / parameter equals\n",
    "nay_pep8.py:16:38: E231 missing whitespace after ','\n",
    "nay_pep8.py:16:44: E221 multiple spaces before operator\n",
    "nay_pep8.py:16:44: E251 unexpected spaces around keyword / parameter equals\n",
    "nay_pep8.py:16:47: E251 unexpected spaces around keyword / parameter equals\n",
    "nay_pep8.py:17:11: E111 indentation is not a multiple of 4\n",
    "nay_pep8.py:17:17: E201 whitespace after '('\n",
    "nay_pep8.py:17:25: E202 whitespace before ')'\n",
    "nay_pep8.py:17:27: W292 no newline at end of file\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac83992e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please help me\n",
      "PLEASE EUREKA!!\n"
     ]
    }
   ],
   "source": [
    "def print_phrase(phrase, polite=True, shout=False):\n",
    "    if polite:# It's generally polite to say please\n",
    "        phrase = 'Please ' + phrase\n",
    "\n",
    "    if shout:  #All caps looks like a written shout\n",
    "        phrase = phrase.upper() + '!!'\n",
    "\n",
    "    print(phrase)\n",
    "\n",
    "\n",
    "#Politely ask for help\n",
    "print_phrase('help me', polite=True)\n",
    " # Shout about a discovery\n",
    "print_phrase('eureka', shout=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3729a8d",
   "metadata": {},
   "source": [
    "* See the comment and type error that would be raised\n",
    "```python\n",
    "my_script.py:2:15: E261 at least two spaces before inline comment\n",
    "my_script.py:5:16: E262 inline comment should start with '# '\n",
    "my_script.py:11:1: E265 block comment should start with '# '\n",
    "my_script.py:13:2: E114 indentation is not a multiple of four (comment)\n",
    "my_script.py:13:2: E116 unexpected indentation (comment)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62bbdc43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please help me\n",
      "PLEASE EUREKA!!\n"
     ]
    }
   ],
   "source": [
    "def print_phrase(phrase, polite=True, shout=False):\n",
    "    if polite:  # It's generally polite to say please\n",
    "        phrase = 'Please ' + phrase\n",
    "\n",
    "    if shout:  # All caps looks like a written shout\n",
    "        phrase = phrase.upper() + '!!'\n",
    "\n",
    "    print(phrase)\n",
    "\n",
    "\n",
    "# Politely ask for help\n",
    "print_phrase('help me', polite=True)\n",
    "# Shout about a discovery\n",
    "print_phrase('eureka', shout=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba42686",
   "metadata": {},
   "source": [
    "* We can see the inline comments here are off and would be caught with the `StyleChecker` instance and use of the method above in the previous exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fb310e",
   "metadata": {},
   "source": [
    "### `Writing a Python Module`\n",
    "* What are the minimal requirements to make an import-able python package?\n",
    "    - A Directory with a blank file named **__init__.py**\n",
    "    \n",
    "<br>\n",
    "\n",
    "#### Naming Convention\n",
    "* PEP 8 instructs that package names be all lowercase and only use underscores when it improves readability\n",
    "\n",
    "```python\n",
    "# example import from (text_analyzer, textAnalyzer, TextAnalyzer, & __text_analyzer__)\n",
    "\n",
    "# easiesnt and right convention\n",
    "import text_analyzer\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e226991e",
   "metadata": {},
   "source": [
    "* Recognizing packages\n",
    "The structure of your directory tree is printed below. You'll be working in the file my_script.py that you can see in the tree.\n",
    "\n",
    "```python\n",
    "recognizing_packages\n",
    "├── MY_PACKAGE\n",
    "│&nbsp;&nbsp; └── _init_.py\n",
    "├── package\n",
    "│&nbsp;&nbsp; └── __init__.py\n",
    "├── package_py\n",
    "│&nbsp;&nbsp; └── __init__\n",
    "│&nbsp;&nbsp;     └── __init__.py\n",
    "├── py_package\n",
    "│&nbsp;&nbsp; └── __init__.py\n",
    "├── pyackage\n",
    "│&nbsp;&nbsp; └── init.py\n",
    "└── my_script.py\n",
    "```\n",
    "\n",
    "* Package Selection\n",
    "\n",
    "```python\n",
    "# Import local packages\n",
    "import py_package\n",
    "import package\n",
    "\n",
    "# View the help for each package\n",
    "help(py_package)\n",
    "help(package)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc8ab15",
   "metadata": {},
   "source": [
    "### Adding functionality to your package\n",
    "In the file counter_utils.py, you will write 2 functions to be a part of your package: plot_counter and sum_counters. The structure of your package can be seen in the tree below. For the coding portions of this exercise, you will be working in the file counter_utils.py.\n",
    "\n",
    "```python\n",
    "text_analyzer\n",
    "├── __init__.py\n",
    "└── counter_utils.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c399aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed functionality\n",
    "from collections import Counter\n",
    "\n",
    "def plot_counter(counter, n_most_common=5):\n",
    "  # Subset the n_most_common items from the input counter\n",
    "  top_items = counter.most_common(n_most_common)\n",
    "  # Plot `top_items`\n",
    "  plot_counter_most_common(top_items)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92844f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed functionality\n",
    "from collections import Counter\n",
    "\n",
    "def sum_counters(counters):\n",
    "  # Sum the inputted counters\n",
    "  return sum(counters, Counter())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2235203",
   "metadata": {},
   "source": [
    "* You just wrote two functions for your package in the file counter_utils.py named plot_counter & sum_counters. \n",
    "\n",
    "Which of the following lines would correctly import these functions in __init__.py using relative import syntax?\n",
    "\n",
    "\n",
    "* from counter_utils import plot_counter, sum_counters\n",
    "\n",
    "* **from .counter_utils import plot_counter, sum_counters**\n",
    "\n",
    "* from . import plot_counter, sum_counters\n",
    "\n",
    "* from .counter_utils import plot_counter & sum_counters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16683748",
   "metadata": {},
   "source": [
    "### Using your package's new functionality\n",
    "\n",
    "You've now created some great functionality for text analysis to your package. In this exercise, you'll leverage your package to analyze some tweets written by DataCamp & DataCamp users.\n",
    "\n",
    "The object word_counts is loaded into your environment. It contains a list of Counter objects that contain word counts from a sample of DataCamp tweets.\n",
    "\n",
    "* Structure\n",
    "```python\n",
    "working_dir\n",
    "├── text_analyzer\n",
    "│    ├── __init__.py\n",
    "│    ├── counter_utils.py\n",
    "└── my_script.py\n",
    "```\n",
    "\n",
    "```python\n",
    "# Import local package\n",
    "import text_analyzer\n",
    "\n",
    "# Sum word_counts using sum_counters from text_analyzer\n",
    "word_count_totals = text_analyzer.sum_counters(word_counts)\n",
    "\n",
    "# Plot word_count_totals using plot_counter from text_analyzer\n",
    "text_analyzer.plot_counter(word_count_totals)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f7f72c",
   "metadata": {},
   "source": [
    "### Writing `requirements.txt`\n",
    "We covered how having a requirements.txt file can help your package be more portable by allowing your users to easily recreate its intended environment. In this exercise, you will be writing the contents of a requirements file to a python variable.\n",
    "\n",
    "Note, in practice, the code you write in this exercise would be written to it's own txt file instead of a variable in your python session.\n",
    "\n",
    "* Write the requirement for matplotlib with at least version 3.0.0 or above.\n",
    "* Write the requirement for numpy version 1.15.4 exactly.\n",
    "* Write the requirement for pandas with at most version 0.22.0.\n",
    "* Write a non-version specific requirement for pycodestyle\n",
    "\n",
    "```python\n",
    "requirements = \"\"\"\n",
    "matplotlib>=3.0.0\n",
    "numpy==1.15.4\n",
    "pandas<=0.22.0\n",
    "pycodestyle\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "* Recall now that **pip install -r allows you to install everything listed in a requirements file.** \n",
    "* Above is the requirements file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1950923e",
   "metadata": {},
   "source": [
    "### Creating setup.py\n",
    "In order to make your package installable by pip you need to create a setup.py file. In this exercise you will create this file for the text_analyzer package you've been building\n",
    "\n",
    "* import the needed function, setup, from the setuptools package.\n",
    "* Complete the name & packages arguments; keep in mind your package is located in a directory named text_analyzer.\n",
    "* List yourself as the author.\n",
    "\n",
    "```python\n",
    "# Import needed function from setuptools\n",
    "from setuptools import setup\n",
    "\n",
    "# Create proper setup to be used by pip\n",
    "setup(name='text_analyzer',\n",
    "      version='0.0.1',\n",
    "      description='Perform and visualize a text anaylsis.',\n",
    "      author='Craig',\n",
    "      packages=['text_analyzer'])\n",
    "\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "### Listing requirements in setup.py\n",
    "We created a `setup.py` file earlier, but we forgot to list our dependency on matplotlib in the install_requires argument. In this exercise you will practice listing your version specific dependencies by correcting the setup.py you previously wrote for your text_analyzer package.\n",
    "\n",
    "* import the needed function, setup, from the setuptools package.\n",
    "* List yourself as the author.\n",
    "* Specify your install_requires to require matplotlib version 3.0.0 or above.\n",
    "\n",
    "```python\n",
    "# Import needed function from setuptools\n",
    "from setuptools import setup\n",
    "\n",
    "# Create proper setup to be used by pip\n",
    "setup(name='text_analyzer',\n",
    "      version='0.0.1',\n",
    "      description='Perform and visualize a text anaylsis.',\n",
    "      author='Craig',\n",
    "      packages=['text_analyzer'],\n",
    "      install_requires=['matplotlib>=3.0.0'])\n",
    "```\n",
    "* When users pip install your package the correct version of matplotlib will be automatically handled by pip."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18642e8",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Utilizing Classes\n",
    "\n",
    "<br>\n",
    "\n",
    "### Writing a class for your package\n",
    "We've covered how classes can be written in Python. In this exercise, you'll be creating the beginnings of a Document class that will be a foundation for text analysis in your package. Once the class is written you will modify your package's __init__.py file to make it easily accessible by your users.\n",
    "\n",
    "* Structure\n",
    "```python\n",
    "working_dir\n",
    "├── text_analyzer\n",
    "│    ├── __init__.py\n",
    "│    ├── counter_utils.py\n",
    "│    ├── document.py\n",
    "└── my_script.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536a97d6",
   "metadata": {},
   "source": [
    "* You are working in **document.py**.\n",
    "* Finish the def statement that will create a new Document instance when a user calls Document().\n",
    "* Use your knowledge of PEP 8 conventions to complete the definition of the newly named class method.\n",
    "\n",
    "```python\n",
    "# Define document Class\n",
    "class Document:\n",
    "    \"\"\"A class for text analysis\n",
    "    \n",
    "    :param text : string of text to be analyzed\n",
    "    :ivar text: string of text to be analyzed; set by 'text' parameter\n",
    "    \"\"\"\n",
    "    # Method to create a new instance of MyClass\n",
    "    def __init__(self,text):\n",
    "        # Store text parameter to the text attribute\n",
    "        self.text = text\n",
    "```\n",
    "\n",
    "* You just completed writing the Document class for your package in document.py. Which of the following lines would correctly **import** this class in __init__.py using relative import syntax?\n",
    "\n",
    "#### Possible Answers\n",
    "\n",
    "* from document import Document\n",
    "\n",
    "* from . import Document\n",
    "\n",
    "* **from .document import Document**\n",
    "\n",
    "* from .document import document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bef3cf6",
   "metadata": {},
   "source": [
    "### Using your package's class\n",
    "You just wrote the beginnings of a Document class that you'll build upon to perform text analysis. In this exercise, you'll test out its current functionality of storing text.\n",
    "\n",
    "Below is the document tree that you've built up so far when developing your package. You'll be working in **my_script.py**\n",
    "\n",
    "```python\n",
    "working_dir\n",
    "├── text_analyzer\n",
    "│    ├── __init__.py\n",
    "│    ├── counter_utils.py\n",
    "│    ├── document.py\n",
    "└── my_script.py\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "```python\n",
    "# Import custom text_analyzer package\n",
    "import text_analyzer\n",
    "\n",
    "# Create an instance of Document with datacamp_tweet\n",
    "my_document = text_analyzer.Document(text=datacamp_tweet)\n",
    "\n",
    "# Print the text attribute of the Document instance\n",
    "print(my_document.text)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f59c7fb",
   "metadata": {},
   "source": [
    "### Writing a `non-public` method\n",
    "In the lesson, we covered how to add functionality to classes using non-public methods. By defining methods as non-public you're signifying to the user that the method is only to be used inside the package.\n",
    "\n",
    "In this exercise, you will define a non-public method that will be leveraged by your class to count words.\n",
    "\n",
    "* Counter from collections has been loaded into your environment, as well as the function tokenize().\n",
    "* Add a method named count_words as a non-public method.\n",
    "* Give your non-public method the functionality to count the contents tokens attribute using Counter().\n",
    "* Utilize your new function in the __init__ metho\n",
    "\n",
    "```python\n",
    "class Document:\n",
    "  def __init__(self, text):\n",
    "    self.text = text\n",
    "    # Tokenize the document with non-public tokenize method\n",
    "    self.tokens = self._tokenize()\n",
    "    # Perform word count with non-public count_words method\n",
    "    self.word_counts = self._count_words()\n",
    "\n",
    "  def _tokenize(self):\n",
    "    return tokenize(self.text)\n",
    "\t\n",
    "  # non-public method to tally document's word counts with Counter\n",
    "  def _count_words(self):\n",
    "    return Counter(self.tokens)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb42e9c3",
   "metadata": {},
   "source": [
    "### Using your class's functionality\n",
    "You've now added additional functionality to your Document class's __init__ method that automatically processes text for your users. In this exercise, you'll act as one of those users to see the benefits of your hard work.\n",
    "\n",
    "* Create a new Document instance from the datacamp_tweets data set loaded into your environment. The datacamp_tweets object is a single string containing hundreds of tweets written by DataCamp & DataCamp users.\n",
    "* Print the first 5 tokens from datacamp_doc.\n",
    "* Print the top 5 most common words that were calculated by the non-public _count_words() method automatically in the Document.__init__ method.\n",
    "\n",
    "```python\n",
    "# create a new document instance from datacamp_tweets\n",
    "datacamp_doc = Document(datacamp_tweets)\n",
    "\n",
    "# print the first 5 tokens from datacamp_doc\n",
    "print(datacamp_doc.tokens[:5])\n",
    "\n",
    "# print the top 5 most used words in datacamp_doc\n",
    "print(datacamp_doc.word_counts.most_common(5))\n",
    "```\n",
    "* Thanks to the functionality you added to the `__init__ method`, your users get the benefits of tokenization and word counts without any extra effort.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea83782",
   "metadata": {},
   "source": [
    "### Using inheritance to create a class\n",
    "You've previously written a `Document` class for text analysis, but your NLP project will now have a focus on Social Media data. Your general Document class might be useful later so it's best not destroy it while your focus shifts to tweets.\n",
    "\n",
    "Instead of copy-pasting the already written functionality, you will use the principles of `'DRY'` and inheritance to quickly create your new SocialMedia class.\n",
    "\n",
    "* Document has been preloaded in the session.\n",
    "* Complete the class statement to create a SocialMedia class that inherits from Document.\n",
    "* Define SocialMedia's __init__() method that initializes a Document.\n",
    "\n",
    "\n",
    "```python\n",
    "# Define a SocialMedia class that is a child of the `Document class`\n",
    "class SocialMedia(Document):\n",
    "    def __init__(self, text):\n",
    "        Document.__init__(self, text)\n",
    "\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "### Adding functionality to a child class\n",
    "You've just written a `SocialMedia` class that inherits functionality from `Document`, parent_class. As of now, the SocialMedia class doesn't have any functionality different from Document. In this exercise, you will build features into SocialMedia to specialize it for use with Social Media data.\n",
    "\n",
    "* The function filter_word_counts() has been loaded in your session. Use help() to see its proper usage.\n",
    "* Finish the _count_hashtags method using filter_word_counts() so that only words_counts starting with # remain.\n",
    "\n",
    "#### `Reference of Document Parent Class`\n",
    "```python\n",
    "class Document:\n",
    "    # Initialize a new Document instance\n",
    "    def __init__(self, text):\n",
    "        self.text = text\n",
    "        # Pre tokenize the document with non-public tokenize method\n",
    "        self.tokens = self._tokenize()\n",
    "        # Pre tokenize the document with non-public count_words\n",
    "        self.word_counts = self._count_words()\n",
    "\n",
    "    def _tokenize(self):\n",
    "        return tokenize(self.text)\n",
    "\n",
    "    # Non-public method to tally document's word counts\n",
    "    def _count_words(self):\n",
    "        # Use collections.Counter to count the document's tokens\n",
    "        return Counter(self.tokens)\n",
    "```\n",
    "\n",
    "```python\n",
    "# Define a SocialMedia class that is a child of the `Document class`\n",
    "class SocialMedia(Document):\n",
    "    def __init__(self, text):\n",
    "        Document.__init__(self, text)\n",
    "        self.hashtag_counts = self._count_hashtags()\n",
    "        \n",
    "    def _count_hashtags(self):\n",
    "        # Filter attribute so only words starting with '#' remain\n",
    "        return filter_word_counts(self.word_counts, first_char='#')\n",
    "```\n",
    "\n",
    "* function filter reference\n",
    "```python\n",
    "Help on function filter_word_counts in module __main__:\n",
    "\n",
    "filter_word_counts(word_counts, first_char)\n",
    "    Filter Document.word_counts by the first character of the word\n",
    "    \n",
    "    :param word_counts: the word_counts attribute of a Document class instance\n",
    "    :param first_char: only keep word counts that start with this character\n",
    "    \n",
    "    >>> # How to filter to only words that start with 'A'\n",
    "    >>> filter_word_counts(document.word_counts, 'A')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920d658d",
   "metadata": {},
   "source": [
    "* A little more functionality for the child class \n",
    "\n",
    "* Fill in the first line ofSocialMedia's __init__ method using the parent class to properly utilize inheritance.\n",
    "* Properly call the _count_mentions method in __init__ to add a new feature to SocialMedia.\n",
    "\n",
    "```python\n",
    "# Define a SocialMedia class that is a child of the `Document class`\n",
    "class SocialMedia(Document):\n",
    "    def __init__(self, text):\n",
    "        Document.__init__(self, text)\n",
    "        self.hashtag_counts = self._count_hashtags()\n",
    "        self.mention_counts = self._count_mentions()\n",
    "        \n",
    "    def _count_hashtags(self):\n",
    "        # Filter attribute so only words starting with '#' remain\n",
    "        return filter_word_counts(self.word_counts, first_char='#')      \n",
    "    \n",
    "    def _count_mentions(self):\n",
    "        # Filter attribute so only words starting with '@' remain\n",
    "        return filter_word_counts(self.word_counts, first_char='@')\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55ecc68",
   "metadata": {},
   "source": [
    "### Using your child class\n",
    "Thanks to the power of inheritance you were able to create a feature-rich, `SocialMedia` class based on its parent, Document. Let's see some of these features in action.\n",
    "\n",
    "Additionally, SocialMedia has been added to __init__.py for ease of use.\n",
    "\n",
    "* import your text_analyzer custom package.\n",
    "* Define dc_tweets as an instance of SocialMedia with the preloaded datacamp_tweets object as the text.\n",
    "* print the 5 most_common mentioned users in the data using the appropriate dc_tweets attribute.\n",
    "* Use text_analyzer's plot_counter() method to plot the most used hashtags in the data using the appropriate dc_tweets attribute.\n",
    "\n",
    "```python\n",
    "# Import custom text_analyzer package\n",
    "import text_analyzer\n",
    "\n",
    "# Create a SocialMedia instance with datacamp_tweets\n",
    "dc_tweets = text_analyzer.SocialMedia(text=datacamp_tweets)\n",
    "\n",
    "# Print the top five most most mentioned users\n",
    "print(dc_tweets.mention_counts.most_common(5))\n",
    "\n",
    "# Plot the most used hashtags\n",
    "text_analyzer.plot_counter(dc_tweets.mention_counts)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04a2cdd",
   "metadata": {},
   "source": [
    "### Creating a grandchild class\n",
    "In this exercise you will be using inheritance to create a Tweet class from your SocialMedia class. This new grandchild class of Document will be able to tackle Twitter specific details such as retweets.\n",
    "\n",
    "* Complete the class statement so that Tweets inherits from SocialMedia. SocialMedia has already been loaded in your environment.\n",
    "* Use super() to call the __init__ method of the parent class.\n",
    "* Define retweet_text. Use help() to complete the call to filter_lines with the correct parameter name. filter_lines has already been loaded in your environment.\n",
    "* return retweet_text from _process_retweets as an instance of SocialMedia.\n",
    "\n",
    "\n",
    "```python\n",
    "# Define a Tweet class that inherits from SocialMedia\n",
    "class Tweets(SocialMedia):\n",
    "    def __init__(self, text):\n",
    "        # Call parent's __init__ with super()\n",
    "        super().__init__(text)\n",
    "        # Define retweets attribute with non-public method\n",
    "        self.retweets = self._process_retweets()\n",
    "\n",
    "    def _process_retweets(self):\n",
    "        # Filter tweet text to only include retweets\n",
    "        retweet_text = filter_lines(self.text, first_chars='RT')\n",
    "        # Return retweet_text as a SocialMedia object\n",
    "        return SocialMedia(retweet_text)\n",
    "```\n",
    "\n",
    "### Using Inherited Methods \n",
    "```python\n",
    "# Import needed package\n",
    "import text_analyzer\n",
    "\n",
    "# Create instance of Tweets\n",
    "my_tweets = text_analyzer.Tweets(datacamp_tweets)\n",
    "\n",
    "# Plot the most used hashtags in the retweets\n",
    "my_tweets.retweets.plot_counts('hashtag_counts')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feddc38c",
   "metadata": {},
   "source": [
    "## Maintainability\n",
    "\n",
    "<br>\n",
    "\n",
    "### Writing docstrings\n",
    "We just learned some about the benefits of docstrings. In this exercise, you will practice writing docstrings that can be utilized by a documentation generator like Sphinx.\n",
    "\n",
    "Note that your docstring submission must match the solution exactly. If you find yourself getting it wrong several times, it may be a good idea to refresh the sample code and start over.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "308f7d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split text into tokens using a regular expression\n",
      "\n",
      "  :param text: text to be tokenized\n",
      "  :param regex: regular expression used to match tokens using re.findall \n",
      "  :return: a list of resulting tokens\n",
      "\n",
      "  >>> tokenize('the rain in spain')\n",
      "  ['the', 'rain', 'in', 'spain']\n",
      "  \n",
      "['the', 'rain', 'in', 'spain']\n"
     ]
    }
   ],
   "source": [
    "# Complete the function's docstring\n",
    "import re \n",
    "def tokenize(text, regex=r'[a-zA-z]+'):\n",
    "  \"\"\"Split text into tokens using a regular expression\n",
    "\n",
    "  :param text: text to be tokenized\n",
    "  :param regex: regular expression used to match tokens using re.findall \n",
    "  :return: a list of resulting tokens\n",
    "\n",
    "  >>> tokenize('the rain in spain')\n",
    "  ['the', 'rain', 'in', 'spain']\n",
    "  \"\"\"\n",
    "  return re.findall(regex, text, flags=re.IGNORECASE)\n",
    "\n",
    "# Print the docstring\n",
    "print(tokenize.__doc__)\n",
    "print(tokenize('the rain in spain'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26d4ea8",
   "metadata": {},
   "source": [
    "### Using good function names\n",
    "A good function name can go a long way for both user and maintainer understanding. A good function name is descriptive and describes what a function does. In this exercise, you'll choose a name for a function that will help aid in its readability when used.\n",
    "\n",
    "* The math module has been pre-loaded into your environment to be able to use its sqrt function.\n",
    "* Give function the best possible name from the following options: do_stuff, hypotenuse_length, square_root_of_leg_a_squared_plus_leg_b_squared, pythagorean_theorem.\n",
    "* Complete the docstring's example with the function's name.\n",
    "* print the result of using the newly named function to find the length of the hypotenuse for a right triangle with legs of length 6 & 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd64b0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def hypotenuse_length(leg_a, leg_b):\n",
    "    \"\"\"Find the length of a right triangle's hypotenuse\n",
    "\n",
    "    :param leg_a: length of one leg of triangle\n",
    "    :param leg_b: length of other leg of triangle\n",
    "    :return: length of hypotenuse\n",
    "    \n",
    "    >>> hypotenuse_length(3, 4)\n",
    "    5\n",
    "    \"\"\"\n",
    "    return math.sqrt(leg_a**2 + leg_b**2)\n",
    "\n",
    "\n",
    "# Print the length of the hypotenuse with legs 6 & 8\n",
    "print(hypotenuse_length(6, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c745e00",
   "metadata": {},
   "source": [
    "### Using good variable names\n",
    "Just like functions, descriptive variable names can make your code much more readable. In this exercise, you'll write some code using good variable naming practices.\n",
    "\n",
    "There's not always a clear best name for a variable. The exercise has been written to try and make a clear best choice from the provided options.\n",
    "\n",
    "* Choose the best variable name to hold the sample of pupil diameter measurements in millimeters from the following choices: `d`, `diameter`, `pupil_diameter`, or `pupil_diameter_in_millimeters`.\n",
    "* Take the mean of the measurements and assign it to a variable. Choose the best variable name to hold this mean from the following options: m, mean, mean_diameter, or mean_pupil_diameter_in_millimeters.\n",
    "* Print the resulting average pupil diameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dad8d0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.04\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean\n",
    "\n",
    "# Sample measurements of pupil diameter in mm\n",
    "pupil_diameter = [3.3, 6.8, 7.0, 5.4, 2.7]\n",
    "\n",
    "# Average pupil diameter from sample\n",
    "mean_diameter = mean(pupil_diameter)\n",
    "\n",
    "print(mean_diameter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37c0e21",
   "metadata": {},
   "source": [
    "* One letter variable names aren't very descriptive, long variable names can interfere with readability, and one word variable names are sometimes a great option; in this case the options you chose strike the balance between readability and descriptiveness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbc2efe",
   "metadata": {},
   "source": [
    "### Refactoring for readability\n",
    "Refactoring longer functions into smaller units can help with both readability and modularity. In this exercise, you will refactor a function into smaller units. The function you will be refactoring is shown below. Note, in the exercise, you won't be using docstrings for the sake of space; in a real application, you should include documentation!\n",
    "\n",
    "```python\n",
    "def polygon_area(n_sides, side_len):\n",
    "    \"\"\"Find the area of a regular polygon\n",
    "\n",
    "    :param n_sides: number of sides\n",
    "    :param side_len: length of polygon sides\n",
    "    :return: area of polygon\n",
    "\n",
    "    >>> round(polygon_area(4, 5))\n",
    "    25\n",
    "    \"\"\"\n",
    "    perimeter = n_sides * side_len\n",
    "\n",
    "    apothem_denominator = 2 * math.tan(math.pi / n_sides)\n",
    "    apothem = side_len / apothem_denominator\n",
    "\n",
    "    return perimeter * apothem / 2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1a8567f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "259.80762113533166\n"
     ]
    }
   ],
   "source": [
    "def polygon_perimeter(n_sides, side_len):\n",
    "    return n_sides * side_len\n",
    "\n",
    "def polygon_apothem(n_sides, side_len):\n",
    "    denominator = 2 * math.tan(math.pi / n_sides)\n",
    "    return side_len / denominator\n",
    "\n",
    "def polygon_area(n_sides, side_len):\n",
    "    perimeter = polygon_perimeter(n_sides, side_len)\n",
    "    apothem = polygon_apothem(n_sides, side_len)\n",
    "\n",
    "    return perimeter * apothem / 2\n",
    "\n",
    "# Print the area of a hexagon with legs of size 10\n",
    "print(polygon_area(n_sides=6, side_len=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa98edc0",
   "metadata": {},
   "source": [
    "### Using doctest\n",
    "We just learned about doctest, which, if you're writing full docstrings with examples, is a simple way to minimally test your functions. In this exercise, you'll get some hands-on practice testing and debugging with doctest.\n",
    "\n",
    "The following have all be pre-loaded in your environment: doctest, Counter, and text_analyzer.\n",
    "\n",
    "Note that your docstring submission must match the solution exactly. If you find yourself getting it wrong several times, it may be a good idea to refresh the sample code and start over.\n",
    "\n",
    "```python\n",
    "def sum_counters(counters):\n",
    "    \"\"\"Aggregate collections.Counter objects by summing counts\n",
    "\n",
    "    :param counters: list/tuple of counters to sum\n",
    "    :return: aggregated counters with counts summed\n",
    "\n",
    "    >>> d1 = text_analyzer.Document('1 2 fizz 4 buzz fizz 7 8')\n",
    "    >>> d2 = text_analyzer.Document('fizz buzz 11 fizz 13 14')\n",
    "    >>> sum_counters([d1.word_counts, d2.word_counts])\n",
    "    Counter({'fizz': 4, 'buzz': 2})\n",
    "    \"\"\"\n",
    "    return sum(counters, Counter())\n",
    "\n",
    "doctest.testmod()\n",
    "```\n",
    "* Thanks to doctest you've not only checked your example is correct, but you've implemented a simple test to ensure the function continues working as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339f382b",
   "metadata": {},
   "source": [
    "### Using pytest\n",
    "doctest is a great tool, but it's not nearly as powerful as pytest. In this exercise, you'll write tests for your SocialMedia class using the pytest framework.\n",
    "\n",
    "```python\n",
    "from collections import Counter\n",
    "from text_analyzer import SocialMedia\n",
    "\n",
    "# Create an instance of SocialMedia for testing\n",
    "test_post = 'learning #python & #rstats is awesome! thanks @datacamp!'\n",
    "sm_post = SocialMedia(test_post)\n",
    "\n",
    "# Test hashtag counts are created properly\n",
    "def test_social_media_hashtags():\n",
    "    expected_hashtag_counts = Counter({'#python': 1, '#rstats': 1})\n",
    "    assert sm_post.hashtag_counts == expected_hashtag_counts\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e905f10",
   "metadata": {},
   "source": [
    "### Documenting classes for Sphinx\n",
    "`sphinx` is a great tool for rendering documentation as HTML. In this exercise, you'll write a docstring for a class that can be taken advantage of by sphinx.\n",
    "\n",
    "Note that your docstring submission must match the solution exactly. If you find yourself getting it wrong several times, it may be a good idea to refresh the sample code and start over.\n",
    "\n",
    "\n",
    "```python\n",
    "from text_analyzer import Document\n",
    "\n",
    "class SocialMedia(Document):\n",
    "    \"\"\"Analyze text data from social media\n",
    "    \n",
    "    :param text: social media text to analyze\n",
    "\n",
    "    :ivar hashtag_counts: Counter object containing counts of hashtags used in text\n",
    "    :ivar mention_counts: Counter object containing counts of @mentions used in text\n",
    "    \"\"\"\n",
    "    def __init__(self, text):\n",
    "        Document.__init__(self, text)\n",
    "        self.hashtag_counts = self._count_hashtags()\n",
    "        self.mention_counts = self._count_mentions()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395bc4c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a40b3ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
