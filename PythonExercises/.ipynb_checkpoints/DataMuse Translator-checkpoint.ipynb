{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5fbb0aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " token    : POS   : dep.    : head\n",
      "------------------------------------\n",
      " I        :       :         : I\n",
      " drove    :       :         : drove\n",
      " home     :       :         : home\n",
      " with     :       :         : with\n",
      " joy      :       :         : joy\n",
      " .        :       :         : .\n"
     ]
    }
   ],
   "source": [
    "def show_dep(text):\n",
    "    tokens = parser(text)\n",
    "    for token in tokens:\n",
    "        print(\" {:<8} : {:<5} : {:<7} : {}\".format(token.orth_,token.pos_,token.dep_,token.head))\n",
    "print(\" {:<8} : {:<5} : {:<7} : {}\".format(\"token\",\"POS\",\"dep.\",\"head\"))\n",
    "print(\"------------------------------------\")\n",
    "show_dep(\"I drove home with joy.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "68ba9bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Defaults', '__annotations__', '__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_components', '_config', '_disabled', '_ensure_doc', '_ensure_doc_with_context', '_factory_meta', '_get_pipe_index', '_has_gpu_model', '_link_components', '_meta', '_multiprocessing_pipe', '_optimizer', '_path', '_pipe_configs', '_pipe_meta', '_resolve_component_status', 'add_pipe', 'analyze_pipes', 'batch_size', 'begin_training', 'component', 'component_names', 'components', 'config', 'create_optimizer', 'create_pipe', 'create_pipe_from_source', 'default_config', 'default_error_handler', 'disable_pipe', 'disable_pipes', 'disabled', 'enable_pipe', 'evaluate', 'factories', 'factory', 'factory_names', 'from_bytes', 'from_config', 'from_disk', 'get_factory_meta', 'get_factory_name', 'get_pipe', 'get_pipe_config', 'get_pipe_meta', 'has_factory', 'has_pipe', 'initialize', 'lang', 'make_doc', 'max_length', 'meta', 'path', 'pipe', 'pipe_factories', 'pipe_labels', 'pipe_names', 'pipeline', 'rehearse', 'remove_pipe', 'rename_pipe', 'replace_listeners', 'replace_pipe', 'resume_training', 'select_pipes', 'set_error_handler', 'set_factory_meta', 'to_bytes', 'to_disk', 'tokenizer', 'update', 'use_params', 'vocab']\n"
     ]
    }
   ],
   "source": [
    "print(dir(parser))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d2b73a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "#doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "\n",
    "def pull_pos(text):\n",
    "    eng_lg_doc_string = nlp(text)\n",
    "    print(\" {:<8} : {:<5} : {:<7} : {}\".format(\"Text\",\"Tag\",\"Dep.\",\"POS\"))\n",
    "    print(\"------------------------------------\")\n",
    "    for token in eng_lg_doc_string:\n",
    "        print(\" {:<8} : {:<5} : {:<7} : {}\".format(token.text,token.tag_,token.dep_,token.pos_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c05f94fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Text     : Tag   : Dep.    : POS\n",
      "------------------------------------\n",
      " Apple    : NNP   : nsubj   : PROPN\n",
      " is       : VBZ   : aux     : AUX\n",
      " looking  : VBG   : ROOT    : VERB\n",
      " strategically : RB    : advmod  : ADV\n",
      " at       : IN    : prep    : ADP\n",
      " buying   : VBG   : pcomp   : VERB\n",
      " a        : DT    : det     : DET\n",
      " pretty   : JJ    : amod    : ADJ\n",
      " U.K.     : NNP   : compound : PROPN\n",
      " startup  : NN    : dobj    : NOUN\n",
      " ,        : ,     : punct   : PUNCT\n",
      " for      : IN    : prep    : ADP\n",
      " $        : $     : quantmod : SYM\n",
      " 1        : CD    : compound : NUM\n",
      " billion  : CD    : pobj    : NUM\n",
      " .        : .     : punct   : PUNCT\n",
      "\n",
      "\n",
      " Text     : Tag   : Dep.    : POS\n",
      "------------------------------------\n",
      " The      : DT    : det     : DET\n",
      " dog      : NN    : nsubj   : NOUN\n",
      " is       : VBZ   : aux     : AUX\n",
      " wilding  : VBG   : ROOT    : VERB\n",
      " out      : RP    : prt     : ADP\n",
      "\n",
      "\n",
      " Text     : Tag   : Dep.    : POS\n",
      "------------------------------------\n",
      " The      : DT    : det     : DET\n",
      " shark    : NN    : nsubj   : NOUN\n",
      " is       : VBZ   : aux     : AUX\n",
      " eating   : VBG   : ROOT    : VERB\n",
      " the      : DT    : det     : DET\n",
      " flailing : VBG   : amod    : VERB\n",
      " seal     : NN    : dobj    : NOUN\n"
     ]
    }
   ],
   "source": [
    "pull_pos(\"Apple is looking strategically at buying a pretty U.K. startup, for $1 billion.\")\n",
    "print('\\n')\n",
    "pull_pos(\"The dog is wilding out\")\n",
    "print('\\n')\n",
    "pull_pos('The shark is eating the flailing seal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "0ee19201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.datamuse.com/words?max=5&ml=Dog\n",
      "[{'word': 'hound', 'score': 14679551, 'tags': ['syn', 'n', 'results_type:primary_rel']}, {'word': 'tail', 'score': 13613214, 'tags': ['syn', 'n']}, {'word': 'trail', 'score': 12890296, 'tags': ['syn', 'n']}, {'word': 'tag', 'score': 11880526, 'tags': ['syn', 'n']}, {'word': 'heel', 'score': 11529463, 'tags': ['syn', 'n']}]\n"
     ]
    }
   ],
   "source": [
    "import requests as re\n",
    "import json\n",
    "\n",
    "params_dict = {'max': 5, 'ml': 'Dog'}\n",
    "resp = re.get('https://api.datamuse.com/words', params=params_dict)\n",
    "print(resp.url)\n",
    "print(json.loads(resp.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6846ddae",
   "metadata": {},
   "source": [
    "* We Want to Take a Sentenet String and use the pulled part of speech (function) above allong with the datamuse words api rel_[code] to pull a like word and return a sentence that should be hopefully a bit silly yet similar to the provided sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "90286211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rd\n",
    "import requests as re\n",
    "def sentence_eval(sntnc):\n",
    "    sent_lst = []\n",
    "    nlp_evl = spacy.load(\"en_core_web_sm\")\n",
    "    eng_string = nlp_evl(sntnc)\n",
    "    for token in eng_string:\n",
    "        if token.pos_ in ('PROPN', 'PUNCT', 'DET', 'AUX'):\n",
    "            #print(token.text)\n",
    "            sent_lst.append(token.text)\n",
    "        elif token.pos_ == 'VERB':\n",
    "            #print(token.text)\n",
    "            params = {'ml':token.text, 'max':15}\n",
    "            vrb_words = json.loads(re.get('https://api.datamuse.com/words', params=params).text)\n",
    "            rand_int_word_sel = rd.randint(0, len(vrb_words) - 1)\n",
    "            if token.text[-3:] != 'ing':\n",
    "                sent_lst.append(vrb_words[rand_int_word_sel]['word'])\n",
    "            else:\n",
    "                #print(vrb_words)\n",
    "                rand_int_word_sel_ing = [x for x in vrb_words if x['word'][-3:] == 'ing']\n",
    "                #print(rand_int_word_sel_ing)\n",
    "                ing_rand = rd.randint(0, len(rand_int_word_sel_ing))\n",
    "                #print(ing_rand)\n",
    "                sent_lst.append(rand_int_word_sel_ing[ing_rand]['word'])\n",
    "        elif token.pos_ == 'NOUN':\n",
    "            params = {'max':5, 'rel_jjb':token.text}\n",
    "            get_adj_nouns = re.get('https://api.datamuse.com/words', params=params)\n",
    "            get_adj_list = json.loads(get_adj_nouns.text)\n",
    "            sent_lst.append(get_adj_list[rd.randint(0, len(get_adj_list))]['word'])\n",
    "            sent_lst.append(token.text)\n",
    "        else:\n",
    "            # New kind of replacement\n",
    "            fr_pr = {'sl':token.text, 'max':10}\n",
    "            nw_words = json.loads(re.get('https://api.datamuse.com/words', params=fr_pr).text)\n",
    "            rand_new = rd.randint(0, len(nw_words) - 1)\n",
    "            sent_lst.append(nw_words[rand_new]['word'])\n",
    "            # Add a possible fun word after replacing\n",
    "            scnd_pr = {'rel_bgb':token.text}\n",
    "            predecessors = json.loads(re.get('https://api.datamuse.com/words', params=scnd_pr).text)\n",
    "            rand_prd = rd.randint(0, len(predecessors) - 1)\n",
    "            sent_lst.append(predecessors[rand_prd]['word'])\n",
    "            \n",
    "    return [sent_lst, ' '.join(sent_lst)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "8fcad72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random as rd\n",
    "rd.randint(0, 5) # random int (using above for selecting some random words from the api results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f11264fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['The', 'big', 'dog', 'is', 'mounting', 'the', 'barbed', 'fence'], 'The big dog is mounting the barbed fence']\n",
      "\n",
      "\n",
      "[['The', 'blue', 'shark', 'is', 'ingesting', 'the', 'privy', 'seal'], 'The blue shark is ingesting the privy seal']\n"
     ]
    }
   ],
   "source": [
    "print(sentence_eval(\"The dog is climbing the fence\"))\n",
    "print('\\n')\n",
    "print(sentence_eval(\"The shark is eating the seal\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
